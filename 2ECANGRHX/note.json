{
  "paragraphs": [
    {
      "text": "%md\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n# Bulk Data Loading\n\nThis notebook introduces the Splice Machine Bulk HFile Import mechanism, which you can use to import data into your database in a highly performant manner. Bulk importing splits a data file into temporary HFiles (store files) before it is imported into your database by directly loading the generated StoreFiles into your Region Servers. In this notebook we\u0027ll walk you through a simple example, after which you will be able to bulk import data into your database. \n\n\u003cp class\u003d\"noteIcon\"\u003eWe recommend using Bulk HFile importing; however, if your input might contain data errors that need checking, you must use our our basic import procedures, \u003ccode\u003eIMPORT_DATA\u003c/code\u003e or \u003ccode\u003eMERGE_DATA_FROM_FILE\u003c/code\u003e instead, because they perform constraint checking during ingestion.\u003c/p\u003e\n\nThis notebook contains these sections:\n\n* The *Bulk Data Import Checklist* summarizes important details about the format of the data you\u0027re importing.\n* The *Automatic Bulk Data Import* method shows you how to quickly bulk import your data.\n* The *Manual Bulk Data Import* allows you to control the splitting of data.\n* *Using the `BULK_IMPORT_HFILE` Command* shows the syntax for importing data using the `BULK_IMPORT_HFILE` system procedure.\n\nWhen you use bulk HFile to import your data, files are essentially split into temporary Hadoop files (HFiles) that are directly loaded into the region servers. Ideally, the process creates HFiles of equal size, which allows the data to be spread across all region servers equally. There are two methods for splitting the data into hfiles.\n\n* With *Automatic Splitting,* the system samplse the data in an attempt to determine the optimal split points. This is the quicker and easier method, but does not always ensure you have the ideal splitting of the data.\n* Using *Manual Splitting* improves the performance of the bulk data import process. Instead of having the system samples the data for split point, you provide the split points that tell the procedure where to split your data. This requires you to know the data well enough to provide the split points.\n\nLastly we will walk you through step-by-step examples of using both the automatic and manual process bulk data import processes.",
      "user": "anonymous",
      "dateUpdated": "2019-06-12 15:03:34.376",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003ch1\u003eBulk Data Loading\u003c/h1\u003e\n\u003cp\u003eThis notebook introduces the Splice Machine Bulk HFile Import mechanism, which you can use to import data into your database in a highly performant manner. Bulk importing splits a data file into temporary HFiles (store files) before it is imported into your database by directly loading the generated StoreFiles into your Region Servers. In this notebook we\u0026rsquo;ll walk you through a simple example, after which you will be able to bulk import data into your database. \u003c/p\u003e\n\u003cp class\u003d\"noteIcon\"\u003eWe recommend using Bulk HFile importing; however, if your input might contain data errors that need checking, you must use our our basic import procedures, \u003ccode\u003eIMPORT_DATA\u003c/code\u003e or \u003ccode\u003eMERGE_DATA_FROM_FILE\u003c/code\u003e instead, because they perform constraint checking during ingestion.\u003c/p\u003e\n\u003cp\u003eThis notebook contains these sections:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eThe \u003cem\u003eBulk Data Import Checklist\u003c/em\u003e summarizes important details about the format of the data you\u0026rsquo;re importing.\u003c/li\u003e\n  \u003cli\u003eThe \u003cem\u003eAutomatic Bulk Data Import\u003c/em\u003e method shows you how to quickly bulk import your data.\u003c/li\u003e\n  \u003cli\u003eThe \u003cem\u003eManual Bulk Data Import\u003c/em\u003e allows you to control the splitting of data.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eUsing the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e Command\u003c/em\u003e shows the syntax for importing data using the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e system procedure.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen you use bulk HFile to import your data, files are essentially split into temporary Hadoop files (HFiles) that are directly loaded into the region servers. Ideally, the process creates HFiles of equal size, which allows the data to be spread across all region servers equally. There are two methods for splitting the data into hfiles.\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eWith \u003cem\u003eAutomatic Splitting,\u003c/em\u003e the system samplse the data in an attempt to determine the optimal split points. This is the quicker and easier method, but does not always ensure you have the ideal splitting of the data.\u003c/li\u003e\n  \u003cli\u003eUsing \u003cem\u003eManual Splitting\u003c/em\u003e improves the performance of the bulk data import process. Instead of having the system samples the data for split point, you provide the split points that tell the procedure where to split your data. This requires you to know the data well enough to provide the split points.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLastly we will walk you through step-by-step examples of using both the automatic and manual process bulk data import processes.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559318768601_621263894",
      "id": "20190531-160608_403567962",
      "dateCreated": "2019-05-31 16:06:08.601",
      "dateStarted": "2019-06-12 15:03:34.404",
      "dateFinished": "2019-06-12 15:03:34.750",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Bulk Data Import Checklist\n\nWhen you bulk import data from flat files into your database, you need to specify a number of details about your data files to get them correctly imported. Before starting this process, please make sure your data formats will work, as defined here:\n\n\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol width\u003d\"30%\" /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eData File Detail\u003c/th\u003e\n            \u003cth\u003eSpecific Requirements\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eField delimited?\u003c/td\u003e\n            \u003ctd\u003eThe fields in each row \u003cstrong\u003emust\u003c/strong\u003e have delimiters between them.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eRows terminated?\u003c/td\u003e\n            \u003ctd\u003eEach row \u003cstrong\u003emust\u003c/strong\u003e be terminated with a newline character.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eHeader row included?\u003c/td\u003e\n            \u003ctd\u003eHeader rows are not allowed; if your data contains one, you \u003cstrong\u003emust\u003c/strong\u003e remove it.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003eDate\u003c/code\u003e, \u003ccode\u003etime\u003c/code\u003e, \u003ccode\u003etimestamp\u003c/code\u003e data types\u003c/td\u003e\n            \u003ctd\u003e If you are using \u003ccode\u003edate\u003c/code\u003e, \u003ccode\u003etime\u003c/code\u003e, and/or \u003ccode\u003etimestamp\u003c/code\u003e data types in the target table, you need to know how that data is represented in the flat file; your file \u003cstrong\u003emust\u003c/strong\u003e use a consistent representation, and you must specify that format when using the import command.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003eChar\u003c/code\u003e and \u003ccode\u003eVarchar\u003c/code\u003e data\u003c/td\u003e\n            \u003ctd\u003e\u003cp\u003eIf any of your \u003ccode\u003echar\u003c/code\u003e or \u003ccode\u003evarchar\u003c/code\u003e data contains your delimiter character, you \u003cstrong\u003eneed to use\u003c/strong\u003e a special character delimiter.\u003c/p\u003e\n                \u003cp\u003eIf any of your \u003ccode\u003echar\u003c/code\u003e or \u003ccode\u003evarchar\u003c/code\u003e data contains newline characters, you \u003cstrong\u003eneed to use\u003c/strong\u003e the \u003ccode\u003eoneLineRecords\u003c/code\u003e parameter.\u003c/p\u003e\n            \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\n\n\u003cp class\u003d\"noteIcon\"\u003eIt is a good idea to test your import, delimiting, date formatting, etc., on a small amount of data first before loading all of your data. That\u0027s what we\u0027ll do in this notebook.\u003c/p\u003e\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:27:12.598",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eBulk Data Import Checklist\u003c/h2\u003e\n\u003cp\u003eWhen you bulk import data from flat files into your database, you need to specify a number of details about your data files to get them correctly imported. Before starting this process, please make sure your data formats will work, as defined here:\u003c/p\u003e\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol width\u003d\"30%\" /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eData File Detail\u003c/th\u003e\n            \u003cth\u003eSpecific Requirements\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eField delimited?\u003c/td\u003e\n            \u003ctd\u003eThe fields in each row \u003cstrong\u003emust\u003c/strong\u003e have delimiters between them.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eRows terminated?\u003c/td\u003e\n            \u003ctd\u003eEach row \u003cstrong\u003emust\u003c/strong\u003e be terminated with a newline character.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003eHeader row included?\u003c/td\u003e\n            \u003ctd\u003eHeader rows are not allowed; if your data contains one, you \u003cstrong\u003emust\u003c/strong\u003e remove it.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003eDate\u003c/code\u003e, \u003ccode\u003etime\u003c/code\u003e, \u003ccode\u003etimestamp\u003c/code\u003e data types\u003c/td\u003e\n            \u003ctd\u003e If you are using \u003ccode\u003edate\u003c/code\u003e, \u003ccode\u003etime\u003c/code\u003e, and/or \u003ccode\u003etimestamp\u003c/code\u003e data types in the target table, you need to know how that data is represented in the flat file; your file \u003cstrong\u003emust\u003c/strong\u003e use a consistent representation, and you must specify that format when using the import command.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003eChar\u003c/code\u003e and \u003ccode\u003eVarchar\u003c/code\u003e data\u003c/td\u003e\n            \u003ctd\u003e\u003cp\u003eIf any of your \u003ccode\u003echar\u003c/code\u003e or \u003ccode\u003evarchar\u003c/code\u003e data contains your delimiter character, you \u003cstrong\u003eneed to use\u003c/strong\u003e a special character delimiter.\u003c/p\u003e\n                \u003cp\u003eIf any of your \u003ccode\u003echar\u003c/code\u003e or \u003ccode\u003evarchar\u003c/code\u003e data contains newline characters, you \u003cstrong\u003eneed to use\u003c/strong\u003e the \u003ccode\u003eoneLineRecords\u003c/code\u003e parameter.\u003c/p\u003e\n            \u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp class\u003d\"noteIcon\"\u003eIt is a good idea to test your import, delimiting, date formatting, etc., on a small amount of data first before loading all of your data. That\u0027s what we\u0027ll do in this notebook.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559324576281_1037587833",
      "id": "20190531-174256_33448938",
      "dateCreated": "2019-05-31 17:42:56.281",
      "dateStarted": "2019-06-05 21:27:12.613",
      "dateFinished": "2019-06-05 21:27:12.650",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Automatic Bulk Data Import\n\nIf you choose to use the automatic bulk data import process, all you need to do is run the `BULK_IMPORT_HFILE` system procedure. Splice Machine will automatically generate the split points by sampling the data that is being imported.  Before you execute `BULK_IMPORT_HFILE`, be sure to create the table and indexes first in Splice Machine.\n\nIf you discover that the automatic bulk data import process is not as performant as expected, you should consider the manual bulk data import process.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:28:59.474",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eAutomatic Bulk Data Import\u003c/h2\u003e\n\u003cp\u003eIf you choose to use the automatic bulk data import process, all you need to do is run the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e system procedure. Splice Machine will automatically generate the split points by sampling the data that is being imported. If you discover that the automatic bulk data import process is not as performant as expected, you should consider the manual bulk data import process. Before you execute \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e, be sure to create the table and indexes first in Splice Machine.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559343038082_-1537166862",
      "id": "20190531-225038_1926569480",
      "dateCreated": "2019-05-31 22:50:38.083",
      "dateStarted": "2019-06-05 21:28:27.874",
      "dateFinished": "2019-06-05 21:28:27.895",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Manual Bulk Data Import\n\nWhen using the manual bulk data import process, you need to pre-split the data by providing a CSV file that specifies all of the split points. Follow these steps to manually bulk import your data:\n\n1. Create the table in your Splice Machine database\n2. Optionally, create any index(es) on the table\n3. Pre-split the table\n4. Call the `SPLIT_TABLE_OR_INDEX` system procedure for the table\n5. Optionally, pre-split any index(es) on the table\n6. Optionally, call the `SPLIT_TABLE_OR_INDEX` system procedure for the index(es)\n7. Call the `BULK_IMPORT_HFILE` system procedure",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:30:39.269",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eManual Bulk Data Import\u003c/h2\u003e\n\u003cp\u003eWhen using the manual bulk data import process, you need to pre-split the data by providing a CSV file that specifies all of the split points. Follow these steps to manually bulk import your data:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eCreate the table in your Splice Machine database\u003c/li\u003e\n  \u003cli\u003eOptionally, create any index(es) on the table\u003c/li\u003e\n  \u003cli\u003ePre-split the table\u003c/li\u003e\n  \u003cli\u003eCall the \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e system procedure for the table\u003c/li\u003e\n  \u003cli\u003eOptionally, pre-split any index(es) on the table\u003c/li\u003e\n  \u003cli\u003eOptionally, call the \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e system procedure for the index(es)\u003c/li\u003e\n  \u003cli\u003eCall the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e system procedure\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559575103024_-616259271",
      "id": "20190603-151823_282426459",
      "dateCreated": "2019-06-03 15:18:23.024",
      "dateStarted": "2019-06-05 21:30:39.279",
      "dateFinished": "2019-06-05 21:30:39.331",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. Create the table in your Splice Machine database\n\nThe table you\u0027re importing into must exist in your Splice Machine database.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:31:20.658",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. Create the table in your Splice Machine database\u003c/h3\u003e\n\u003cp\u003eThe table you\u0026rsquo;re importing into must exist in your Splice Machine database.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602251032_-1481102806",
      "id": "20190603-225051_1876664131",
      "dateCreated": "2019-06-03 22:50:51.032",
      "dateStarted": "2019-06-05 21:31:20.659",
      "dateFinished": "2019-06-05 21:31:20.675",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 2. Optionally, create any index(es) on the table\n\nIf you’re going to index the table you’re importing, Splice Machine recommends that you create the index prior to using bulk import. This allows the index to also be pre-split into regions, which will prevent downstream bottlenecks.",
      "user": "anonymous",
      "dateUpdated": "2019-06-03 23:35:55.355",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. Optionally, create any index(es) on the table\u003c/h3\u003e\n\u003cp\u003eIf you’re going to index the table you’re importing, Splice Machine recommends that you create the index prior to using bulk import. This allows the index to also be pre-split into regions, which will prevent downstream bottlenecks.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602399629_2032079170",
      "id": "20190603-225319_914059632",
      "dateCreated": "2019-06-03 22:53:19.629",
      "dateStarted": "2019-06-03 23:35:55.357",
      "dateFinished": "2019-06-03 23:35:55.378",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 3. Pre-split the table\n\nWhen you pre-split a table, you are essentially identifying primary key values that can horizontally split the data into roughly equal parts. For example: let\u0027s say you have some order data that you want to load. The data contains a column for order id that has values from 1 to 999,999. We can pre-split this table into 4 roughly equal parts by using the order id column and specifying the values 250000, 500000, and 750000.\n\nCreate a file that contains the following. Note that we specify three split values to create four splits:\n\n```\n250000\n500000\n750000\n```\n\n\u003cdiv class\u003d\"noteIcon\"\u003e\u003cp\u003eSplit key values can be multiple columns, in which case each column value would be delimited by a pipe character (|). For example:\u003cp\u003e\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u003ccode\u003e200000|2019-01-01\u003c/code\u003e\u003c/p\u003e\u003c/div\u003e",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:38:14.902",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e3. Pre-split the table\u003c/h3\u003e\n\u003cp\u003eWhen you pre-split a table, you are essentially identifying primary key values that can horizontally split the data into roughly equal parts. For example: let\u0026rsquo;s say you have some order data that you want to load. The data contains a column for order id that has values from 1 to 999,999. We can pre-split this table into 4 roughly equal parts by using the order id column and specifying the values 250000, 500000, and 750000.\u003c/p\u003e\n\u003cp\u003eCreate a file that contains the following. Note that we specify three split values to create four splits:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e250000\n500000\n750000\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class\u003d\"noteIcon\"\u003e\u003cp\u003eSplit key values can be multiple columns, in which case each column value would be delimited by a pipe character (|). For example:\u003cp\u003e\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u003ccode\u003e200000|2019-01-01\u003c/code\u003e\u003c/p\u003e\u003c/div\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602428292_-2012676629",
      "id": "20190603-225348_1001222002",
      "dateCreated": "2019-06-03 22:53:48.292",
      "dateStarted": "2019-06-05 21:38:14.903",
      "dateFinished": "2019-06-05 21:38:14.924",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 4. Call the SPLIT_TABLE_OR_INDEX system procedure for the table\n\nSyntax for the `SPLIT_TABLE_OR_INDEX` command looks like this:\n\n```\ncall SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX (\n    schemaName,\n    tableName,\n    indexName,\n    columnList | null,\n    fileName,\n    columnDelimiter | null,\n    characterDelimiter | null,\n    timestampFormat | null,\n    dateFormat | null,\n    timeFormat | null,\n    maxBadRecords,\n    badRecordDirectory | null,\n    oneLineRecords | null,\n    charset | null,\n);\n```\nNotice that many of the parameters allow you to apply the default value by specifying `null`.\n\n\u003cp class\u003d\"noteNote\"\u003eYou can find full details about these parameters, including the default value for each, in \u003ca href\u003d\"https://doc.splicemachine.com/sqlref_sysprocs_splittable.html\" target\u003d\"_blank\"\u003eour \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e documentation.\u003c/a\u003e\u003c/p\u003e",
      "user": "anonymous",
      "dateUpdated": "2019-06-12 15:05:03.986",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e4. Call the SPLIT_TABLE_OR_INDEX system procedure for the table\u003c/h3\u003e\n\u003cp\u003eSyntax for the \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e command looks like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecall SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX (\n    schemaName,\n    tableName,\n    indexName,\n    columnList | null,\n    fileName,\n    columnDelimiter | null,\n    characterDelimiter | null,\n    timestampFormat | null,\n    dateFormat | null,\n    timeFormat | null,\n    maxBadRecords,\n    badRecordDirectory | null,\n    oneLineRecords | null,\n    charset | null,\n);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that many of the parameters allow you to apply the default value by specifying \u003ccode\u003enull\u003c/code\u003e.\u003c/p\u003e\n\u003cp class\u003d\"noteNote\"\u003eYou can find full details about these parameters, including the default value for each, in \u003ca href\u003d\"https://doc.splicemachine.com/sqlref_sysprocs_splittable.html\" target\u003d\"_blank\"\u003eour \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e documentation.\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602445483_289855710",
      "id": "20190603-225405_1559909743",
      "dateCreated": "2019-06-03 22:54:05.483",
      "dateStarted": "2019-06-05 21:38:59.662",
      "dateFinished": "2019-06-05 21:38:59.678",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 5. Optionally, pre-split any index(es) on the table\n\nIf you have any indexes for the table you need to repeat step 3 for each index.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:57:45.694",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e5. Optionally, pre-split any index(es) on the table\u003c/h3\u003e\n\u003cp\u003eIf you have any indexes for the table you will need to repeat step 3 for each index.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602448003_-1100288598",
      "id": "20190603-225408_770167072",
      "dateCreated": "2019-06-03 22:54:08.003",
      "dateStarted": "2019-06-04 14:26:26.826",
      "dateFinished": "2019-06-04 14:26:26.843",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 6. Optionally, call the SPLIT_TABLE_OR_INDEX system procedure for the index(es)\n\nIf you have any indexes for the table you need to repeat step 4 for each index.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:58:03.809",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e6. Optionally, call the SPLIT_TABLE_OR_INDEX system procedure for the index(es)\u003c/h3\u003e\n\u003cp\u003eIf you have any indexes for the table you will need to repeat step 4 for each index.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602451598_1808725521",
      "id": "20190603-225411_1051299024",
      "dateCreated": "2019-06-03 22:54:11.598",
      "dateStarted": "2019-06-04 14:26:59.704",
      "dateFinished": "2019-06-04 14:26:59.717",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 7. Call the BULK_IMPORT_HFILE system procedure\n\nLastly, call the `BULK_IMPORT_HFILE` command to bulk load your data. We will go over a complete example later in this notebook.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:58:17.775",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e7. Call the BULK_IMPORT_HFILE system procedure\u003c/h3\u003e\n\u003cp\u003eLastly, call the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e command to bulk load your data. We will go over a complete example later on in this notebook.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602453692_1218698556",
      "id": "20190603-225413_1997988980",
      "dateCreated": "2019-06-03 22:54:13.692",
      "dateStarted": "2019-06-04 14:29:26.460",
      "dateFinished": "2019-06-04 14:29:26.478",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## BULK_IMPORT_HFILE Command\n\nSyntax for the `BULK_IMPORT_HFILE` command looks like this:\n```\ncall SYSCS_UTIL.BULK_IMPORT_HFILE (\n    schemaName,\n    tableName,\n    insertColumnList | null,\n    fileOrDirectoryName,\n    columnDelimiter | null,\n    characterDelimiter | null,\n    timestampFormat | null,\n    dateFormat | null,\n    timeFormat | null,\n    maxBadRecords,\n    badRecordDirectory | null,\n    oneLineRecords | null,\n    charset | null,\n    bulkImportDirectory,\n    skipSampling\n);\n```\nNotice that many of the parameters allow you to apply the default value by specifying `null`.\n\n\u003cp class\u003d\"noteNote\"\u003eYou can find full details about these parameters, including the default value for each, in \u003ca href\u003d\"https://doc.splicemachine.com/sqlref_sysprocs_importhfile.htmll\" target\u003d\"_blank\"\u003eour \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e documentation.\u003c/a\u003e\u003c/p\u003e\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:29:46.102",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eBULK_IMPORT_HFILE Command\u003c/h2\u003e\n\u003cp\u003eSyntax for the \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e command looks like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecall SYSCS_UTIL.BULK_IMPORT_HFILE (\n    schemaName,\n    tableName,\n    insertColumnList | null,\n    fileOrDirectoryName,\n    columnDelimiter | null,\n    characterDelimiter | null,\n    timestampFormat | null,\n    dateFormat | null,\n    timeFormat | null,\n    maxBadRecords,\n    badRecordDirectory | null,\n    oneLineRecords | null,\n    charset | null,\n    bulkImportDirectory,\n    skipSampling\n);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that many of the parameters allow you to apply the default value by specifying \u003ccode\u003enull\u003c/code\u003e.\u003c/p\u003e\n\u003cp class\u003d\"noteNote\"\u003eYou can find full details about these parameters, including the default value for each, in \u003ca href\u003d\"https://doc.splicemachine.com/sqlref_sysprocs_importhfile.htmll\" target\u003d\"_blank\"\u003eour \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e documentation.\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559602671448_-508920858",
      "id": "20190603-225751_747541388",
      "dateCreated": "2019-06-03 22:57:51.448",
      "dateStarted": "2019-06-10 17:29:46.106",
      "dateFinished": "2019-06-10 17:29:48.500",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Step-by-Step Example of Automatic Bulk Data Import\n\nThis example walks you through the automatic bulk data import process one step at a time:\n\n1. *Create a Database Schema and Table*\n2. *Run the Automatic Bulk Import Data Procedure*\n3. *Review Imported Data*\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:59:22.878",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eStep-by-Step Example of Automatic Bulk Data Import\u003c/h2\u003e\n\u003cp\u003eThis example will walk you through the automatic bulk data import process one step at a time. In these steps you will:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003e\u003cem\u003eCreate a Database Schema and Table\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eRun the Automatic Bulk Import Data Procedure\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eReview Imported Data\u003c/em\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559603962198_-46723797",
      "id": "20190603-231922_1642293487",
      "dateCreated": "2019-06-03 23:19:22.200",
      "dateStarted": "2019-06-04 22:28:12.111",
      "dateFinished": "2019-06-04 22:28:12.127",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. Create a Database Schema and Table\n\nYou can get started by clicking the  \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph in this Notebook, which uses the `%splicemachine` interpreter to:\n\n* Create a new schema named `DEV3` in your database.\n* Create the `customer_bulk_import_example1` table in your database.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 21:59:42.665",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. Create a Database Schema and Table\u003c/h3\u003e\n\u003cp\u003eYou can get started by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph in this Notebook, which uses the \u003ccode\u003e%splicemachine\u003c/code\u003e interpreter to:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eCreate a new schema named \u003ccode\u003eDEV3\u003c/code\u003e in your database\u003c/li\u003e\n  \u003cli\u003eCreate the \u003ccode\u003ecustomer_bulk_import_example1\u003c/code\u003e table in your database.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559659519835_-1509748211",
      "id": "20190604-144519_1646070724",
      "dateCreated": "2019-06-04 14:45:19.835",
      "dateStarted": "2019-06-04 22:28:05.489",
      "dateFinished": "2019-06-04 22:28:05.523",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nCREATE TABLE DEV3.CUSTOMER_BULK_IMPORT_EXAMPLE1 (\n C_CUSTKEY INTEGER NOT NULL PRIMARY KEY,\n C_NAME VARCHAR(25),\n C_ADDRESS VARCHAR(40),\n C_NATIONKEY INTEGER NOT NULL,\n C_PHONE VARCHAR(15),\n C_ACCTBAL DECIMAL(15,2),\n C_MKTSEGMENT VARCHAR(10),\n C_COMMENT VARCHAR(117)\n);",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:30:14.907",
      "config": {
        "editorMode": "ace/mode/sql",
        "enabled": true,
        "results": {},
        "editorHide": false,
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "completionSupport": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559659518843_-542530214",
      "id": "20190604-144518_1198347952",
      "dateCreated": "2019-06-04 14:45:18.843",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 2. Run the Automatic Bulk Import Data Procedure\n\nNow we\u0027ll bulk import our data, which is the customer table data for TPCH-100. We\u0027ll use the automatic method for generating the split keys.\n\nThe first two rows of the data look like this:\n\n\u003cpre\u003e1,1,1,0.2548,GC,BARBARBAR,amotastqqsxqk,50000.0,-10.0,10.0,1,0,xzgtmkfcc,ylkolttoyrgtoypvu,vihxvtlufla,UC,808711111,7664160137823585,2016-08-26 15:09:58.574,OE,kmmmpivhrpyzdrcxiznqsujdvhnvbtvktvzncdigrmfrnbvmuqfdrgyzsacziwobfxcwbqrctbvyyhcefmpsitdjlebpphhtihhnserrolqbjeqpggnkvfowexxgtqoglwqrhhbjdnfrmbeieubdmtkfqicfjtwwbdwbbcacqvukmxhmnpekydlesjzatacwuntakarbcbfgrvxcztgzzfcbkppjfpznjxpnanktiswszzrgxvlccrksbojbzywtziijmdwfwdxyzrwwllzcnjdbkfoxzudqfdowuwuopemcfhxhrskhsrgydkklsgzaujzbqagycvqdnkpmtligujssjierqetnwxzipykpbxbkdunzrvekjpsonlqhtvmntabhlfpzvrzzbwbuzsqdvkbebissivntknptkfpxfcgcwmymncyfqifaqecxp\n2,1,1,0.2728,GC,BARBARBAR,maqolvlurgl,50000.0,-10.0,10.0,1,0,aommxpkuezwgcfyl,allgnqktgezptiui,rphjjqoevqwdpugh,ZL,115811111,8576454984888259,2016-08-26 15:09:58.575,OE,ozcazgrmfwgpdjcgeestwqmnygzqvvuxsrnnyjbxostljnlplmrdmcdbtxxoadyxeidhbffnevyierxsfgaqjuvpvgpcokbkshiqmyxlnqxwwukdcxswquhivmfkmmapjokweswzvwrpckizbjqjqlmvjjhdnjtdfxwfxfgufdjnfjudkmnbygatwvjbvgahmwwvchbsjeibfoqsfxcsbjkpxyhipsymwolcrokuhxumxkaafrgjzpxyuhkkqbijpgzcmzculivdhwjewwdepktddpswulbzwioeqvhjtorzeyqztitiagbqreoaydsqzixungqygjpiysoexyunbnuzupywuyjxavzvuccooszqbxgioulozbojsumejqoajofbzckjprjjcmmgugntnao\u003c/pre\u003e\n\nImport this data by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph, which calls our `BULK_IMPORT_HFILE` command.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 22:01:07.167",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. Run the Automatic Bulk Import Data Procedure\u003c/h3\u003e\n\u003cp\u003eNow we\u0026rsquo;ll bulk import our data, which is the customer table data for TPCH-100. We\u0026rsquo;ll use the automatic method for generating the split keys.\u003c/p\u003e\n\u003cp\u003eThe first two rows of the data look like this:\u003c/p\u003e\n\u003cpre\u003e1,1,1,0.2548,GC,BARBARBAR,amotastqqsxqk,50000.0,-10.0,10.0,1,0,xzgtmkfcc,ylkolttoyrgtoypvu,vihxvtlufla,UC,808711111,7664160137823585,2016-08-26 15:09:58.574,OE,kmmmpivhrpyzdrcxiznqsujdvhnvbtvktvzncdigrmfrnbvmuqfdrgyzsacziwobfxcwbqrctbvyyhcefmpsitdjlebpphhtihhnserrolqbjeqpggnkvfowexxgtqoglwqrhhbjdnfrmbeieubdmtkfqicfjtwwbdwbbcacqvukmxhmnpekydlesjzatacwuntakarbcbfgrvxcztgzzfcbkppjfpznjxpnanktiswszzrgxvlccrksbojbzywtziijmdwfwdxyzrwwllzcnjdbkfoxzudqfdowuwuopemcfhxhrskhsrgydkklsgzaujzbqagycvqdnkpmtligujssjierqetnwxzipykpbxbkdunzrvekjpsonlqhtvmntabhlfpzvrzzbwbuzsqdvkbebissivntknptkfpxfcgcwmymncyfqifaqecxp\n2,1,1,0.2728,GC,BARBARBAR,maqolvlurgl,50000.0,-10.0,10.0,1,0,aommxpkuezwgcfyl,allgnqktgezptiui,rphjjqoevqwdpugh,ZL,115811111,8576454984888259,2016-08-26 15:09:58.575,OE,ozcazgrmfwgpdjcgeestwqmnygzqvvuxsrnnyjbxostljnlplmrdmcdbtxxoadyxeidhbffnevyierxsfgaqjuvpvgpcokbkshiqmyxlnqxwwukdcxswquhivmfkmmapjokweswzvwrpckizbjqjqlmvjjhdnjtdfxwfxfgufdjnfjudkmnbygatwvjbvgahmwwvchbsjeibfoqsfxcsbjkpxyhipsymwolcrokuhxumxkaafrgjzpxyuhkkqbijpgzcmzculivdhwjewwdepktddpswulbzwioeqvhjtorzeyqztitiagbqreoaydsqzixungqygjpiysoexyunbnuzupywuyjxavzvuccooszqbxgioulozbojsumejqoajofbzckjprjjcmmgugntnao\u003c/pre\u003e\n\u003cp\u003eImport this data by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph, which calls our \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e command.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559659517942_-1524002668",
      "id": "20190604-144517_520643715",
      "dateCreated": "2019-06-04 14:45:17.942",
      "dateStarted": "2019-06-05 22:01:07.167",
      "dateFinished": "2019-06-05 22:01:07.185",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\ncall SYSCS_UTIL.BULK_IMPORT_HFILE(\u0027DEV3\u0027, \u0027CUSTOMER_BULK_IMPORT_EXAMPLE1\u0027, null, \u0027s3a://splice-benchmark-data/flat/TPCH/100/customer\u0027, \u0027|\u0027, null, null, null, null, 0, \u0027/tmp\u0027, true, null, \u0027/tmp/TMP_HFILE\u0027, false);",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:30:31.984",
      "config": {
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "commonSetting": {},
              "mode": "table",
              "setting": {
                "table": {
                  "updated": false,
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "updated": false,
                    "names": {
                      "files": "string",
                      "failedRows": "string",
                      "rowsImported": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    }
                  },
                  "tableOptionValue": {
                    "showPagination": false,
                    "useFilter": false,
                    "showAggregationFooter": false
                  },
                  "initialized": false,
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]"
                }
              },
              "optionOpen": false,
              "height": 300.0
            }
          }
        },
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "completionSupport": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559659516919_-1816219140",
      "id": "20190604-144516_1347289645",
      "dateCreated": "2019-06-04 14:45:16.919",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\u003cbr/\u003e\nYou\u0027ll notice that after you run the paragraph, you see a short report that indicates how many rows were successfully loaded and how many failed to load. In this example, all 15 million rows were successfully loaded.\n\nYou have probably also noticed that we used default values by specifying `null` for all of the parameters that have defaults; here\u0027s what those defaults mean:\n\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eParameter\u003c/th\u003e\n            \u003cth\u003eNULL Value Details\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003einsertColumnList\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur column list exactly matches the columns and ordering of columns in the table, so there\u0027s not need to specify a list.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003ecolumnDelimiter\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data uses the default comma character (\u003ccode\u003e,\u003c/code\u003e) to delimit columns.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003estringDelimiter\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eNone of our data fields contain the comma character, so we don\u0027t need a string delimiter character.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003etimestampFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data matches the default timestamp format, which is \u003ccode\u003eyyyy-MM-dd HH:mm:ss\u003c/code\u003e.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003edateFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data doesn\u0027t contain any date columns, so there\u0027s no need to specify a format.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003etimeFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data doesn\u0027t contain any time columns, so there\u0027s no need to specify a format.\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e",
      "user": "anonymous",
      "dateUpdated": "2019-06-12 20:20:10.798",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "language": "markdown",
          "completionSupport": false
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cbr/\u003e\n\u003cp\u003eYou\u0026rsquo;ll notice that after you run the paragraph, you see a short report that indicates how many rows were successfully loaded and how many failed to load. In this example, all 15 million rows were successfully loaded.\u003c/p\u003e\n\u003cp\u003eYou have probably also noticed that we used default values by specifying \u003ccode\u003enull\u003c/code\u003e for all of the parameters that have defaults; here\u0026rsquo;s what those defaults mean:\u003c/p\u003e\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eParameter\u003c/th\u003e\n            \u003cth\u003eNULL Value Details\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003einsertColumnList\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur column list exactly matches the columns and ordering of columns in the table, so there\u0027s not need to specify a list.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003ecolumnDelimiter\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data uses the default comma character (\u003ccode\u003e,\u003c/code\u003e) to delimit columns.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003estringDelimiter\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eNone of our data fields contain the comma character, so we don\u0027t need a string delimiter character.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003etimestampFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data matches the default timestamp format, which is \u003ccode\u003eyyyy-MM-dd HH:mm:ss\u003c/code\u003e.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003edateFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data doesn\u0027t contain any date columns, so there\u0027s no need to specify a format.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003ccode\u003etimeFormat\u003c/code\u003e\u003c/td\u003e\n            \u003ctd\u003eOur data doesn\u0027t contain any time columns, so there\u0027s no need to specify a format.\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1559659515522_1228070265",
      "id": "20190604-144515_562914129",
      "dateCreated": "2019-06-04 14:45:15.522",
      "dateStarted": "2019-06-12 20:20:00.039",
      "dateFinished": "2019-06-12 20:20:00.059",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 3. Review Imported Data\n\nLets take a look at the data we just imported by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph, which will select all the data from the `CUSTOMER_BULK_IMPORT_EXAMPLE1` table.",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:50:23.729",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "language": "markdown",
          "completionSupport": false
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e3. Review Imported Data\u003c/h3\u003e\n\u003cp\u003eLets take a look at the data we just imported by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph, which will select all the data from the \u003ccode\u003eCUSTOMER_BULK_IMPORT_EXAMPLE1\u003c/code\u003e table.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687342509_1064709741",
      "id": "20190604-222902_80066050",
      "dateCreated": "2019-06-04 22:29:02.509",
      "dateStarted": "2019-06-10 17:50:12.122",
      "dateFinished": "2019-06-10 17:50:12.151",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nSELECT * FROM DEV3.CUSTOMER_BULK_IMPORT_EXAMPLE1;\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:50:17.885",
      "config": {
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "commonSetting": {},
              "mode": "table",
              "setting": {
                "table": {
                  "updated": false,
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "updated": false,
                    "names": {
                      "C_ACCTBAL": "string",
                      "C_COMMENT": "string",
                      "C_CUSTKEY": "string",
                      "C_PHONE": "string",
                      "C_NATIONKEY": "string",
                      "C_ADDRESS": "string",
                      "C_MKTSEGMENT": "string",
                      "C_NAME": "string"
                    }
                  },
                  "tableOptionValue": {
                    "showPagination": false,
                    "useFilter": false,
                    "showAggregationFooter": false
                  },
                  "initialized": false,
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]"
                }
              },
              "optionOpen": false,
              "height": 300.0
            }
          }
        },
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687523082_162930063",
      "id": "20190604-223203_1603289077",
      "dateCreated": "2019-06-04 22:32:03.082",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Step-by-Step Example of Manual Bulk Data Import\n\nThis example will walk you through the manual bulk data import process one step at a time. In these steps you will:\n\n1. *Create a Database Schema and Table*\n2. *Manually Split the Table*\n2. *Run the Manual Bulk Import Data Procedure*\n3. *Review Imported Data*\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-04 23:04:09.317",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eStep-by-Step Example of Manual Bulk Data Import\u003c/h2\u003e\n\u003cp\u003eThis example will walk you through the manual bulk data import process one step at a time. In these steps you will:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003e\u003cem\u003eCreate a Database Schema and Table\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eManually Split the Table\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eRun the Manual Bulk Import Data Procedure\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eReview Imported Data\u003c/em\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559604002423_1624363595",
      "id": "20190603-232002_725447130",
      "dateCreated": "2019-06-03 23:20:02.423",
      "dateStarted": "2019-06-04 23:04:09.318",
      "dateFinished": "2019-06-04 23:04:09.330",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. Create a Database Schema and Table\n\nYou can get started by clicking the  \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph in this Notebook, which uses the `%splicemachine` interpreter to Create the `customer_bulk_import_example2` table in your database.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 22:03:43.303",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. Create a Database Schema and Table\u003c/h3\u003e\n\u003cp\u003eYou can get started by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph in this Notebook, which uses the \u003ccode\u003e%splicemachine\u003c/code\u003e interpreter to:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eCreate the \u003ccode\u003ecustomer_bulk_import_example2\u003c/code\u003e table in your database.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687029809_1119210650",
      "id": "20190604-222349_1188182272",
      "dateCreated": "2019-06-04 22:23:49.809",
      "dateStarted": "2019-06-04 22:48:59.680",
      "dateFinished": "2019-06-04 22:48:59.688",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nCREATE TABLE DEV3.CUSTOMER_BULK_IMPORT_EXAMPLE2 (\n C_CUSTKEY INTEGER NOT NULL PRIMARY KEY,\n C_NAME VARCHAR(25),\n C_ADDRESS VARCHAR(40),\n C_NATIONKEY INTEGER NOT NULL,\n C_PHONE VARCHAR(15),\n C_ACCTBAL DECIMAL(15,2),\n C_MKTSEGMENT VARCHAR(10),\n C_COMMENT VARCHAR(117)\n);",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:50:50.342",
      "config": {
        "enabled": true,
        "results": {},
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687028683_102180375",
      "id": "20190604-222348_199256013",
      "dateCreated": "2019-06-04 22:23:48.683",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 2. Manually Split the Table\n\nNow we need to create the split keys for our data. The customer data file that we are loading contains a customer key column that has values from 1 to 15,000,000. For this exercise, we want to evenly split the data into 4 hfiles, so the keys look like this:\n\n```\n3750000\n7500000\n11250000\n```\n\nFor every N lines of split data you specify, you’ll end up with N+1 regions; for example, the above 3 splits will produce these 4 regions:\n\n```\n0 -\u003e 3750000\n3750001 -\u003e 7500000\n7500001 -\u003e 11250000\n11250001 -\u003e (last possible key value)\n```\n\nWe have already created this file for you, so all you need to do is \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* the next paragraph. This calls the `SPLIT_TABLE_OR_INDEX` procedure, passing in the file that contains the split keys as a parameter value.\n\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 22:06:18.027",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. Manually Split the Table\u003c/h3\u003e\n\u003cp\u003eNow we need to create the split keys for our data. The customer data file that we are loading contains a customer key column that has values from 1 to 15,000,000. For this exercise, we want to evenly split the data into 4 hfiles, so the keys look like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e3750000\n7500000\n11250000\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor every N lines of split data you specify, you’ll end up with N+1 regions; for example, the above 3 splits will produce these 4 regions:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e0 -\u0026gt; 3750000\n3750001 -\u0026gt; 7500000\n7500001 -\u0026gt; 11250000\n11250001 -\u0026gt; (last possible key value)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe have already created this file for you, so all you need to do is \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e the next paragraph. This calls the \u003ccode\u003eSPLIT_TABLE_OR_INDEX\u003c/code\u003e procedure, passing in the file that contains the split keys as a parameter value.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687027581_-810239616",
      "id": "20190604-222347_469786882",
      "dateCreated": "2019-06-04 22:23:47.581",
      "dateStarted": "2019-06-05 22:06:18.028",
      "dateFinished": "2019-06-05 22:06:18.069",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\ncall SYSCS_UTIL.SYSCS_SPLIT_TABLE_OR_INDEX(\n    \u0027DEV3\u0027,\n    \u0027CUSTOMER_BULK_IMPORT_EXAMPLE2\u0027,\n    null, \n    \u0027C_CUSTKEY\u0027,\n    \u0027/opt/data/customer-split-keys.csv\u0027,\n    \u0027|\u0027, \n    null, \n    null, \n    null,\n    null, \n    -1, \n    \u0027/tmp\u0027, \n    true, \n    null\n);",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:51:08.231",
      "config": {
        "enabled": true,
        "results": {},
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "completionSupport": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559690679990_1353020230",
      "id": "20190604-232439_1511491436",
      "dateCreated": "2019-06-04 23:24:39.990",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 3. Run the Manual Bulk Import Data Procedure\n\nNow we\u0027re ready to bulk import our data. As in the previous example, we are bulk importing the customer table data for TPCH-100. This time we have pre-split the table so we will not need to sample the data before importing. The main difference in this call to `BULK_IMPORT_HFILE` is that the last parameter, `skipSampling`, is now set to `true` to indicate that we\u0027ve already pre-split the data.\n\nImport the data in this file by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph, which calls our `BULK_IMPORT_HFILE` procedure.",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 22:08:45.744",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e3. Run the Manual Bulk Import Data Procedure\u003c/h3\u003e\n\u003cp\u003eNow we\u0026rsquo;re ready to bulk import our data. As in the previous example, we are bulk importing the customer table data for TPCH-100. This time we have pre-split the table so we will not need to sample the data before importing. The main difference in this call to \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e is that the last parameter, \u003ccode\u003eskipSampling\u003c/code\u003e, is now set to \u003ccode\u003etrue\u003c/code\u003e to indicate that we\u0026rsquo;ve already pre-split the data.\u003c/p\u003e\n\u003cp\u003eImport the data in this file by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph, which calls our \u003ccode\u003eBULK_IMPORT_HFILE\u003c/code\u003e procedure.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559687025939_1048948520",
      "id": "20190604-222345_571011902",
      "dateCreated": "2019-06-04 22:23:45.939",
      "dateStarted": "2019-06-05 22:08:45.745",
      "dateFinished": "2019-06-05 22:08:45.762",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\ncall SYSCS_UTIL.BULK_IMPORT_HFILE(\u0027DEV3\u0027, \u0027CUSTOMER_BULK_IMPORT_EXAMPLE2\u0027, null, \u0027s3a://splice-benchmark-data/flat/TPCH/100/customer\u0027, \u0027|\u0027, null, null, null, null, 0, \u0027/tmp\u0027, true, null, \u0027/tmp/TMP_HFILE\u0027, true);",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 17:51:23.927",
      "config": {
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "commonSetting": {},
              "mode": "table",
              "setting": {
                "table": {
                  "updated": false,
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "updated": false,
                    "names": {
                      "files": "string",
                      "failedRows": "string",
                      "rowsImported": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    }
                  },
                  "tableOptionValue": {
                    "showPagination": false,
                    "useFilter": false,
                    "showAggregationFooter": false
                  },
                  "initialized": false,
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]"
                }
              },
              "optionOpen": false,
              "height": 300.0
            }
          }
        },
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559691187111_-1974822490",
      "id": "20190604-233307_1183266826",
      "dateCreated": "2019-06-04 23:33:07.111",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### 4. Review Imported Data\n\nLets take a look at the data we just imported by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e *Run* button to run the next paragraph, which selects all of the data in the `CUSTOMER_BULK_IMPORT_EXAMPLE1` table.\n",
      "user": "anonymous",
      "dateUpdated": "2019-06-05 22:09:28.586",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e4. Review Imported Data\u003c/h3\u003e\n\u003cp\u003eLets take a look at the data we just imported by clicking the \u003cimg class\u003d\"inline\" src\u003d\"https://doc.splicemachine.com/zeppelin/images/zepPlayIcon.png\" alt\u003d\"Run Zep Paragraph Icon\"\u003e \u003cem\u003eRun\u003c/em\u003e button to run the next paragraph, which selects all of the data in the \u003ccode\u003eCUSTOMER_BULK_IMPORT_EXAMPLE1\u003c/code\u003e table.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559691745353_-1433523523",
      "id": "20190604-234225_1662630352",
      "dateCreated": "2019-06-04 23:42:25.353",
      "dateStarted": "2019-06-05 22:09:28.586",
      "dateFinished": "2019-06-05 22:09:28.599",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nSELECT * FROM DEV3.CUSTOMER_BULK_IMPORT_EXAMPLE2;",
      "user": "anonymous",
      "dateUpdated": "2019-06-10 18:03:06.721",
      "config": {
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "commonSetting": {},
              "mode": "table",
              "setting": {
                "table": {
                  "updated": false,
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "updated": false,
                    "names": {
                      "C_ACCTBAL": "string",
                      "C_COMMENT": "string",
                      "C_CUSTKEY": "string",
                      "C_PHONE": "string",
                      "C_NATIONKEY": "string",
                      "C_ADDRESS": "string",
                      "C_MKTSEGMENT": "string",
                      "C_NAME": "string"
                    }
                  },
                  "tableOptionValue": {
                    "showPagination": false,
                    "useFilter": false,
                    "showAggregationFooter": false
                  },
                  "initialized": false,
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]"
                }
              },
              "optionOpen": false,
              "height": 300.0
            }
          }
        },
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "editorSetting": {
          "editOnDblClick": false,
          "language": "sql"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559691773383_1772025010",
      "id": "20190604-234253_863481730",
      "dateCreated": "2019-06-04 23:42:53.383",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\nThe next notebook in this class, [*Transactions in Splice Machine*](/#/notebook/2ED6JR671), teaches you how transactions are processed in Splice Machine.\n",
      "user": "anonymous",
      "dateUpdated": "2019-05-31 17:44:30.123",
      "config": {
        "editorMode": "ace/mode/markdown",
        "enabled": false,
        "results": {},
        "editorHide": true,
        "fontSize": 9.0,
        "tableHide": false,
        "editorSetting": {
          "editOnDblClick": true,
          "completionSupport": false,
          "language": "markdown"
        },
        "colWidth": 12.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eWhere to Go Next\u003c/h2\u003e\n\u003cp\u003eThe next notebook in this class, \u003ca href\u003d\"/#/notebook/2ED6JR671\"\u003e\u003cem\u003eTransactions in Splice Machine\u003c/em\u003e\u003c/a\u003e, teaches you how transactions are processed in Splice Machine.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ],
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1559324570392_-1505826819",
      "id": "20190531-174250_1268073170",
      "dateCreated": "2019-05-31 17:42:50.392",
      "dateStarted": "2019-05-31 17:44:30.128",
      "dateFinished": "2019-05-31 17:44:30.154",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training /Advanced Developer/d. Bulk Data Loading",
  "id": "2ECANGRHX",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "splicemachine:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}