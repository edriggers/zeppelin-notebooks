{
  "paragraphs": [
    {
      "text": "%md\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" />\n\n# Crystal Ball\n\nThis notebook presents the *Crystal Ball* application, which is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. This app is presented in the following sections:\n\n* *Set Up Your JDBC Connection URL*\n* *Managing Your Timeline*\n* *Crystal Ball Application Requirements*\n* *Ingesting Advanced Shipping Notices - Transfer Orders*\n* *Using Timeline Tables*\n* *Applying the Crystal Ball*\n* *Machine Learning*\n\n## What the Crystal Ball Does\nYou can do the following with the *Crystal Ball* application:\n\n* Perform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments\n* Learn when shipments are likely to be late\n* Anticipate stock outs that are due to predicted late orders\n* Determine which customers or downstream orders are affected by anticipated stockouts.\n\nWhen supply chain managers have the crystal ball, they can:\n\n* Plan around stock outs\n* Warn down stream consumers so they can re-plan.\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:39.581",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" />\n<h1>Crystal Ball</h1>\n<p>This notebook presents the <em>Crystal Ball</em> application, which is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. This app is presented in the following sections:</p>\n<ul>\n  <li><em>Set Up Your JDBC Connection URL</em></li>\n  <li><em>Managing Your Timeline</em></li>\n  <li><em>Crystal Ball Application Requirements</em></li>\n  <li><em>Ingesting Advanced Shipping Notices - Transfer Orders</em></li>\n  <li><em>Using Timeline Tables</em></li>\n  <li><em>Applying the Crystal Ball</em></li>\n  <li><em>Machine Learning</em></li>\n</ul>\n<h2>What the Crystal Ball Does</h2>\n<p>You can do the following with the <em>Crystal Ball</em> application:</p>\n<ul>\n  <li>Perform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments</li>\n  <li>Learn when shipments are likely to be late</li>\n  <li>Anticipate stock outs that are due to predicted late orders</li>\n  <li>Determine which customers or downstream orders are affected by anticipated stockouts.</li>\n</ul>\n<p>When supply chain managers have the crystal ball, they can:</p>\n<ul>\n  <li>Plan around stock outs</li>\n  <li>Warn down stream consumers so they can re-plan.</li>\n</ul>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139913_292026853",
      "id": "20170621-041621_785608971",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:49:25.277",
      "dateFinished": "2018-11-30 22:49:25.308",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Set Up Your JDBC Connection URL\n\nTo connect to your Splice Machine database, you need to configure the URL you'll be connecting to via JDBC. \n\nFor this class, you can simply use the `defaultJDBCURL` assignment in the next paragraph. When running on a cluster, you can copy and paste the JDBC URL you'll find displayed at the bottom right of your cluster dashboard.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:51.409",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Set Up Your JDBC Connection URL</h2>\n<p>To connect to your Splice Machine database, you need to configure the URL you&rsquo;ll be connecting to via JDBC. </p>\n<p>For this class, you can simply use the <code>defaultJDBCURL</code> assignment in the next paragraph. When running on a cluster, you can copy and paste the JDBC URL you&rsquo;ll find displayed at the bottom right of your cluster dashboard.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542765401625_-1467740243",
      "id": "20181120-175641_472076393",
      "dateCreated": "2018-11-20 17:56:41.625",
      "dateStarted": "2018-11-30 22:49:29.864",
      "dateFinished": "2018-11-30 22:49:29.873",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n  val defaultJDBCURL = \"\"\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin\"\"\"\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 21:57:48.464",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "JDBCurl": "jdbc:splice://localhost:1527/splicedb;user=splice;password=admin"
        },
        "forms": {
          "JDBCurl": {
            "type": "TextBox",
            "name": "JDBCurl",
            "displayName": "JDBCurl",
            "defaultValue": "jdbc:splice://localhost:1527/splicedb;user=splice;password=admin;useSpark=true",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139914_897915583",
      "id": "20170622-063514_1166002275",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Managing the Timeline\nThe code in the next paragraph manages the timeline:",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:00.261",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Managing the Timeline</h2>\n<p>The code in the next paragraph manages the timeline:</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542765659638_-1071926324",
      "id": "20181120-180059_1459449180",
      "dateCreated": "2018-11-20 18:00:59.638",
      "dateStarted": "2018-11-30 21:58:12.470",
      "dateFinished": "2018-11-30 21:58:12.477",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Timeline  Code",
      "text": "%spark\nimport java.sql.{Connection,Timestamp}\nimport java.util.Date\nimport com.splicemachine.si.api.txn.WriteConflict\nimport org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\nimport com.splicemachine.spark.splicemachine._\n    \n  val table = \"TimeLine_Int\"\n  val schema = \"TimeLine\"\n  val internalTN = schema + \".\" + table\n  val startOfTimeStr = \"1678-01-01 00:00:00\"\n  val endOfTimeStr = \"2261-12-31 00:00:00\"\n  val startOfTime = java.sql.Timestamp.valueOf(startOfTimeStr)\n  val endOfTime = java.sql.Timestamp.valueOf(endOfTimeStr)\n  val MAX_RETRIES: Integer = 2\n\n  val SQL_ID = 1\n  val SQL_ST = 2\n  val SQL_ET = 3\n  val SQL_VAL = 4\n  val DF_ID = 0\n  val DF_ST = 1\n  val DF_ET = 2\n  val DF_VAL = 3\n  \n  val columnsWithPrimaryKey: String  = \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n  val columnsWithoutPrimaryKey = \"(\" + \"Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint \" + \")\"\n  val primaryKeys = Seq(\"Timeline_ID, ST\")\n  val columnsInsertString = \"(\" + \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Val\" + \") \"\n  val columnsSelectString = \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Value\"\n  val columnsInsertStringValues = \"values (?,?,?,?)\"\n\n\n  /* (t1<=ST and t2>ST) or (t1>ST and t1<ET)  (t1 t2 t1 t1 )*/\n  val overlapCondition = \"where Timeline_Id = ? and ((ST >=? and ST <?) or ((ST < ?) and (ET > >?)))\"\n\n\n  val internalOptions = Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> internalTN,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n  )\n\n  val internalJDBCOptions = new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(internalOptions)\n  val splicemachineContext =  new com.splicemachine.spark.splicemachine.SplicemachineContext(defaultJDBCURL)\n\n\n\n  /**\n    *\n    * createTimeline (table)\n    *\n    * @param table table name of timeline\n    * @return\n    */\n  def createTimeline(table: String, columnsWithPrimaryKey: String , internalJDBCOptions: JDBCOptions = internalJDBCOptions ): Unit = {\n    val conn = JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    if (splicemachineContext.tableExists(table)){\n      conn.createStatement().execute(\"drop table \" + table)\n    }\n    conn.createStatement().execute(\"create table \" + table + columnsWithPrimaryKey)\n  }\n  \n  \n  \n  /**\n    *\n    * initialize (id startOfTime endOfTime value)\n    *\n    * @param table table name of timeline\n    * @param id id of timeline\n    * @param value initial value of timeline\n    * @return\n    */\n def initialize(table: String, id: Integer, value: Integer, columnsInsertString : String = columnsInsertString ,columnsInsertStringValues :String = columnsInsertStringValues  , internalJDBCOptions :JDBCOptions = internalJDBCOptions ): Unit = {\n    val conn = JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    val start: Timestamp = startOfTime\n    val end: Timestamp = endOfTime\n    try {\n      var ps = conn.prepareStatement(\"delete from \" + table + \" where timeline_id = \" + id)\n      ps.execute()\n      ps = conn.prepareStatement(\"insert into \" + table + columnsInsertString + columnsInsertStringValues)\n      ps.setInt(SQL_ID, id)\n      ps.setTimestamp(SQL_ST, start)\n      ps.setTimestamp(SQL_ET, end)\n      ps.setInt(SQL_VAL, value)\n      ps.execute()\n    } finally {\n      conn.close()\n    }\n  }\n\n  val CHANGE_AT_ST = 0\n  val CHANGE_AT_ET = 1\n  val CHANGE_BETWEEN_ST_ET =2\n  \n\n  /**\n    * splitMiddle - The new delta interval is subsumed by one interval.\n    *\n    *  ST------------ET\n    *      t1---t2         ==>   ST---t1 t1----t2 t2----ET\n    *\n    * Change the original interval to end at the start of the new delta interval\n    * Create a new record for the delta and apply the delta value\n    * Create a new record for the interval from the delta to the end of the original interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    *\n    */\n    \n                \n  def splitMiddle(id: Integer,\n                  t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                  delta: Long,\n                  persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT')\")\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldET = df.first().getTimestamp(DF_ET)\n\n      /* Update containing interval to be the begin split */\n      val updatedDF = df\n        .filter(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* calculate persistence */\n      val firstValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal + delta\n        case _                     => 0\n      }\n\n      /* Insert the two new splits */\n      /* Note - the second new split will have delta added\n\t\tin the persistAfter method\n       */\n      val newDF = sqlContext.createDataFrame(Seq(\n        (id, t1, t2, firstValue),\n        (id, t2, oldET, oldVal)))\n        .toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n\n  /***\n    * \tsplitAtEnd - Delta overlaps beginning of interval.\n    *\n    *         ST------ET\n    *      t1---t2         ==>  ST---t2 t2----ET\n    *\n    * Change the interval to end at the end of the delta then add a split from end of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n    \n     \n  def splitAtEnd(id: Integer,\n                 t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                 delta: Long,\n                 persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"\"\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT') AND ST < to_utc_timestamp('$t2','GMT')\"\"\")\n\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldST = df.first().getTimestamp(DF_ST)\n      var oldET = df.first().getTimestamp(DF_ET)\n      /* Update overlapping interval to be the begin split */\n\n      /* calculate persistence */\n      /* Note - the second new split will have delta added\n          in the persistAfter method if required\n */\n      val firstValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal + delta\n        case _                     => 0\n      }\n\n      val updatedDF = df\n\t    .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT') AND ST < to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t2))\n      .withColumn(\"VAL\", lit(firstValue))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* Insert a new split after the delta */\n      val newDF = sqlContext.createDataFrame(Seq((id, t2, oldET, oldVal))).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n  /**\n    * \tsplitAtStart - Delta overlaps end of interval.\n    *\n    *         ST-----ET\n    *            t1------t2         ==>    ST---t1 t1---ET\n    *\n    * Change the interval to end at the start of the delta then add a split from beginning of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n   \n  def splitAtStart(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long, persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND \" +\n                s\"ET < to_utc_timestamp('$t2','GMT') AND ET > to_utc_timestamp('$t1','GMT')\")\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldST = df.first().getTimestamp(DF_ST)\n      var oldET = df.first().getTimestamp(DF_ET)\n\n      /* calculate persistence */\n      val newValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal\n        case _                     => 0\n      }\n      /* Update overlapping interval to be the begin split */\n      val updatedDF = df\n        .filter(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET < to_utc_timestamp('$t2','GMT') AND ET > to_utc_timestamp('$t1','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      .withColumn(\"VAL\", lit(newValue))\n      splicemachineContext.update(updatedDF, internalTN)\n      \n      /* Insert a new split */\n      val newDF = sqlContext.createDataFrame(Seq(\n        (id, t1, oldET, oldVal)\n      )).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n }\n                   \n    \n  /***\n    *   changeNoSplit - Handles all intervals contained by delta\n    *\n    *           ST-----ET\n    *     t1---------------t2\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def changeNoSplit(id: Integer,\n                    t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                    delta: Long,\n                    persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n           \n    val df = sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET <= to_utc_timestamp('$t2','GMT')\")\n\n    /* Calculate persistence */\n    val increment: Long = persistence match {\n      case CHANGE_AT_ST          => delta\n      case CHANGE_AT_ET          => 0\n      case CHANGE_BETWEEN_ST_ET  => delta\n      case _                     => 0\n    }\n    val updatedDF = df\n      .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET <= to_utc_timestamp('$t2','GMT')\")\n      .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + increment)\n\n    splicemachineContext.update(updatedDF, internalTN)\n  }\n\n  /***\n    *   persistAfter - changes the values for all intervals after delta\n    *\n    *     t1---------------t2  ST-----ET\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def persistAfter(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long,\n                   persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n\n    /* Persist delta after new splits if necesary */\n    if (persistence != CHANGE_BETWEEN_ST_ET) {\n      val persistDF = sqlContext.read.options(internalOptions).splicemachine\n        .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + delta)\n      splicemachineContext.update(persistDF, internalTN)\n    }\n  }\n\n  /** *\n    * update - increases/decreases the value for the interval\n    * from the start, end or during the interval\n    *\n    * @param table       - the name of the timeline table\n    * @param id          - the id of the timeline to update\n    * @param t1          - the start of new delta\n    * @param t2          - the end of the new delta\n    * @param delta       - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                    CHANGE_AT_ET persists delta from t2 onwards\n    *                    CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n\n  def update(table: String,\n             id: Integer,\n             t1: Timestamp, t2: Timestamp,\n             delta: Long,\n             persistence: Int): Unit = {\n                \n\n   val intOptions = Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> table,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n  )\n    changeNoSplit(id, t1, t2, delta, persistence, table,intOptions )\n    splitAtStart(id, t1, t2, delta, persistence, table,intOptions)\n    splitMiddle(id, t1, t2, delta, persistence, table,intOptions)\n    splitAtEnd(id, t1, t2, delta, persistence, table,intOptions)\n    persistAfter(id, t1, t2, delta, persistence, table,intOptions)\n  }\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:24.318",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139915_1318983996",
      "id": "20170622-231413_1135446195",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Crystal Ball Application Requirements\n\nThe *Crystal Ball* app was built to meet these requirements:\n\n* Streaming inventory movements - ASN - EDI856\n* Streaming ancilary data like real-time weather\n* Needle-in-Haystack OLTP queries and range scans for ATP\n* ACID Transactions for concurrent inventory changes\n* OLAP for analysis and feature engineering\n* OLAP for inventory projections\n* Machine Learning\n* UI for Collaboration\n\nSplice Machine has all these components pre-integrated and optimized",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:29.638",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Crystal Ball Application Requirements</h2>\n<p>The <em>Crystal Ball</em> app was built to meet these requirements:</p>\n<ul>\n  <li>Streaming inventory movements - ASN - EDI856</li>\n  <li>Streaming ancilary data like real-time weather</li>\n  <li>Needle-in-Haystack OLTP queries and range scans for ATP</li>\n  <li>ACID Transactions for concurrent inventory changes</li>\n  <li>OLAP for analysis and feature engineering</li>\n  <li>OLAP for inventory projections</li>\n  <li>Machine Learning</li>\n  <li>UI for Collaboration</li>\n</ul>\n<p>Splice Machine has all these components pre-integrated and optimized</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139916_-1935319884",
      "id": "20170621-041831_354747046",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:35:52.088",
      "dateFinished": "2018-11-30 22:35:52.100",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Ingesting Advanced Shipping Notices - Transfer Orders\n\nYou can copy and paste the data ingestion calls shown below; this data was generated by a supply-chain simulator notebook (URL). Here are some notes about this:\n\n* The simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates.\n* The generator randomly selects features for the transfer orders. \n* The files below reflect the state of the database after the simulation runs. The orders and change orders are independent files that can be loaded separately.\n* The simulation runs are cumulative, which means demo has the inventory timelines for the test data and the train data. \n\nTo use the demo data, you need to: \n\n1. Load, train, and test for orders and change orders\n2. Load the demo inventory timeline file.\n\nThe paragraphs in this section contain the code that takes care of these tasks.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:34.027",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Ingesting Advanced Shipping Notices - Transfer Orders</h2>\n<p>You can copy and paste the data ingestion calls shown below; this data was generated by a supply-chain simulator notebook (URL). Here are some notes about this:</p>\n<ul>\n  <li>The simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates.</li>\n  <li>The generator randomly selects features for the transfer orders.</li>\n  <li>The files below reflect the state of the database after the simulation runs. The orders and change orders are independent files that can be loaded separately.</li>\n  <li>The simulation runs are cumulative, which means demo has the inventory timelines for the test data and the train data.</li>\n</ul>\n<p>To use the demo data, you need to: </p>\n<ol>\n  <li>Load, train, and test for orders and change orders</li>\n  <li>Load the demo inventory timeline file.</li>\n</ol>\n<p>The paragraphs in this section contain the code that takes care of these tasks.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139916_1177726344",
      "id": "20170621-044326_1460127976",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:39:21.380",
      "dateFinished": "2018-11-30 22:39:21.396",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initialize",
      "text": "%spark\n\nz.run(\"20170622-063514_1166002275\"); // JDBC URL\nz.run(\"20170622-231413_1135446195\"); // Timeline Code\nz.run(\"20170622-222153_977899468\"); // DDL\nz.run(\"20170623-174025_718327456\"); // Load Data\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 18:16:19.969",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-243689402",
      "id": "20170628-085245_2111524765",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ncreate schema TIMELINE;\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-1588197916",
      "id": "20170703-142111_1098530498",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Schema",
      "text": "%splicemachine\n\ndrop table IF EXISTS  TIMELINE.TRANSFERORDERS;\ndrop table IF EXISTS  TIMELINE.TO_DELIVERY_CHG_EVENT;\ndrop table IF EXISTS  TIMELINE.TIMELINE_INT;\ndrop table IF EXISTS TIMELINE.STOCKOUTS;\n\n\n\ncreate table TIMELINE.TRANSFERORDERS(\n    TO_ID   BIGINT,\n    PO_ID   BIGINT,\n    SHIPFROM BIGINT,\n    SHIPTO  BIGINT,\n    SHIPDATE TIMESTAMP,\n    DELIVERYDATE TIMESTAMP,\n    MODDELIVERYDATE TIMESTAMP,\n    SOURCEINVENTORY BIGINT,\n    DESTINATIONINVENTORY BIGINT,\n    QTY BIGINT,\n    SUPPLIER BIGINT,\n    ASN VARCHAR(100),\n    CONTAINER VARCHAR(100),\n    TRANSPORTMODE SMALLINT,\n    CARRIER BIGINT,\n    FROMWEATHER SMALLINT,\n    TOWEATHER SMALLINT,\n    LATITUDE  DOUBLE,\n    LONGITUDE DOUBLE,\n    primary key (TO_ID)\n    );\n\ncreate index TIMELINE.TOSTIDX on TRANSFERORDERS (\n    ShipDate,\n    TO_Id\n );\n \n create index TIMELINE.TOETIDX on TRANSFERORDERS (\n    Deliverydate,\n    TO_Id\n );\n\ncreate table TIMELINE.TO_DELIVERY_CHG_EVENT(\n    TO_event_Id bigint,\n    TO_Id bigint ,\n    ShipFrom bigint,\n    ShipTo bigint,\n    OrgDeliveryDate timestamp,\n    newDeliveryDate timestamp,\n    Supplier varchar(100) ,\n    TransportMode smallint ,\n    Carrier bigint ,\n    Fromweather smallint,\n    ToWeather smallint,\n    primary key (TO_event_Id)\n    );\n    \ncreate table TIMELINE.TIMELINE_INT(\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    ET          TIMESTAMP,\n    VAL         BIGINT,\n    primary key (Timeline_Id, ST)\n    );\n    \ncreate table TIMELINE.STOCKOUTS(\n    TO_ID   BIGINT,\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    primary key (TO_ID,ST)\n    );\n    \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-1902551066",
      "id": "20170622-222153_977899468",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Train Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/train_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/data_0623/train_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/train_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 09:59:01.663",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          },
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          },
          "2": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139918_798437646",
      "id": "20170623-174025_718327456",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Test Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/test_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/data_0623/test_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/test_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139919_29713688",
      "id": "20170628-222352_2120811555",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Demo Data",
      "text": "%splicemachine\n\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/demo_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/demo_0623/demo_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/demo_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139919_1122296054",
      "id": "20170628-222451_440347172",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Transfer Orders",
      "text": "%splicemachine\nselect * from timeline.transferorders\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:42.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TO_ID": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "304"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139920_-22590724",
      "id": "20170623-175231_773807313",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Using Timeline Tables\n\nTimelines are a relational representation of temporal data for AI applications. \n\nA timeline table contains a collection of timelines, each with a unique id. Every row represents: `TIMELINE_ID = VAL @ [ST ET]` meaning the variable denoted by the id has the value over that time interval\n\nSome notes about Timelines:\n\n* Timelines record historical, present and future values.\n* Timelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.\n* Timelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.\n\nFor example, you have to make sure that when you move an order, the decrement to the source inventory changes atomically with the change to the destination inventory.\n\nThis code paragraphs in this section demonstrate how to use timeline tables for tracking inventory, finding stock-outs, and finding ATP inventory.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:08:31.459",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Using Timeline Tables</h2>\n<p>Timelines are a relational representation of temporal data for AI applications. </p>\n<p>A timeline table contains a collection of timelines, each with a unique id. Every row represents: <code>TIMELINE_ID = VAL @ [ST ET]</code> meaning the variable denoted by the id has the value over that time interval</p>\n<p>Some notes about Timelines:</p>\n<ul>\n  <li>Timelines record historical, present and future values.</li>\n  <li>Timelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.</li>\n  <li>Timelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.</li>\n</ul>\n<p>For example, you have to make sure that when you move an order, the decrement to the source inventory changes atomically with the change to the destination inventory.</p>\n<p>This code paragraphs in this section demonstrate how to use timeline tables for tracking inventory, finding stock-outs, and finding ATP inventory.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139922_1998505180",
      "id": "20170621-050328_679054277",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:44:42.724",
      "dateFinished": "2018-11-30 22:44:42.741",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Tracking Inventory As Timelines",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere TIMELINE_ID = ${inv=200}\norder by TIMELINE.TIMELINE_INT.ST;",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:36:40.824",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false,
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "ST",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 3.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": "200",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139922_1831631662",
      "id": "20170621-052218_96471785",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:36:40.865",
      "dateFinished": "2018-11-30 22:36:41.163",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Stock Outs",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere timeline_id = ${inv= 100} AND val < 0 \norder by timeline.timeline_int.st;",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 132.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TIMELINE_ID": "string",
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "500"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139923_-2084294906",
      "id": "20170621-052618_1306506874",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "ATP",
      "text": "%splicemachine\nselect VAL AS Available from timeline.timeline_int\nwhere timeline_id = ${inv= 100} \nAND ST <= TIMESTAMP('${Time=2017-05-05 00:00:00.0}')  \nAND ET > TIMESTAMP('${Time=2017-05-05 00:00:00.0}')",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 90.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "AVAILABLE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "100",
          "Time": "2016-05-10 00:00:00.0"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false
          },
          "Time": {
            "type": "TextBox",
            "name": "Time",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139923_-2110959174",
      "id": "20170621-053013_888862556",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Applying the Crystal Ball\n\nYou can apply the crystal ball to perform a *What-If* on any predicted late shipment. By moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.\n\nThe code paragraphs in this section create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only. \n\nAfter that, we perform a *What-If* simulation for a specified order with a delay",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:08:52.889",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Applying the Crystal Ball</h2>\n<p>You can apply the crystal ball to perform a <em>What-If</em> on any predicted late shipment. By moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.</p>\n<p>The code paragraphs in this section create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only. </p>\n<p>After that, we perform a <em>What-If</em> simulation for a specified order with a delay</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139924_1939899989",
      "id": "20170621-054855_1620710812",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-12-01 07:08:50.569",
      "dateFinished": "2018-12-01 07:08:50.575",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Prediction Table",
      "text": "%splicemachine\nDrop table IF EXISTS TIMELINE.PREDICTIONS;\ncreate table TIMELINE.PREDICTIONS(\n    TO_ID   BIGINT,\n    LatenessBin1 DOUBLE,\n    LatenessBin2 DOUBLE,\n    LatenessBin3 DOUBLE,\n    LatenessBin4 DOUBLE,\n    LatenessBin5 DOUBLE,\n    LatenessBin6 DOUBLE,\n    LatenessBin7 DOUBLE,\n    LatenessBin8 DOUBLE,\n    LatenessBin9 DOUBLE,\n    LatenessBin10 DOUBLE,\n    primary key (TO_ID)\n    );\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:37:11.406",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139924_1899668217",
      "id": "20170623-181559_517039267",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initializing Predictions Randomly",
      "text": "%splicemachine\ninsert into TIMELINE.PREDICTIONS (\n    TO_ID, \n    LatenessBin1,\n    LatenessBin2,\n    LatenessBin3,\n    LatenessBin4\n    )\n    SELECT TO_ID, RANDOM(), RANDOM(), RANDOM(), RANDOM() \n    From TIMELINE.TRANSFERORDERS\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139925_-1273981434",
      "id": "20170623-182513_1199711298",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Predictions",
      "text": "%splicemachine\nSELECT TP.TO_ID, TP.LatenessBin1 as ZERO_DAYLATE, TP.LatenessBin2 as ONE_DAYLATE, TP.LatenessBin3 as FIVE_DAYLATE,  TP.LatenessBin4 as TEN_DAYLATE, timeline.transferorders.*    FROM timeline.predictions TP  LEFT OUTER JOIN timeline.transferorders  ON TP.to_id = timeline.transferorders.to_id\nwhere TIMESTAMP('${begin =2017-05-05 00:00:00.0}') >= timeline.transferorders.deliverydate \nAND TIMESTAMP('${end =2017-05-05 00:00:00.0}') >timeline.transferorders.deliverydate \nAND TP.LatenessBin3 >= ${threshold = .75}",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TO_ID": "string",
                      "ZERO_DAYLATE": "string",
                      "ONE_DAYLATE": "string",
                      "FIVE_DAYLATE": "string",
                      "TEN_DAYLATE": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "end": "2017-05-05 00:00:00.0",
          "threshold": ".5",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "type": "TextBox",
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          },
          "threshold": {
            "type": "TextBox",
            "name": "threshold",
            "defaultValue": " .75",
            "hidden": false
          },
          "begin": {
            "type": "TextBox",
            "name": "begin",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139927_-96827937",
      "id": "20170714-183906_14590483",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Perform a *What-If* Simulation for a Specified Order with a Delay\n\nPick an order that may be delayed by a specified number of days to see what orders may result in stock out situation because of the delay.\n\nFirst, all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.\n\nNext, the delay is simulated, inventory calculations are made, and the Orders that are sourced from the Destination are again checked for stockout situation.\n\nSince these *what-if* calculations are done on a temporary table, the actual data is not impacted.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:09:14.540",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Perform a <em>What-If</em> Simulation for a Specified Order with a Delay</h3>\n<p>Pick an order that may be delayed by a specified number of days to see what orders may result in stock out situation because of the delay.</p>\n<p>First, all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.</p>\n<p>Next, the delay is simulated, inventory calculations are made, and the Orders that are sourced from the Destination are again checked for stockout situation.</p>\n<p>Since these <em>what-if</em> calculations are done on a temporary table, the actual data is not impacted.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139928_-1737510532",
      "id": "20170716-211650_1813160194",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:53:25.728",
      "dateFinished": "2018-11-30 22:53:25.753",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%angular\n\n<form class=\"form-inline\">\n  <div class=\"form-group\">\n   <h5>Simulate Late Order </h5>\n    <label for=\"orderFieldId\"> Order ID : </label>\n    <input type=\"text\" class=\"form-control\" id=\"orderFieldId\" placeholder= Order id ...\" ng-model=\"orderId\"></input>\n    <label for=\"delayFieldId\">Delay in Days: </label>\n    <input type=\"text\" class=\"form-control\" id=\"delayFieldId\" placeholder= Delay Days ...\" ng-model=\"delayDays\"></input>\n      <button type=\"submit\" class=\"btn btn-primary\" ng-click=\"z.angularBind('orderId',orderId,'20170625-202310_651912174');z.angularBind('delayDays',delayDays,'20170625-202310_651912174'); z.runParagraph('20170625-202310_651912174')\"> Run What-If</button>\n  </div>\n\n</form>\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "ANGULAR",
            "data": "<form class=\"form-inline\">\n  <div class=\"form-group\">\n   <h5>Simulate Late Order </h5>\n    <label for=\"orderFieldId\"> Order ID : </label>\n    <input type=\"text\" class=\"form-control\" id=\"orderFieldId\" placeholder= Order id ...\" ng-model=\"orderId\"></input>\n    <label for=\"delayFieldId\">Delay in Days: </label>\n    <input type=\"text\" class=\"form-control\" id=\"delayFieldId\" placeholder= Delay Days ...\" ng-model=\"delayDays\"></input>\n      <button type=\"submit\" class=\"btn btn-primary\" ng-click=\"z.angularBind('orderId',orderId,'20170625-202310_651912174');z.angularBind('delayDays',delayDays,'20170625-202310_651912174'); z.runParagraph('20170625-202310_651912174')\"> Run What-If</button>\n  </div>\n\n</form>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139928_14213738",
      "id": "20170627-003424_154469379",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If Simulation Code",
      "text": "%spark\n\nval splicemachineContext = new SplicemachineContext(defaultJDBCURL)\nval InventoryTable = \"timeline.timeline_int\"\nval TOTable = \"timeline.transferorders\"\nval stockoutTable = \"timeline.STOCKOUTS\"\nval CHANGE_AT_ST = 0\nval CHANGE_AT_ET = 1\nval tempTableColsWithPKey : String  = \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n\ndef createTempInvTable (smContext :SplicemachineContext, source : Long, dest : Long): String = {\n    \n    var tempTable =\"Timeline.\"+  \"TEMP_INV_\" + org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n            while(smContext.tableExists( tempTable))\n                tempTable =\"Timeline.\"+  \"TEMP_INV_\" +org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n    \n    \n    \n    val tempOptions = Map(\n         org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> tempTable,\n        org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n    )\n\n    val tempJDBCOptions = new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(tempOptions)\n\n    \n    val conn = JdbcUtils.createConnectionFactory(tempJDBCOptions)()\n    try {\n    conn.createStatement().execute(\"create table \" + tempTable + tempTableColsWithPKey)\n    } finally {\n      conn.close()\n    }\n    \n    //insert \n    val stmt = \"select *  FROM timeline.timeline_int  WHERE Timeline_Id  in ( \" + source + \", \"+ dest +\")\"\n    val timesDf = splicemachineContext.df(stmt)\n    smContext.insert(timesDf,tempTable )\n   tempTable\n \n    \n}\n\ndef whatif(smContext :SplicemachineContext,\n            tempInvTable: String,\n           source: Integer,\n           destination: Integer,\n           shippingDate: Timestamp,\n           deliveryDate: Timestamp,\n           newDeliveryDate : Timestamp,\n           qty: Long,\n           retryCount: Integer = 0,\n           revertFlag: Boolean): Unit = {\n\n        val conn: Connection = smContext.getConnection()\n         try {\n          conn.setAutoCommit(false) //TBD - Need to set to false when DBAAS-570 is resolved\n          update(tempInvTable, source, shippingDate, deliveryDate,  qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, deliveryDate,  -qty, CHANGE_AT_ET)\n          update(tempInvTable, source, shippingDate, newDeliveryDate,  -qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, newDeliveryDate,  qty, CHANGE_AT_ET)\n          conn.commit()\n          \n        }\n        catch {\n          case exp: WriteConflict => {\n            conn.rollback()\n            conn.setAutoCommit(true)\n            if (retryCount < MAX_RETRIES) {\n              println(\"Retrying create TO\" + source + \" \" + destination + \" \" + shippingDate + \" \" + deliveryDate + \" \" + qty + \" \" + retryCount + 1)\n              whatif(smContext, tempInvTable,source, destination, shippingDate, deliveryDate, newDeliveryDate, qty, retryCount + 1, revertFlag)\n            }\n            else {\n              // put code here to handle too many retries\n            }\n          }\n          case e: Throwable => println(s\"Got some other kind of exception: $e\")\n        }\n        finally {\n          conn.setAutoCommit(true)\n        }\n      }\n      \n      \n  // Will need to copy the inventory table so that what-if is not visible to others\n\n  val transferOrdersTable = Map(\n    JDBCOptions.JDBC_TABLE_NAME -> \"Timeline.TransferOrders\",\n    JDBCOptions.JDBC_URL -> defaultJDBCURL\n    ) \n  val orderid = z.angular(\"orderId\").toString.toLong\n  val q = s\"select *  FROM timeline.transferorders WHERE to_id = $orderid\"\n  val order = splicemachineContext.df(q)\n  \n   val days = z.angular(\"delayDays\").toString.toInt\n \n  if(order.count > 0 && days > 0) {\n    //  val days: Int = 5\n      val source = order.first().getAs(\"SOURCEINVENTORY\").asInstanceOf[Long]\n      val dest = order.first().getAs(\"DESTINATIONINVENTORY\").asInstanceOf[Long]\n      val ship = order.first().getAs(\"SHIPDATE\").asInstanceOf[Timestamp]\n      val delivery = order.first().getAs(\"DELIVERYDATE\").asInstanceOf[Timestamp]\n      val qty = order.first().getAs(\"QTY\").asInstanceOf[Long]\n      val newDelivery =new Timestamp( new org.joda.time.DateTime (delivery).plusDays(days).getMillis())\n      \n      //Populate stockouts before What If\n      \n     val queryBefore = s\"\"\"SELECT t.to_id, i.ST, i.timeline_id FROM $InventoryTable i  , $TOTable t\n        WHERE i.timeline_id = $dest\n        AND t.sourceinventory = i.timeline_id\n        AND val < 0\n        AND i.ST <=  t.shipdate\n        AND  t.shipdate < i.ET\n        ORDER BY i.ST\"\"\"\n    \n       println(s\"q=$queryBefore\")\n      val stockOutsBefore = splicemachineContext.df(queryBefore)\n  \n      splicemachineContext.insert(stockOutsBefore, stockoutTable)\n      z.run(\"20170621-055239_1661420434\")\n      z.run(\"20170628-152508_1831563439\")\n      \n      val tempInventoryTable = createTempInvTable(splicemachineContext,source,dest)\n      \n      whatif(splicemachineContext,tempInventoryTable,source.toInt, dest.toInt, ship, delivery, newDelivery, qty, days, false)\n      \n      val destInvCol = TOTable + \".destinationinventory \"\n      val timelineIdCol = tempInventoryTable + \".timeline_id \"\n      val toIdCol = TOTable + \".to_id \"\n      val stCol = tempInventoryTable + \".ST \"\n      val etCol = tempInventoryTable + \".ET \"\n      val delDateCol = TOTable + \".deliverydate \"\n      val shipDateCol =  TOTable + \".shipdate \"\n      val sourceInvCol = TOTable + \".sourceinventory \"\n      val latCol = TOTable + \".latitude \"\n      val longCol = TOTable + \".longitude \"\n      val srcWeatherCol = TOTable + \".fromweather \"\n      val destWeatherCol = TOTable + \".toweather \"\n      /*\n      val query = s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n                        WHERE $timelineIdCol = $dest\n                        AND $destInvCol = $timelineIdCol\n                        AND val < 0\n                        AND $stCol >= $delDateCol\n                        ORDER BY $stCol\"\"\"\n                        println(s\"q=$query\")\n                        */\n   \n     val query = s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n        WHERE $timelineIdCol = $dest\n        AND $sourceInvCol = $timelineIdCol\n        AND val < 0\n        AND $stCol <=  $shipDateCol\n        AND  $shipDateCol < $etCol\n        ORDER BY $stCol\"\"\"\n    \n    println(s\"q=$query\")\n      val stockOuts = splicemachineContext.df(query)\n  \n     // whatif(source.toInt, dest.toInt, ship, delivery, newDelivery, qty, 5, true) // undo what-if \n      splicemachineContext.insert(stockOuts, stockoutTable)\n      z.run(\"20170716-165322_7991113\")\n      z.run(\"20170628-152508_1831563439\")\n     // splicemachineContext.dropTable(tempInventoryTable)\n   } else {\n    println(\" NO ORDERS FOUND FOR ORDER ID \" + orderid)\n   }\n  \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:46:54.989",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "orderid": "19"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nsplicemachineContext: com.splicemachine.spark.splicemachine.SplicemachineContext = com.splicemachine.spark.splicemachine.SplicemachineContext@4adcbaa0\n\nInventoryTable: String = timeline.timeline_int\n\nTOTable: String = timeline.transferorders\n\nstockoutTable: String = timeline.STOCKOUTS\n\nCHANGE_AT_ST: Int = 0\n\nCHANGE_AT_ET: Int = 1\n\ntempTableColsWithPKey: String = (Timeline_Id bigint, ST timestamp, ET timestamp, Val bigint, primary key (Timeline_ID, ST))\n\ncreateTempInvTable: (smContext: com.splicemachine.spark.splicemachine.SplicemachineContext, source: Long, dest: Long)String\n\nwhatif: (smContext: com.splicemachine.spark.splicemachine.SplicemachineContext, tempInvTable: String, source: Integer, destination: Integer, shippingDate: java.sql.Timestamp, deliveryDate: java.sql.Timestamp, newDeliveryDate: java.sql.Timestamp, qty: Long, retryCount: Integer, revertFlag: Boolean)Unit\n\ntransferOrdersTable: scala.collection.immutable.Map[String,String] = Map(dbtable -> Timeline.TransferOrders, url -> jdbc:splice://localhost:1527/splicedb;user=splice;password=admin)\n\norderid: Long = 4\n\nq: String = select *  FROM timeline.transferorders WHERE to_id = 4\n\norder: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [TO_ID: bigint, PO_ID: bigint ... 17 more fields]\n\ndays: Int = 5\nq=SELECT t.to_id, i.ST, i.timeline_id FROM timeline.timeline_int i  , timeline.transferorders t\n        WHERE i.timeline_id = 900\n        AND t.sourceinventory = i.timeline_id\n        AND val < 0\n        AND i.ST <=  t.shipdate\n        AND  t.shipdate < i.ET\n        ORDER BY i.ST\nq=SELECT timeline.transferorders.to_id , Timeline.TEMP_INV_BZTTCS.ST , Timeline.TEMP_INV_BZTTCS.timeline_id  FROM Timeline.TEMP_INV_BZTTCS , timeline.transferorders\n        WHERE Timeline.TEMP_INV_BZTTCS.timeline_id  = 900\n        AND timeline.transferorders.sourceinventory  = Timeline.TEMP_INV_BZTTCS.timeline_id \n        AND val < 0\n        AND Timeline.TEMP_INV_BZTTCS.ST  <=  timeline.transferorders.shipdate \n        AND  timeline.transferorders.shipdate  < Timeline.TEMP_INV_BZTTCS.ET \n        ORDER BY Timeline.TEMP_INV_BZTTCS.ST \n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139929_1255247635",
      "id": "20170625-202310_651912174",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs? - Before",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id = Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id =  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id =  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST =  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:09:55.112",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11.0,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                },
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string",
                      "TO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "QTY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "SOURCEINVENTORY": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "SUPPLIER": "string",
                      "CARRIER": "string",
                      "TRANSPORTMODE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139929_-1800321072",
      "id": "20170621-055239_1661420434",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs?  - After",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id = Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id =  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id =  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST =  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:02.351",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11.0,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                },
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string",
                      "TO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "QTY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "SOURCEINVENTORY": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "SUPPLIER": "string",
                      "CARRIER": "string",
                      "TRANSPORTMODE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139930_1917140175",
      "id": "20170716-165322_7991113",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ndelete from timeline.stockouts where to_id >0;",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 10"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139930_457417555",
      "id": "20170628-152508_1831563439",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Weather",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:21.526",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 10.0,
                    "aggr": "sum"
                  },
                  "xAxis": {
                    "name": "FROMWEATHER",
                    "index": 9.0,
                    "aggr": "sum"
                  },
                  "group": {
                    "name": "CARRIER",
                    "index": 8.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "FROMWEATHER",
                  "index": 9.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "TOWEATHER",
                  "index": 10.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "NEWDELIVERYDATE",
                  "index": 5.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "98426393"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139931_1644037477",
      "id": "20170623-175239_660149064",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Route",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "SHIPFROM",
                    "index": 2.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "SHIPTO",
                    "index": 3.0,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139931_-871788617",
      "id": "20170628-143430_93328688",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Lat/Long",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT, timeline.transferorders \nwhere timeline.transferorders.to_id = timeline.TO_DELIVERY_CHG_EVENT.to_id",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "LATITUDE",
                    "index": 28.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "LONGITUDE",
                    "index": 29.0,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139932_1417513998",
      "id": "20170628-144341_2096133153",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Using Machine Learning to Predict Late Shipments\n\nHere we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.\n\nThe model considers attributes of the orders such as:\n- Mode of Transport\n- Carrier\n- Latitude \n- Longitude\n- Source City\n- Destination City\n- Part.\n\nThe model also considers exogenous data to enrich the inventory data such as weather:\n- weather at source\n- weather at destination.\n\nThe machine learning algorithm outputs a model that can predict whether a shipment is late. \n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:32.076",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Using Machine Learning to Predict Late Shipments</h2>\n<p>Here we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.</p>\n<p>The model considers attributes of the orders such as:<br/>- Mode of Transport<br/>- Carrier<br/>- Latitude<br/>- Longitude<br/>- Source City<br/>- Destination City<br/>- Part.</p>\n<p>The model also considers exogenous data to enrich the inventory data such as weather:<br/>- weather at source<br/>- weather at destination.</p>\n<p>The machine learning algorithm outputs a model that can predict whether a shipment is late.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1543618455011_1246322468",
      "id": "20181130-225415_805598687",
      "dateCreated": "2018-11-30 22:54:15.011",
      "dateStarted": "2018-12-01 07:10:21.254",
      "dateFinished": "2018-12-01 07:10:21.278",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### ML Means No ETL, Just Transformations\n\nSplice Machine is a Hybrid Transactional and Analytics Processing (*HTAP*) platform, so you can perform both transactional and analytical queries. This means that we don't need to extract and load data; instead, we simply transform it.\n\nBelow we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.\n\nThe first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:38.110",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>ML Means No ETL, Just Transformations</h3>\n<p>Splice Machine is a Hybrid Transactional and Analytics Processing (*HTAP*) platform, so you can perform both transactional and analytical queries. This means that we don&rsquo;t need to extract and load data; instead, we simply transform it.</p>\n<p>Below we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.</p>\n<p>The first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139934_-1835938020",
      "id": "20170621-070538_308959124",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:57:40.958",
      "dateFinished": "2018-11-30 22:57:40.976",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Bin Order Lateness and Label Orders",
      "text": "%splicemachine\n\ndrop table IF EXISTS TIMELINE.FEATURES;\n\nCREATE table TIMELINE.FEATURES AS\nSELECT \n    TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate,  \n    TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN TimeLine.TransferOrders.fromweather \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.fromweather end as currentweather,\n    TimeLine.TransferOrders.*, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN 0 \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate end as Lateness,\n    CASE\n    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 0 \n    THEN\n        CASE\n            WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 5 \n            THEN\n                CASE \n                    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 10\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n\n        END\n    ELSE 0\n    END AS Label\n from TimeLine.TransferOrders Left Outer Join TimeLine.TO_DELIVERY_CHG_EVENT\n on TimeLine.TransferOrders.TO_ID = TimeLine.TO_DELIVERY_CHG_EVENT.TO_ID\n WHERE  TIMESTAMP('${begin = 2017-05-05 00:00:00.0}') >= timeline.transferorders.deliverydate \nAND TIMESTAMP('${end =2017-05-05 00:00:00.0}') > timeline.transferorders.deliverydate; \n select * from timeline.features\n WHERE TIMESTAMP('${begin = 2017-05-05 00:00:00.0}') >= timeline.features.orgdeliverydate \n    AND TIMESTAMP('${end =2017-05-05 00:00:00.0}') > timeline.features.orgdeliverydate ;\n \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:46.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "2": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ORGDELIVERYDATE": "string",
                      "NEWDELIVERYDATE": "string",
                      "CURRENTWEATHER": "string",
                      "TO_ID": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "LATENESS": "string",
                      "LABEL": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "high": "Timestamp('2014-05-01')",
          "Start": "",
          "low": "Timestamp('2018-08-01')",
          "End": "",
          "end": "2017-05-15 00:00:00.0",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "type": "TextBox",
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          },
          "begin": {
            "type": "TextBox",
            "name": "begin",
            "defaultValue": " 2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139935_-1570248896",
      "id": "20170621-115351_1800134706",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### MLlib\n\nMLlib is a rich repository of Transformers and Models. For more information about MLlib, see: <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\" target=\"_blank\">https://spark.apache.org/docs/latest/ml-guide.html</a>\n\nIn this use case, we'll use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and  10 or over days late. Here are some notes about this:\n\n* The Logistic Regression Model expects a dataframe with two elements: feature Vector and label, which means that we have to extract the columns from the above table into this form.\n* Luckily MLlib has such a transformer called a Vector Assembler.\n\nIn the following paragraphs, we:\n\n1. Create a vector assembler\n2. Train the model\n3. Deploy the model to our prediction table\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:51.152",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>MLlib</h3>\n<p>MLlib is a rich repository of Transformers and Models. For more information about MLlib, see: <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\" target=\"_blank\"><a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">https://spark.apache.org/docs/latest/ml-guide.html</a></a></p>\n<p>In this use case, we&rsquo;ll use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and 10 or over days late. Here are some notes about this:</p>\n<ul>\n  <li>The Logistic Regression Model expects a dataframe with two elements: feature Vector and label, which means that we have to extract the columns from the above table into this form.</li>\n  <li>Luckily MLlib has such a transformer called a Vector Assembler.</li>\n</ul>\n<p>In the following paragraphs, we:</p>\n<ol>\n  <li>Create a vector assembler</li>\n  <li>Train the model</li>\n  <li>Deploy the model to our prediction table</li>\n</ol>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_1455601499",
      "id": "20170621-164244_783302183",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 23:07:44.266",
      "dateFinished": "2018-11-30 23:07:44.286",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Assemble Feature Vector and Train Model",
      "text": "%spark\n    \n    import org.apache.spark.ml.feature.VectorAssembler\n    import java.sql.{Connection,Timestamp}\n    import com.splicemachine.spark.splicemachine._\n    import org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\n    import org.apache.spark.ml.classification.LogisticRegression\n    import spark.implicits._\n\n    \n    val optionMap = Map(\n      JDBCOptions.JDBC_TABLE_NAME -> \"Timeline.Features\",\n      JDBCOptions.JDBC_URL -> defaultJDBCURL\n    )\n    val dfUpper = sqlContext.read.options(optionMap).splicemachine\n    val newNames = Seq(\"orgdeliverydate\",\"newdeliverydate\",\"currentweather\",\"to_id\",\n      \"po_id\",\"shipfrom\",\"shipto\",\"shipdate\",\"deliverydate\",\"moddeliverydate\",\"sourceinventory\",\n      \"destinationinventory\",\"qty\",\"supplier\",\"asn\",\"container\",\"transportmode\",\"carrier\",\n      \"fromweather\",\"toweather\",\"latitude\",\"longitude\",\"lateness\",\"label\")\n    val df = dfUpper.toDF(newNames: _*)\n    \n    \n    //assemble feature vector from dataframe\n    val assembler = new VectorAssembler()\n      .setInputCols(Array(\"shipfrom\", \"shipto\", \"sourceinventory\", \"destinationinventory\", \"supplier\", \"transportmode\", \"carrier\", \"fromweather\", \"toweather\"))\n      .setOutputCol(\"features\")\n    \n    val output = assembler.transform(df)\n    println(\"Assembled columns ShipFrom, ShipTo, SourceInventory, DestinationInventory, Supplier, TransportMode, Carrier, FromWeather, ToWeather to vector column 'features'\")\n    output.select(\"features\", \"label\").show(true)\n    \n    // Set parameters for the algorithm.\n    // Here, we limit the number of iterations to 10.\n    val lr = new LogisticRegression()\n        .setMaxIter(10)\n\n        \n    \n    // Fit the model to the data.\n    val model = lr.fit(output)\n    \n   //Get the number of classes in Label\n     val numClasses = model.numClasses\n    // Given a dataset, predict each point's label, and show the results.\n    val newdf = model.transform(output)\n    \n    // Print the coefficients and intercept for multinomial logistic regression\n    println(s\"Coefficients: \\n${model.coefficientMatrix}\")\n    println(s\"Intercepts: ${model.interceptVector}\")\n    \n    ",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:58.207",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_-1971148676",
      "id": "20170621-164423_1216161315",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Deploy Model to Prediction Table",
      "text": "%spark\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.sql.types.{StructType,StructField,DoubleType, LongType}\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.catalyst.encoders.RowEncoder\n\nval predictionTable = \"timeline.predictions\"\n\nvar labelCnt = numClasses\n//Only allow max of 10 lables\nif(labelCnt > 10)\n    labelCnt =10\n\n    \n newdf.printSchema()\n \n    \n    var schema = StructType(\n    StructField(\"TO_ID\", LongType, false) :: Nil)\n   \n    \n    var i=0;\n    for (i <- 1 to labelCnt) {\n        schema = schema.add( StructField(\"LATENESSBIN\"+i, DoubleType, false) )\n    }\n           \n    \nval encoder = RowEncoder(schema)\n \n val pred = newdf\n  .select( \"features\", \"label\", \"probability\", \"prediction\", \"to_id\")\n  .map { case Row( features: Vector, label: Integer, prob: Vector, prediction: Double, idd:Long) => \n  \n    var seq1 : Seq[Any] = Seq(idd.asInstanceOf[Number].longValue())\n    var j=0;\n    for (j <- 1 to labelCnt) {\n        seq1 = seq1:+ ( prob(j-1).asInstanceOf[Number].doubleValue())\n    }\n    println(seq1)\n     Row.fromSeq(seq1)   \n    }(encoder)\n    \n    \n  splicemachineContext.update(pred, predictionTable) \n  pred.show()\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_467778342",
      "id": "20170626-132011_1256759754",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\nWe'll now continue our exploration of Machine Learning with Splice Machine by implementing a [*KMeans clustering algorithm*](/#/notebook/2DX6TGACY) in a Splice Machine Zeppelin notebook.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:11:16.344",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Where to Go Next</h2>\n<p>We&rsquo;ll now continue our exploration of Machine Learning with Splice Machine by implementing a <a href=\"/#/notebook/2DX6TGACY\"><em>KMeans clustering algorithm</em></a> in a Splice Machine Zeppelin notebook.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139938_-585719086",
      "id": "20170714-192918_375392082",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-20 10:52:00.343",
      "dateFinished": "2018-11-20 10:52:00.347",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training/For Data Scientists/h. Predicting Supply Chain Shortages",
  "id": "2DY411M2A",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}