{
  "paragraphs": [
    {
      "text": "%md\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\n# Crystal Ball\n\nThis notebook presents the *Crystal Ball* application, which is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. This app is presented in the following sections:\n\n* *Set Up Your JDBC Connection URL*\n* *Managing Your Timeline*\n* *Crystal Ball Application Requirements*\n* *Ingesting Advanced Shipping Notices - Transfer Orders*\n* *Using Timeline Tables*\n* *Applying the Crystal Ball*\n* *Machine Learning*\n\n## What the Crystal Ball Does\nYou can do the following with the *Crystal Ball* application:\n\n* Perform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments\n* Learn when shipments are likely to be late\n* Anticipate stock outs that are due to predicted late orders\n* Determine which customers or downstream orders are affected by anticipated stockouts.\n\nWhen supply chain managers have the crystal ball, they can:\n\n* Plan around stock outs\n* Warn down stream consumers so they can re-plan.\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:39.581",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003ch1\u003eCrystal Ball\u003c/h1\u003e\n\u003cp\u003eThis notebook presents the \u003cem\u003eCrystal Ball\u003c/em\u003e application, which is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. This app is presented in the following sections:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eSet Up Your JDBC Connection URL\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eManaging Your Timeline\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eCrystal Ball Application Requirements\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eIngesting Advanced Shipping Notices - Transfer Orders\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eUsing Timeline Tables\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eApplying the Crystal Ball\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eMachine Learning\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eWhat the Crystal Ball Does\u003c/h2\u003e\n\u003cp\u003eYou can do the following with the \u003cem\u003eCrystal Ball\u003c/em\u003e application:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ePerform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments\u003c/li\u003e\n  \u003cli\u003eLearn when shipments are likely to be late\u003c/li\u003e\n  \u003cli\u003eAnticipate stock outs that are due to predicted late orders\u003c/li\u003e\n  \u003cli\u003eDetermine which customers or downstream orders are affected by anticipated stockouts.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen supply chain managers have the crystal ball, they can:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ePlan around stock outs\u003c/li\u003e\n  \u003cli\u003eWarn down stream consumers so they can re-plan.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139913_292026853",
      "id": "20170621-041621_785608971",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:49:25.277",
      "dateFinished": "2018-11-30 22:49:25.308",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Set Up Your JDBC Connection URL\n\nTo connect to your Splice Machine database, you need to configure the URL you\u0027ll be connecting to via JDBC. \n\nFor this class, you can simply use the `defaultJDBCURL` assignment in the next paragraph. When running on a cluster, you can copy and paste the JDBC URL you\u0027ll find displayed at the bottom right of your cluster dashboard.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:51.409",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eSet Up Your JDBC Connection URL\u003c/h2\u003e\n\u003cp\u003eTo connect to your Splice Machine database, you need to configure the URL you\u0026rsquo;ll be connecting to via JDBC. \u003c/p\u003e\n\u003cp\u003eFor this class, you can simply use the \u003ccode\u003edefaultJDBCURL\u003c/code\u003e assignment in the next paragraph. When running on a cluster, you can copy and paste the JDBC URL you\u0026rsquo;ll find displayed at the bottom right of your cluster dashboard.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542765401625_-1467740243",
      "id": "20181120-175641_472076393",
      "dateCreated": "2018-11-20 17:56:41.625",
      "dateStarted": "2018-11-30 22:49:29.864",
      "dateFinished": "2018-11-30 22:49:29.873",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n  val defaultJDBCURL \u003d \"\"\"jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin\"\"\"\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 21:57:48.464",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "JDBCurl": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin"
        },
        "forms": {
          "JDBCurl": {
            "type": "TextBox",
            "name": "JDBCurl",
            "displayName": "JDBCurl",
            "defaultValue": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin;useSpark\u003dtrue",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139914_897915583",
      "id": "20170622-063514_1166002275",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Managing the Timeline\nThe code in the next paragraph manages the timeline:",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:00.261",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eManaging the Timeline\u003c/h2\u003e\n\u003cp\u003eThe code in the next paragraph manages the timeline:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542765659638_-1071926324",
      "id": "20181120-180059_1459449180",
      "dateCreated": "2018-11-20 18:00:59.638",
      "dateStarted": "2018-11-30 21:58:12.470",
      "dateFinished": "2018-11-30 21:58:12.477",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Timeline  Code",
      "text": "%spark\nimport java.sql.{Connection,Timestamp}\nimport java.util.Date\nimport com.splicemachine.si.api.txn.WriteConflict\nimport org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\nimport com.splicemachine.spark.splicemachine._\n    \n  val table \u003d \"TimeLine_Int\"\n  val schema \u003d \"TimeLine\"\n  val internalTN \u003d schema + \".\" + table\n  val startOfTimeStr \u003d \"1678-01-01 00:00:00\"\n  val endOfTimeStr \u003d \"2261-12-31 00:00:00\"\n  val startOfTime \u003d java.sql.Timestamp.valueOf(startOfTimeStr)\n  val endOfTime \u003d java.sql.Timestamp.valueOf(endOfTimeStr)\n  val MAX_RETRIES: Integer \u003d 2\n\n  val SQL_ID \u003d 1\n  val SQL_ST \u003d 2\n  val SQL_ET \u003d 3\n  val SQL_VAL \u003d 4\n  val DF_ID \u003d 0\n  val DF_ST \u003d 1\n  val DF_ET \u003d 2\n  val DF_VAL \u003d 3\n  \n  val columnsWithPrimaryKey: String  \u003d \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n  val columnsWithoutPrimaryKey \u003d \"(\" + \"Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint \" + \")\"\n  val primaryKeys \u003d Seq(\"Timeline_ID, ST\")\n  val columnsInsertString \u003d \"(\" + \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Val\" + \") \"\n  val columnsSelectString \u003d \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Value\"\n  val columnsInsertStringValues \u003d \"values (?,?,?,?)\"\n\n\n  /* (t1\u003c\u003dST and t2\u003eST) or (t1\u003eST and t1\u003cET)  (t1 t2 t1 t1 )*/\n  val overlapCondition \u003d \"where Timeline_Id \u003d ? and ((ST \u003e\u003d? and ST \u003c?) or ((ST \u003c ?) and (ET \u003e \u003e?)))\"\n\n\n  val internalOptions \u003d Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -\u003e internalTN,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -\u003e defaultJDBCURL\n  )\n\n  val internalJDBCOptions \u003d new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(internalOptions)\n  val splicemachineContext \u003d  new com.splicemachine.spark.splicemachine.SplicemachineContext(defaultJDBCURL)\n\n\n\n  /**\n    *\n    * createTimeline (table)\n    *\n    * @param table table name of timeline\n    * @return\n    */\n  def createTimeline(table: String, columnsWithPrimaryKey: String , internalJDBCOptions: JDBCOptions \u003d internalJDBCOptions ): Unit \u003d {\n    val conn \u003d JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    if (splicemachineContext.tableExists(table)){\n      conn.createStatement().execute(\"drop table \" + table)\n    }\n    conn.createStatement().execute(\"create table \" + table + columnsWithPrimaryKey)\n  }\n  \n  \n  \n  /**\n    *\n    * initialize (id startOfTime endOfTime value)\n    *\n    * @param table table name of timeline\n    * @param id id of timeline\n    * @param value initial value of timeline\n    * @return\n    */\n def initialize(table: String, id: Integer, value: Integer, columnsInsertString : String \u003d columnsInsertString ,columnsInsertStringValues :String \u003d columnsInsertStringValues  , internalJDBCOptions :JDBCOptions \u003d internalJDBCOptions ): Unit \u003d {\n    val conn \u003d JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    val start: Timestamp \u003d startOfTime\n    val end: Timestamp \u003d endOfTime\n    try {\n      var ps \u003d conn.prepareStatement(\"delete from \" + table + \" where timeline_id \u003d \" + id)\n      ps.execute()\n      ps \u003d conn.prepareStatement(\"insert into \" + table + columnsInsertString + columnsInsertStringValues)\n      ps.setInt(SQL_ID, id)\n      ps.setTimestamp(SQL_ST, start)\n      ps.setTimestamp(SQL_ET, end)\n      ps.setInt(SQL_VAL, value)\n      ps.execute()\n    } finally {\n      conn.close()\n    }\n  }\n\n  val CHANGE_AT_ST \u003d 0\n  val CHANGE_AT_ET \u003d 1\n  val CHANGE_BETWEEN_ST_ET \u003d2\n  \n\n  /**\n    * splitMiddle - The new delta interval is subsumed by one interval.\n    *\n    *  ST------------ET\n    *      t1---t2         \u003d\u003d\u003e   ST---t1 t1----t2 t2----ET\n    *\n    * Change the original interval to end at the start of the new delta interval\n    * Create a new record for the delta and apply the delta value\n    * Create a new record for the interval from the delta to the end of the original interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    *\n    */\n    \n                \n  def splitMiddle(id: Integer,\n                  t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                  delta: Long,\n                  persistence: Int,\n                  internalTN : String \u003dinternalTN ,\n                  internalOptions : Map[String,String] \u003d internalOptions): Unit \u003d {\n    val df \u003d sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID \u003d $id AND ST \u003c to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n    if (df.count() \u003e 0) {\n\n      /* Save old values */\n      var oldVal \u003d df.first().getLong(DF_VAL)\n      var oldET \u003d df.first().getTimestamp(DF_ET)\n\n      /* Update containing interval to be the begin split */\n      val updatedDF \u003d df\n        .filter(s\"TIMELINE_ID \u003d $id AND ST \u003c to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* calculate persistence */\n      val firstValue: Long \u003d persistence match {\n        case CHANGE_AT_ST          \u003d\u003e oldVal + delta\n        case CHANGE_AT_ET          \u003d\u003e oldVal\n        case CHANGE_BETWEEN_ST_ET  \u003d\u003e oldVal + delta\n        case _                     \u003d\u003e 0\n      }\n\n      /* Insert the two new splits */\n      /* Note - the second new split will have delta added\n\t\tin the persistAfter method\n       */\n      val newDF \u003d sqlContext.createDataFrame(Seq(\n        (id, t1, t2, firstValue),\n        (id, t2, oldET, oldVal)))\n        .toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n\n  /***\n    * \tsplitAtEnd - Delta overlaps beginning of interval.\n    *\n    *         ST------ET\n    *      t1---t2         \u003d\u003d\u003e  ST---t2 t2----ET\n    *\n    * Change the interval to end at the end of the delta then add a split from end of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n    \n     \n  def splitAtEnd(id: Integer,\n                 t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                 delta: Long,\n                 persistence: Int,\n                  internalTN : String \u003dinternalTN ,\n                  internalOptions : Map[String,String] \u003d internalOptions): Unit \u003d {\n    val df \u003d sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"\"\"TIMELINE_ID \u003d $id AND ST \u003e\u003d to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027) AND ST \u003c to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\"\"\")\n\n    if (df.count() \u003e 0) {\n\n      /* Save old values */\n      var oldVal \u003d df.first().getLong(DF_VAL)\n      var oldST \u003d df.first().getTimestamp(DF_ST)\n      var oldET \u003d df.first().getTimestamp(DF_ET)\n      /* Update overlapping interval to be the begin split */\n\n      /* calculate persistence */\n      /* Note - the second new split will have delta added\n          in the persistAfter method if required\n */\n      val firstValue: Long \u003d persistence match {\n        case CHANGE_AT_ST          \u003d\u003e oldVal + delta\n        case CHANGE_AT_ET          \u003d\u003e oldVal\n        case CHANGE_BETWEEN_ST_ET  \u003d\u003e oldVal + delta\n        case _                     \u003d\u003e 0\n      }\n\n      val updatedDF \u003d df\n\t    .filter(s\"TIMELINE_ID \u003d $id AND ST \u003e\u003d to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027) AND ST \u003c to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t2))\n      .withColumn(\"VAL\", lit(firstValue))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* Insert a new split after the delta */\n      val newDF \u003d sqlContext.createDataFrame(Seq((id, t2, oldET, oldVal))).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n  /**\n    * \tsplitAtStart - Delta overlaps end of interval.\n    *\n    *         ST-----ET\n    *            t1------t2         \u003d\u003d\u003e    ST---t1 t1---ET\n    *\n    * Change the interval to end at the start of the delta then add a split from beginning of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n   \n  def splitAtStart(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long, persistence: Int,\n                  internalTN : String \u003dinternalTN ,\n                  internalOptions : Map[String,String] \u003d internalOptions): Unit \u003d {\n    val df \u003d sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID \u003d $id AND ST \u003c to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND \" +\n                s\"ET \u003c to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027)\")\n    if (df.count() \u003e 0) {\n\n      /* Save old values */\n      var oldVal \u003d df.first().getLong(DF_VAL)\n      var oldST \u003d df.first().getTimestamp(DF_ST)\n      var oldET \u003d df.first().getTimestamp(DF_ET)\n\n      /* calculate persistence */\n      val newValue: Long \u003d persistence match {\n        case CHANGE_AT_ST          \u003d\u003e oldVal + delta\n        case CHANGE_AT_ET          \u003d\u003e oldVal\n        case CHANGE_BETWEEN_ST_ET  \u003d\u003e oldVal\n        case _                     \u003d\u003e 0\n      }\n      /* Update overlapping interval to be the begin split */\n      val updatedDF \u003d df\n        .filter(s\"TIMELINE_ID \u003d $id AND ST \u003c to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003c to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027) AND ET \u003e to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027)\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      .withColumn(\"VAL\", lit(newValue))\n      splicemachineContext.update(updatedDF, internalTN)\n      \n      /* Insert a new split */\n      val newDF \u003d sqlContext.createDataFrame(Seq(\n        (id, t1, oldET, oldVal)\n      )).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n }\n                   \n    \n  /***\n    *   changeNoSplit - Handles all intervals contained by delta\n    *\n    *           ST-----ET\n    *     t1---------------t2\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def changeNoSplit(id: Integer,\n                    t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                    delta: Long,\n                    persistence: Int,\n                  internalTN : String \u003dinternalTN ,\n                  internalOptions : Map[String,String] \u003d internalOptions): Unit \u003d {\n           \n    val df \u003d sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"TIMELINE_ID \u003d $id AND ST \u003e\u003d to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003c\u003d to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n\n    /* Calculate persistence */\n    val increment: Long \u003d persistence match {\n      case CHANGE_AT_ST          \u003d\u003e delta\n      case CHANGE_AT_ET          \u003d\u003e 0\n      case CHANGE_BETWEEN_ST_ET  \u003d\u003e delta\n      case _                     \u003d\u003e 0\n    }\n    val updatedDF \u003d df\n      .filter(s\"TIMELINE_ID \u003d $id AND ST \u003e\u003d to_utc_timestamp(\u0027$t1\u0027,\u0027GMT\u0027) AND ET \u003c\u003d to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n      .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + increment)\n\n    splicemachineContext.update(updatedDF, internalTN)\n  }\n\n  /***\n    *   persistAfter - changes the values for all intervals after delta\n    *\n    *     t1---------------t2  ST-----ET\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def persistAfter(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long,\n                   persistence: Int,\n                  internalTN : String \u003dinternalTN ,\n                  internalOptions : Map[String,String] \u003d internalOptions): Unit \u003d {\n\n    /* Persist delta after new splits if necesary */\n    if (persistence !\u003d CHANGE_BETWEEN_ST_ET) {\n      val persistDF \u003d sqlContext.read.options(internalOptions).splicemachine\n        .filter(s\"TIMELINE_ID \u003d $id AND ST \u003e\u003d to_utc_timestamp(\u0027$t2\u0027,\u0027GMT\u0027)\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + delta)\n      splicemachineContext.update(persistDF, internalTN)\n    }\n  }\n\n  /** *\n    * update - increases/decreases the value for the interval\n    * from the start, end or during the interval\n    *\n    * @param table       - the name of the timeline table\n    * @param id          - the id of the timeline to update\n    * @param t1          - the start of new delta\n    * @param t2          - the end of the new delta\n    * @param delta       - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                    CHANGE_AT_ET persists delta from t2 onwards\n    *                    CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n\n  def update(table: String,\n             id: Integer,\n             t1: Timestamp, t2: Timestamp,\n             delta: Long,\n             persistence: Int): Unit \u003d {\n                \n\n   val intOptions \u003d Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -\u003e table,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -\u003e defaultJDBCURL\n  )\n    changeNoSplit(id, t1, t2, delta, persistence, table,intOptions )\n    splitAtStart(id, t1, t2, delta, persistence, table,intOptions)\n    splitMiddle(id, t1, t2, delta, persistence, table,intOptions)\n    splitAtEnd(id, t1, t2, delta, persistence, table,intOptions)\n    persistAfter(id, t1, t2, delta, persistence, table,intOptions)\n  }\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:24.318",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139915_1318983996",
      "id": "20170622-231413_1135446195",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Crystal Ball Application Requirements\n\nThe *Crystal Ball* app was built to meet these requirements:\n\n* Streaming inventory movements - ASN - EDI856\n* Streaming ancilary data like real-time weather\n* Needle-in-Haystack OLTP queries and range scans for ATP\n* ACID Transactions for concurrent inventory changes\n* OLAP for analysis and feature engineering\n* OLAP for inventory projections\n* Machine Learning\n* UI for Collaboration\n\nSplice Machine has all these components pre-integrated and optimized",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:29.638",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eCrystal Ball Application Requirements\u003c/h2\u003e\n\u003cp\u003eThe \u003cem\u003eCrystal Ball\u003c/em\u003e app was built to meet these requirements:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eStreaming inventory movements - ASN - EDI856\u003c/li\u003e\n  \u003cli\u003eStreaming ancilary data like real-time weather\u003c/li\u003e\n  \u003cli\u003eNeedle-in-Haystack OLTP queries and range scans for ATP\u003c/li\u003e\n  \u003cli\u003eACID Transactions for concurrent inventory changes\u003c/li\u003e\n  \u003cli\u003eOLAP for analysis and feature engineering\u003c/li\u003e\n  \u003cli\u003eOLAP for inventory projections\u003c/li\u003e\n  \u003cli\u003eMachine Learning\u003c/li\u003e\n  \u003cli\u003eUI for Collaboration\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSplice Machine has all these components pre-integrated and optimized\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139916_-1935319884",
      "id": "20170621-041831_354747046",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:35:52.088",
      "dateFinished": "2018-11-30 22:35:52.100",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Ingesting Advanced Shipping Notices - Transfer Orders\n\nYou can copy and paste the data ingestion calls shown below; this data was generated by a supply-chain simulator notebook (URL). Here are some notes about this:\n\n* The simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates.\n* The generator randomly selects features for the transfer orders. \n* The files below reflect the state of the database after the simulation runs. The orders and change orders are independent files that can be loaded separately.\n* The simulation runs are cumulative, which means demo has the inventory timelines for the test data and the train data. \n\nTo use the demo data, you need to: \n\n1. Load, train, and test for orders and change orders\n2. Load the demo inventory timeline file.\n\nThe paragraphs in this section contain the code that takes care of these tasks.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:07:34.027",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eIngesting Advanced Shipping Notices - Transfer Orders\u003c/h2\u003e\n\u003cp\u003eYou can copy and paste the data ingestion calls shown below; this data was generated by a supply-chain simulator notebook (URL). Here are some notes about this:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eThe simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates.\u003c/li\u003e\n  \u003cli\u003eThe generator randomly selects features for the transfer orders.\u003c/li\u003e\n  \u003cli\u003eThe files below reflect the state of the database after the simulation runs. The orders and change orders are independent files that can be loaded separately.\u003c/li\u003e\n  \u003cli\u003eThe simulation runs are cumulative, which means demo has the inventory timelines for the test data and the train data.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo use the demo data, you need to: \u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eLoad, train, and test for orders and change orders\u003c/li\u003e\n  \u003cli\u003eLoad the demo inventory timeline file.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe paragraphs in this section contain the code that takes care of these tasks.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139916_1177726344",
      "id": "20170621-044326_1460127976",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:39:21.380",
      "dateFinished": "2018-11-30 22:39:21.396",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initialize",
      "text": "%spark\n\nz.run(\"20170622-063514_1166002275\"); // JDBC URL\nz.run(\"20170622-231413_1135446195\"); // Timeline Code\nz.run(\"20170622-222153_977899468\"); // DDL\nz.run(\"20170623-174025_718327456\"); // Load Data\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 18:16:19.969",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-243689402",
      "id": "20170628-085245_2111524765",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ncreate schema TIMELINE;\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-1588197916",
      "id": "20170703-142111_1098530498",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Schema",
      "text": "%splicemachine\n\ndrop table IF EXISTS  TIMELINE.TRANSFERORDERS;\ndrop table IF EXISTS  TIMELINE.TO_DELIVERY_CHG_EVENT;\ndrop table IF EXISTS  TIMELINE.TIMELINE_INT;\ndrop table IF EXISTS TIMELINE.STOCKOUTS;\n\n\n\ncreate table TIMELINE.TRANSFERORDERS(\n    TO_ID   BIGINT,\n    PO_ID   BIGINT,\n    SHIPFROM BIGINT,\n    SHIPTO  BIGINT,\n    SHIPDATE TIMESTAMP,\n    DELIVERYDATE TIMESTAMP,\n    MODDELIVERYDATE TIMESTAMP,\n    SOURCEINVENTORY BIGINT,\n    DESTINATIONINVENTORY BIGINT,\n    QTY BIGINT,\n    SUPPLIER BIGINT,\n    ASN VARCHAR(100),\n    CONTAINER VARCHAR(100),\n    TRANSPORTMODE SMALLINT,\n    CARRIER BIGINT,\n    FROMWEATHER SMALLINT,\n    TOWEATHER SMALLINT,\n    LATITUDE  DOUBLE,\n    LONGITUDE DOUBLE,\n    primary key (TO_ID)\n    );\n\ncreate index TIMELINE.TOSTIDX on TRANSFERORDERS (\n    ShipDate,\n    TO_Id\n );\n \n create index TIMELINE.TOETIDX on TRANSFERORDERS (\n    Deliverydate,\n    TO_Id\n );\n\ncreate table TIMELINE.TO_DELIVERY_CHG_EVENT(\n    TO_event_Id bigint,\n    TO_Id bigint ,\n    ShipFrom bigint,\n    ShipTo bigint,\n    OrgDeliveryDate timestamp,\n    newDeliveryDate timestamp,\n    Supplier varchar(100) ,\n    TransportMode smallint ,\n    Carrier bigint ,\n    Fromweather smallint,\n    ToWeather smallint,\n    primary key (TO_event_Id)\n    );\n    \ncreate table TIMELINE.TIMELINE_INT(\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    ET          TIMESTAMP,\n    VAL         BIGINT,\n    primary key (Timeline_Id, ST)\n    );\n    \ncreate table TIMELINE.STOCKOUTS(\n    TO_ID   BIGINT,\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    primary key (TO_ID,ST)\n    );\n    \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139917_-1902551066",
      "id": "20170622-222153_977899468",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Train Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TRANSFERORDERS\u0027,null, \u0027s3a://splice-demo/supplychain/data_0623/train_orders.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TO_DELIVERY_CHG_EVENT\u0027, null, \u0027s3a://splice-demo/supplychain/data_0623/train_events.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TIMELINE_INT\u0027, null, \u0027s3a://splice-demo/supplychain/data_0623/train_inv.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 09:59:01.663",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          },
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          },
          "2": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139918_798437646",
      "id": "20170623-174025_718327456",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Test Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TRANSFERORDERS\u0027,null, \u0027s3a://splice-demo/supplychain/data_0623/test_orders.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TO_DELIVERY_CHG_EVENT\u0027, null, \u0027s3a://splice-demo/supplychain/data_0623/test_events.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TIMELINE_INT\u0027, null, \u0027s3a://splice-demo/supplychain/data_0623/test_inv.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139919_29713688",
      "id": "20170628-222352_2120811555",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load Demo Data",
      "text": "%splicemachine\n\n\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TRANSFERORDERS\u0027,null, \u0027s3a://splice-demo/supplychain/data_0623/demo_orders.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TO_DELIVERY_CHG_EVENT\u0027, null, \u0027s3a://splice-demo/supplychain/demo_0623/demo_events.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\ncall SYSCS_UTIL.IMPORT_DATA(\u0027TIMELINE\u0027,\u0027TIMELINE_INT\u0027, null, \u0027s3a://splice-demo/supplychain/data_0623/demo_inv.csv\u0027, null, null, \u0027yyyy-MM-dd HH:mm:ss.S\u0027, null, null, -1, \u0027/tmp\u0027, true, null);\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139919_1122296054",
      "id": "20170628-222451_440347172",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Transfer Orders",
      "text": "%splicemachine\nselect * from timeline.transferorders\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:42.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TO_ID": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "304"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139920_-22590724",
      "id": "20170623-175231_773807313",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Using Timeline Tables\n\nTimelines are a relational representation of temporal data for AI applications. \n\nA timeline table contains a collection of timelines, each with a unique id. Every row represents: `TIMELINE_ID \u003d VAL @ [ST ET]` meaning the variable denoted by the id has the value over that time interval\n\nSome notes about Timelines:\n\n* Timelines record historical, present and future values.\n* Timelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.\n* Timelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.\n\nFor example, you have to make sure that when you move an order, the decrement to the source inventory changes atomically with the change to the destination inventory.\n\nThis code paragraphs in this section demonstrate how to use timeline tables for tracking inventory, finding stock-outs, and finding ATP inventory.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:08:31.459",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eUsing Timeline Tables\u003c/h2\u003e\n\u003cp\u003eTimelines are a relational representation of temporal data for AI applications. \u003c/p\u003e\n\u003cp\u003eA timeline table contains a collection of timelines, each with a unique id. Every row represents: \u003ccode\u003eTIMELINE_ID \u003d VAL @ [ST ET]\u003c/code\u003e meaning the variable denoted by the id has the value over that time interval\u003c/p\u003e\n\u003cp\u003eSome notes about Timelines:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eTimelines record historical, present and future values.\u003c/li\u003e\n  \u003cli\u003eTimelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.\u003c/li\u003e\n  \u003cli\u003eTimelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor example, you have to make sure that when you move an order, the decrement to the source inventory changes atomically with the change to the destination inventory.\u003c/p\u003e\n\u003cp\u003eThis code paragraphs in this section demonstrate how to use timeline tables for tracking inventory, finding stock-outs, and finding ATP inventory.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139922_1998505180",
      "id": "20170621-050328_679054277",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:44:42.724",
      "dateFinished": "2018-11-30 22:44:42.741",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Tracking Inventory As Timelines",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere TIMELINE_ID \u003d ${inv\u003d200}\norder by TIMELINE.TIMELINE_INT.ST;",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:36:40.824",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false,
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "ST",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 3.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": "200",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139922_1831631662",
      "id": "20170621-052218_96471785",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:36:40.865",
      "dateFinished": "2018-11-30 22:36:41.163",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Stock Outs",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere timeline_id \u003d ${inv\u003d 100} AND val \u003c 0 \norder by timeline.timeline_int.st;",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 132.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TIMELINE_ID": "string",
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "500"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139923_-2084294906",
      "id": "20170621-052618_1306506874",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "ATP",
      "text": "%splicemachine\nselect VAL AS Available from timeline.timeline_int\nwhere timeline_id \u003d ${inv\u003d 100} \nAND ST \u003c\u003d TIMESTAMP(\u0027${Time\u003d2017-05-05 00:00:00.0}\u0027)  \nAND ET \u003e TIMESTAMP(\u0027${Time\u003d2017-05-05 00:00:00.0}\u0027)",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 90.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "AVAILABLE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "100",
          "Time": "2016-05-10 00:00:00.0"
        },
        "forms": {
          "inv": {
            "type": "TextBox",
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false
          },
          "Time": {
            "type": "TextBox",
            "name": "Time",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139923_-2110959174",
      "id": "20170621-053013_888862556",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Applying the Crystal Ball\n\nYou can apply the crystal ball to perform a *What-If* on any predicted late shipment. By moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.\n\nThe code paragraphs in this section create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only. \n\nAfter that, we perform a *What-If* simulation for a specified order with a delay",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:08:52.889",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eApplying the Crystal Ball\u003c/h2\u003e\n\u003cp\u003eYou can apply the crystal ball to perform a \u003cem\u003eWhat-If\u003c/em\u003e on any predicted late shipment. By moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.\u003c/p\u003e\n\u003cp\u003eThe code paragraphs in this section create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only. \u003c/p\u003e\n\u003cp\u003eAfter that, we perform a \u003cem\u003eWhat-If\u003c/em\u003e simulation for a specified order with a delay\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139924_1939899989",
      "id": "20170621-054855_1620710812",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-12-01 07:08:50.569",
      "dateFinished": "2018-12-01 07:08:50.575",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Prediction Table",
      "text": "%splicemachine\nDrop table IF EXISTS TIMELINE.PREDICTIONS;\ncreate table TIMELINE.PREDICTIONS(\n    TO_ID   BIGINT,\n    LatenessBin1 DOUBLE,\n    LatenessBin2 DOUBLE,\n    LatenessBin3 DOUBLE,\n    LatenessBin4 DOUBLE,\n    LatenessBin5 DOUBLE,\n    LatenessBin6 DOUBLE,\n    LatenessBin7 DOUBLE,\n    LatenessBin8 DOUBLE,\n    LatenessBin9 DOUBLE,\n    LatenessBin10 DOUBLE,\n    primary key (TO_ID)\n    );\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:37:11.406",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139924_1899668217",
      "id": "20170623-181559_517039267",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Initializing Predictions Randomly",
      "text": "%splicemachine\ninsert into TIMELINE.PREDICTIONS (\n    TO_ID, \n    LatenessBin1,\n    LatenessBin2,\n    LatenessBin3,\n    LatenessBin4\n    )\n    SELECT TO_ID, RANDOM(), RANDOM(), RANDOM(), RANDOM() \n    From TIMELINE.TRANSFERORDERS\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139925_-1273981434",
      "id": "20170623-182513_1199711298",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Predictions",
      "text": "%splicemachine\nSELECT TP.TO_ID, TP.LatenessBin1 as ZERO_DAYLATE, TP.LatenessBin2 as ONE_DAYLATE, TP.LatenessBin3 as FIVE_DAYLATE,  TP.LatenessBin4 as TEN_DAYLATE, timeline.transferorders.*    FROM timeline.predictions TP  LEFT OUTER JOIN timeline.transferorders  ON TP.to_id \u003d timeline.transferorders.to_id\nwhere TIMESTAMP(\u0027${begin \u003d2017-05-05 00:00:00.0}\u0027) \u003e\u003d timeline.transferorders.deliverydate \nAND TIMESTAMP(\u0027${end \u003d2017-05-05 00:00:00.0}\u0027) \u003etimeline.transferorders.deliverydate \nAND TP.LatenessBin3 \u003e\u003d ${threshold \u003d .75}",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:43.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TO_ID": "string",
                      "ZERO_DAYLATE": "string",
                      "ONE_DAYLATE": "string",
                      "FIVE_DAYLATE": "string",
                      "TEN_DAYLATE": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "end": "2017-05-05 00:00:00.0",
          "threshold": ".5",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "type": "TextBox",
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          },
          "threshold": {
            "type": "TextBox",
            "name": "threshold",
            "defaultValue": " .75",
            "hidden": false
          },
          "begin": {
            "type": "TextBox",
            "name": "begin",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139927_-96827937",
      "id": "20170714-183906_14590483",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Perform a *What-If* Simulation for a Specified Order with a Delay\n\nPick an order that may be delayed by a specified number of days to see what orders may result in stock out situation because of the delay.\n\nFirst, all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.\n\nNext, the delay is simulated, inventory calculations are made, and the Orders that are sourced from the Destination are again checked for stockout situation.\n\nSince these *what-if* calculations are done on a temporary table, the actual data is not impacted.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:09:14.540",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003ePerform a \u003cem\u003eWhat-If\u003c/em\u003e Simulation for a Specified Order with a Delay\u003c/h3\u003e\n\u003cp\u003ePick an order that may be delayed by a specified number of days to see what orders may result in stock out situation because of the delay.\u003c/p\u003e\n\u003cp\u003eFirst, all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.\u003c/p\u003e\n\u003cp\u003eNext, the delay is simulated, inventory calculations are made, and the Orders that are sourced from the Destination are again checked for stockout situation.\u003c/p\u003e\n\u003cp\u003eSince these \u003cem\u003ewhat-if\u003c/em\u003e calculations are done on a temporary table, the actual data is not impacted.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139928_-1737510532",
      "id": "20170716-211650_1813160194",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:53:25.728",
      "dateFinished": "2018-11-30 22:53:25.753",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%angular\n\n\u003cform class\u003d\"form-inline\"\u003e\n  \u003cdiv class\u003d\"form-group\"\u003e\n   \u003ch5\u003eSimulate Late Order \u003c/h5\u003e\n    \u003clabel for\u003d\"orderFieldId\"\u003e Order ID : \u003c/label\u003e\n    \u003cinput type\u003d\"text\" class\u003d\"form-control\" id\u003d\"orderFieldId\" placeholder\u003d Order id ...\" ng-model\u003d\"orderId\"\u003e\u003c/input\u003e\n    \u003clabel for\u003d\"delayFieldId\"\u003eDelay in Days: \u003c/label\u003e\n    \u003cinput type\u003d\"text\" class\u003d\"form-control\" id\u003d\"delayFieldId\" placeholder\u003d Delay Days ...\" ng-model\u003d\"delayDays\"\u003e\u003c/input\u003e\n      \u003cbutton type\u003d\"submit\" class\u003d\"btn btn-primary\" ng-click\u003d\"z.angularBind(\u0027orderId\u0027,orderId,\u002720170625-202310_651912174\u0027);z.angularBind(\u0027delayDays\u0027,delayDays,\u002720170625-202310_651912174\u0027); z.runParagraph(\u002720170625-202310_651912174\u0027)\"\u003e Run What-If\u003c/button\u003e\n  \u003c/div\u003e\n\n\u003c/form\u003e\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "ANGULAR",
            "data": "\u003cform class\u003d\"form-inline\"\u003e\n  \u003cdiv class\u003d\"form-group\"\u003e\n   \u003ch5\u003eSimulate Late Order \u003c/h5\u003e\n    \u003clabel for\u003d\"orderFieldId\"\u003e Order ID : \u003c/label\u003e\n    \u003cinput type\u003d\"text\" class\u003d\"form-control\" id\u003d\"orderFieldId\" placeholder\u003d Order id ...\" ng-model\u003d\"orderId\"\u003e\u003c/input\u003e\n    \u003clabel for\u003d\"delayFieldId\"\u003eDelay in Days: \u003c/label\u003e\n    \u003cinput type\u003d\"text\" class\u003d\"form-control\" id\u003d\"delayFieldId\" placeholder\u003d Delay Days ...\" ng-model\u003d\"delayDays\"\u003e\u003c/input\u003e\n      \u003cbutton type\u003d\"submit\" class\u003d\"btn btn-primary\" ng-click\u003d\"z.angularBind(\u0027orderId\u0027,orderId,\u002720170625-202310_651912174\u0027);z.angularBind(\u0027delayDays\u0027,delayDays,\u002720170625-202310_651912174\u0027); z.runParagraph(\u002720170625-202310_651912174\u0027)\"\u003e Run What-If\u003c/button\u003e\n  \u003c/div\u003e\n\n\u003c/form\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139928_14213738",
      "id": "20170627-003424_154469379",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If Simulation Code",
      "text": "%spark\n\nval splicemachineContext \u003d new SplicemachineContext(defaultJDBCURL)\nval InventoryTable \u003d \"timeline.timeline_int\"\nval TOTable \u003d \"timeline.transferorders\"\nval stockoutTable \u003d \"timeline.STOCKOUTS\"\nval CHANGE_AT_ST \u003d 0\nval CHANGE_AT_ET \u003d 1\nval tempTableColsWithPKey : String  \u003d \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n\ndef createTempInvTable (smContext :SplicemachineContext, source : Long, dest : Long): String \u003d {\n    \n    var tempTable \u003d\"Timeline.\"+  \"TEMP_INV_\" + org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n            while(smContext.tableExists( tempTable))\n                tempTable \u003d\"Timeline.\"+  \"TEMP_INV_\" +org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n    \n    \n    \n    val tempOptions \u003d Map(\n         org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -\u003e tempTable,\n        org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -\u003e defaultJDBCURL\n    )\n\n    val tempJDBCOptions \u003d new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(tempOptions)\n\n    \n    val conn \u003d JdbcUtils.createConnectionFactory(tempJDBCOptions)()\n    try {\n    conn.createStatement().execute(\"create table \" + tempTable + tempTableColsWithPKey)\n    } finally {\n      conn.close()\n    }\n    \n    //insert \n    val stmt \u003d \"select *  FROM timeline.timeline_int  WHERE Timeline_Id  in ( \" + source + \", \"+ dest +\")\"\n    val timesDf \u003d splicemachineContext.df(stmt)\n    smContext.insert(timesDf,tempTable )\n   tempTable\n \n    \n}\n\ndef whatif(smContext :SplicemachineContext,\n            tempInvTable: String,\n           source: Integer,\n           destination: Integer,\n           shippingDate: Timestamp,\n           deliveryDate: Timestamp,\n           newDeliveryDate : Timestamp,\n           qty: Long,\n           retryCount: Integer \u003d 0,\n           revertFlag: Boolean): Unit \u003d {\n\n        val conn: Connection \u003d smContext.getConnection()\n         try {\n          conn.setAutoCommit(false) //TBD - Need to set to false when DBAAS-570 is resolved\n          update(tempInvTable, source, shippingDate, deliveryDate,  qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, deliveryDate,  -qty, CHANGE_AT_ET)\n          update(tempInvTable, source, shippingDate, newDeliveryDate,  -qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, newDeliveryDate,  qty, CHANGE_AT_ET)\n          conn.commit()\n          \n        }\n        catch {\n          case exp: WriteConflict \u003d\u003e {\n            conn.rollback()\n            conn.setAutoCommit(true)\n            if (retryCount \u003c MAX_RETRIES) {\n              println(\"Retrying create TO\" + source + \" \" + destination + \" \" + shippingDate + \" \" + deliveryDate + \" \" + qty + \" \" + retryCount + 1)\n              whatif(smContext, tempInvTable,source, destination, shippingDate, deliveryDate, newDeliveryDate, qty, retryCount + 1, revertFlag)\n            }\n            else {\n              // put code here to handle too many retries\n            }\n          }\n          case e: Throwable \u003d\u003e println(s\"Got some other kind of exception: $e\")\n        }\n        finally {\n          conn.setAutoCommit(true)\n        }\n      }\n      \n      \n  // Will need to copy the inventory table so that what-if is not visible to others\n\n  val transferOrdersTable \u003d Map(\n    JDBCOptions.JDBC_TABLE_NAME -\u003e \"Timeline.TransferOrders\",\n    JDBCOptions.JDBC_URL -\u003e defaultJDBCURL\n    ) \n  val orderid \u003d z.angular(\"orderId\").toString.toLong\n  val q \u003d s\"select *  FROM timeline.transferorders WHERE to_id \u003d $orderid\"\n  val order \u003d splicemachineContext.df(q)\n  \n   val days \u003d z.angular(\"delayDays\").toString.toInt\n \n  if(order.count \u003e 0 \u0026\u0026 days \u003e 0) {\n    //  val days: Int \u003d 5\n      val source \u003d order.first().getAs(\"SOURCEINVENTORY\").asInstanceOf[Long]\n      val dest \u003d order.first().getAs(\"DESTINATIONINVENTORY\").asInstanceOf[Long]\n      val ship \u003d order.first().getAs(\"SHIPDATE\").asInstanceOf[Timestamp]\n      val delivery \u003d order.first().getAs(\"DELIVERYDATE\").asInstanceOf[Timestamp]\n      val qty \u003d order.first().getAs(\"QTY\").asInstanceOf[Long]\n      val newDelivery \u003dnew Timestamp( new org.joda.time.DateTime (delivery).plusDays(days).getMillis())\n      \n      //Populate stockouts before What If\n      \n     val queryBefore \u003d s\"\"\"SELECT t.to_id, i.ST, i.timeline_id FROM $InventoryTable i  , $TOTable t\n        WHERE i.timeline_id \u003d $dest\n        AND t.sourceinventory \u003d i.timeline_id\n        AND val \u003c 0\n        AND i.ST \u003c\u003d  t.shipdate\n        AND  t.shipdate \u003c i.ET\n        ORDER BY i.ST\"\"\"\n    \n       println(s\"q\u003d$queryBefore\")\n      val stockOutsBefore \u003d splicemachineContext.df(queryBefore)\n  \n      splicemachineContext.insert(stockOutsBefore, stockoutTable)\n      z.run(\"20170621-055239_1661420434\")\n      z.run(\"20170628-152508_1831563439\")\n      \n      val tempInventoryTable \u003d createTempInvTable(splicemachineContext,source,dest)\n      \n      whatif(splicemachineContext,tempInventoryTable,source.toInt, dest.toInt, ship, delivery, newDelivery, qty, days, false)\n      \n      val destInvCol \u003d TOTable + \".destinationinventory \"\n      val timelineIdCol \u003d tempInventoryTable + \".timeline_id \"\n      val toIdCol \u003d TOTable + \".to_id \"\n      val stCol \u003d tempInventoryTable + \".ST \"\n      val etCol \u003d tempInventoryTable + \".ET \"\n      val delDateCol \u003d TOTable + \".deliverydate \"\n      val shipDateCol \u003d  TOTable + \".shipdate \"\n      val sourceInvCol \u003d TOTable + \".sourceinventory \"\n      val latCol \u003d TOTable + \".latitude \"\n      val longCol \u003d TOTable + \".longitude \"\n      val srcWeatherCol \u003d TOTable + \".fromweather \"\n      val destWeatherCol \u003d TOTable + \".toweather \"\n      /*\n      val query \u003d s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n                        WHERE $timelineIdCol \u003d $dest\n                        AND $destInvCol \u003d $timelineIdCol\n                        AND val \u003c 0\n                        AND $stCol \u003e\u003d $delDateCol\n                        ORDER BY $stCol\"\"\"\n                        println(s\"q\u003d$query\")\n                        */\n   \n     val query \u003d s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n        WHERE $timelineIdCol \u003d $dest\n        AND $sourceInvCol \u003d $timelineIdCol\n        AND val \u003c 0\n        AND $stCol \u003c\u003d  $shipDateCol\n        AND  $shipDateCol \u003c $etCol\n        ORDER BY $stCol\"\"\"\n    \n    println(s\"q\u003d$query\")\n      val stockOuts \u003d splicemachineContext.df(query)\n  \n     // whatif(source.toInt, dest.toInt, ship, delivery, newDelivery, qty, 5, true) // undo what-if \n      splicemachineContext.insert(stockOuts, stockoutTable)\n      z.run(\"20170716-165322_7991113\")\n      z.run(\"20170628-152508_1831563439\")\n     // splicemachineContext.dropTable(tempInventoryTable)\n   } else {\n    println(\" NO ORDERS FOUND FOR ORDER ID \" + orderid)\n   }\n  \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-30 22:46:54.989",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "orderid": "19"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nsplicemachineContext: com.splicemachine.spark.splicemachine.SplicemachineContext \u003d com.splicemachine.spark.splicemachine.SplicemachineContext@4adcbaa0\n\nInventoryTable: String \u003d timeline.timeline_int\n\nTOTable: String \u003d timeline.transferorders\n\nstockoutTable: String \u003d timeline.STOCKOUTS\n\nCHANGE_AT_ST: Int \u003d 0\n\nCHANGE_AT_ET: Int \u003d 1\n\ntempTableColsWithPKey: String \u003d (Timeline_Id bigint, ST timestamp, ET timestamp, Val bigint, primary key (Timeline_ID, ST))\n\ncreateTempInvTable: (smContext: com.splicemachine.spark.splicemachine.SplicemachineContext, source: Long, dest: Long)String\n\nwhatif: (smContext: com.splicemachine.spark.splicemachine.SplicemachineContext, tempInvTable: String, source: Integer, destination: Integer, shippingDate: java.sql.Timestamp, deliveryDate: java.sql.Timestamp, newDeliveryDate: java.sql.Timestamp, qty: Long, retryCount: Integer, revertFlag: Boolean)Unit\n\ntransferOrdersTable: scala.collection.immutable.Map[String,String] \u003d Map(dbtable -\u003e Timeline.TransferOrders, url -\u003e jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin)\n\norderid: Long \u003d 4\n\nq: String \u003d select *  FROM timeline.transferorders WHERE to_id \u003d 4\n\norder: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [TO_ID: bigint, PO_ID: bigint ... 17 more fields]\n\ndays: Int \u003d 5\nq\u003dSELECT t.to_id, i.ST, i.timeline_id FROM timeline.timeline_int i  , timeline.transferorders t\n        WHERE i.timeline_id \u003d 900\n        AND t.sourceinventory \u003d i.timeline_id\n        AND val \u003c 0\n        AND i.ST \u003c\u003d  t.shipdate\n        AND  t.shipdate \u003c i.ET\n        ORDER BY i.ST\nq\u003dSELECT timeline.transferorders.to_id , Timeline.TEMP_INV_BZTTCS.ST , Timeline.TEMP_INV_BZTTCS.timeline_id  FROM Timeline.TEMP_INV_BZTTCS , timeline.transferorders\n        WHERE Timeline.TEMP_INV_BZTTCS.timeline_id  \u003d 900\n        AND timeline.transferorders.sourceinventory  \u003d Timeline.TEMP_INV_BZTTCS.timeline_id \n        AND val \u003c 0\n        AND Timeline.TEMP_INV_BZTTCS.ST  \u003c\u003d  timeline.transferorders.shipdate \n        AND  timeline.transferorders.shipdate  \u003c Timeline.TEMP_INV_BZTTCS.ET \n        ORDER BY Timeline.TEMP_INV_BZTTCS.ST \n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139929_1255247635",
      "id": "20170625-202310_651912174",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs? - Before",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id \u003d Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id \u003d  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id \u003d  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST \u003d  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:09:55.112",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11.0,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                },
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string",
                      "TO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "QTY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "SOURCEINVENTORY": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "SUPPLIER": "string",
                      "CARRIER": "string",
                      "TRANSPORTMODE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139929_-1800321072",
      "id": "20170621-055239_1661420434",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs?  - After",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id \u003d Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id \u003d  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id \u003d  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST \u003d  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:02.351",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11.0,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                },
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ST": "string",
                      "ET": "string",
                      "VAL": "string",
                      "TO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "QTY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "SOURCEINVENTORY": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "SUPPLIER": "string",
                      "CARRIER": "string",
                      "TRANSPORTMODE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139930_1917140175",
      "id": "20170716-165322_7991113",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ndelete from timeline.stockouts where to_id \u003e0;",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 10"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139930_457417555",
      "id": "20170628-152508_1831563439",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Weather",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:06:21.526",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 10.0,
                    "aggr": "sum"
                  },
                  "xAxis": {
                    "name": "FROMWEATHER",
                    "index": 9.0,
                    "aggr": "sum"
                  },
                  "group": {
                    "name": "CARRIER",
                    "index": 8.0,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "FROMWEATHER",
                  "index": 9.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "TOWEATHER",
                  "index": 10.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "NEWDELIVERYDATE",
                  "index": 5.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "98426393"
        },
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139931_1644037477",
      "id": "20170623-175239_660149064",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Route",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "SHIPFROM",
                    "index": 2.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "SHIPTO",
                    "index": 3.0,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139931_-871788617",
      "id": "20170628-143430_93328688",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Num of Late Orders By Lat/Long",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT, timeline.transferorders \nwhere timeline.transferorders.to_id \u003d timeline.TO_DELIVERY_CHG_EVENT.to_id",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "LATITUDE",
                    "index": 28.0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "LONGITUDE",
                    "index": 29.0,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139932_1417513998",
      "id": "20170628-144341_2096133153",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Using Machine Learning to Predict Late Shipments\n\nHere we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.\n\nThe model considers attributes of the orders such as:\n- Mode of Transport\n- Carrier\n- Latitude \n- Longitude\n- Source City\n- Destination City\n- Part.\n\nThe model also considers exogenous data to enrich the inventory data such as weather:\n- weather at source\n- weather at destination.\n\nThe machine learning algorithm outputs a model that can predict whether a shipment is late. \n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:32.076",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eUsing Machine Learning to Predict Late Shipments\u003c/h2\u003e\n\u003cp\u003eHere we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.\u003c/p\u003e\n\u003cp\u003eThe model considers attributes of the orders such as:\u003cbr/\u003e- Mode of Transport\u003cbr/\u003e- Carrier\u003cbr/\u003e- Latitude\u003cbr/\u003e- Longitude\u003cbr/\u003e- Source City\u003cbr/\u003e- Destination City\u003cbr/\u003e- Part.\u003c/p\u003e\n\u003cp\u003eThe model also considers exogenous data to enrich the inventory data such as weather:\u003cbr/\u003e- weather at source\u003cbr/\u003e- weather at destination.\u003c/p\u003e\n\u003cp\u003eThe machine learning algorithm outputs a model that can predict whether a shipment is late.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1543618455011_1246322468",
      "id": "20181130-225415_805598687",
      "dateCreated": "2018-11-30 22:54:15.011",
      "dateStarted": "2018-12-01 07:10:21.254",
      "dateFinished": "2018-12-01 07:10:21.278",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### ML Means No ETL, Just Transformations\n\nSplice Machine is a Hybrid Transactional and Analytics Processing (*HTAP*) platform, so you can perform both transactional and analytical queries. This means that we don\u0027t need to extract and load data; instead, we simply transform it.\n\nBelow we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.\n\nThe first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:38.110",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eML Means No ETL, Just Transformations\u003c/h3\u003e\n\u003cp\u003eSplice Machine is a Hybrid Transactional and Analytics Processing (*HTAP*) platform, so you can perform both transactional and analytical queries. This means that we don\u0026rsquo;t need to extract and load data; instead, we simply transform it.\u003c/p\u003e\n\u003cp\u003eBelow we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.\u003c/p\u003e\n\u003cp\u003eThe first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139934_-1835938020",
      "id": "20170621-070538_308959124",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 22:57:40.958",
      "dateFinished": "2018-11-30 22:57:40.976",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Bin Order Lateness and Label Orders",
      "text": "%splicemachine\n\ndrop table IF EXISTS TIMELINE.FEATURES;\n\nCREATE table TIMELINE.FEATURES AS\nSELECT \n    TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate,  \n    TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN TimeLine.TransferOrders.fromweather \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.fromweather end as currentweather,\n    TimeLine.TransferOrders.*, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN 0 \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate end as Lateness,\n    CASE\n    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate \u003e 0 \n    THEN\n        CASE\n            WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate \u003e 5 \n            THEN\n                CASE \n                    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate \u003e 10\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n\n        END\n    ELSE 0\n    END AS Label\n from TimeLine.TransferOrders Left Outer Join TimeLine.TO_DELIVERY_CHG_EVENT\n on TimeLine.TransferOrders.TO_ID \u003d TimeLine.TO_DELIVERY_CHG_EVENT.TO_ID\n WHERE  TIMESTAMP(\u0027${begin \u003d 2017-05-05 00:00:00.0}\u0027) \u003e\u003d timeline.transferorders.deliverydate \nAND TIMESTAMP(\u0027${end \u003d2017-05-05 00:00:00.0}\u0027) \u003e timeline.transferorders.deliverydate; \n select * from timeline.features\n WHERE TIMESTAMP(\u0027${begin \u003d 2017-05-05 00:00:00.0}\u0027) \u003e\u003d timeline.features.orgdeliverydate \n    AND TIMESTAMP(\u0027${end \u003d2017-05-05 00:00:00.0}\u0027) \u003e timeline.features.orgdeliverydate ;\n \n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:56:46.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {
          "2": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "ORGDELIVERYDATE": "string",
                      "NEWDELIVERYDATE": "string",
                      "CURRENTWEATHER": "string",
                      "TO_ID": "string",
                      "PO_ID": "string",
                      "SHIPFROM": "string",
                      "SHIPTO": "string",
                      "SHIPDATE": "string",
                      "DELIVERYDATE": "string",
                      "MODDELIVERYDATE": "string",
                      "SOURCEINVENTORY": "string",
                      "DESTINATIONINVENTORY": "string",
                      "QTY": "string",
                      "SUPPLIER": "string",
                      "ASN": "string",
                      "CONTAINER": "string",
                      "TRANSPORTMODE": "string",
                      "CARRIER": "string",
                      "FROMWEATHER": "string",
                      "TOWEATHER": "string",
                      "LATITUDE": "string",
                      "LONGITUDE": "string",
                      "LATENESS": "string",
                      "LABEL": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "high": "Timestamp(\u00272014-05-01\u0027)",
          "Start": "",
          "low": "Timestamp(\u00272018-08-01\u0027)",
          "End": "",
          "end": "2017-05-15 00:00:00.0",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "type": "TextBox",
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false
          },
          "begin": {
            "type": "TextBox",
            "name": "begin",
            "defaultValue": " 2017-05-05 00:00:00.0",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542398139935_-1570248896",
      "id": "20170621-115351_1800134706",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### MLlib\n\nMLlib is a rich repository of Transformers and Models. For more information about MLlib, see: \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003ehttps://spark.apache.org/docs/latest/ml-guide.html\u003c/a\u003e\n\nIn this use case, we\u0027ll use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and  10 or over days late. Here are some notes about this:\n\n* The Logistic Regression Model expects a dataframe with two elements: feature Vector and label, which means that we have to extract the columns from the above table into this form.\n* Luckily MLlib has such a transformer called a Vector Assembler.\n\nIn the following paragraphs, we:\n\n1. Create a vector assembler\n2. Train the model\n3. Deploy the model to our prediction table\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:51.152",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eMLlib\u003c/h3\u003e\n\u003cp\u003eMLlib is a rich repository of Transformers and Models. For more information about MLlib, see: \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003e\u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\"\u003ehttps://spark.apache.org/docs/latest/ml-guide.html\u003c/a\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn this use case, we\u0026rsquo;ll use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and 10 or over days late. Here are some notes about this:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eThe Logistic Regression Model expects a dataframe with two elements: feature Vector and label, which means that we have to extract the columns from the above table into this form.\u003c/li\u003e\n  \u003cli\u003eLuckily MLlib has such a transformer called a Vector Assembler.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn the following paragraphs, we:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eCreate a vector assembler\u003c/li\u003e\n  \u003cli\u003eTrain the model\u003c/li\u003e\n  \u003cli\u003eDeploy the model to our prediction table\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_1455601499",
      "id": "20170621-164244_783302183",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-30 23:07:44.266",
      "dateFinished": "2018-11-30 23:07:44.286",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Assemble Feature Vector and Train Model",
      "text": "%spark\n    \n    import org.apache.spark.ml.feature.VectorAssembler\n    import java.sql.{Connection,Timestamp}\n    import com.splicemachine.spark.splicemachine._\n    import org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\n    import org.apache.spark.ml.classification.LogisticRegression\n    import spark.implicits._\n\n    \n    val optionMap \u003d Map(\n      JDBCOptions.JDBC_TABLE_NAME -\u003e \"Timeline.Features\",\n      JDBCOptions.JDBC_URL -\u003e defaultJDBCURL\n    )\n    val dfUpper \u003d sqlContext.read.options(optionMap).splicemachine\n    val newNames \u003d Seq(\"orgdeliverydate\",\"newdeliverydate\",\"currentweather\",\"to_id\",\n      \"po_id\",\"shipfrom\",\"shipto\",\"shipdate\",\"deliverydate\",\"moddeliverydate\",\"sourceinventory\",\n      \"destinationinventory\",\"qty\",\"supplier\",\"asn\",\"container\",\"transportmode\",\"carrier\",\n      \"fromweather\",\"toweather\",\"latitude\",\"longitude\",\"lateness\",\"label\")\n    val df \u003d dfUpper.toDF(newNames: _*)\n    \n    \n    //assemble feature vector from dataframe\n    val assembler \u003d new VectorAssembler()\n      .setInputCols(Array(\"shipfrom\", \"shipto\", \"sourceinventory\", \"destinationinventory\", \"supplier\", \"transportmode\", \"carrier\", \"fromweather\", \"toweather\"))\n      .setOutputCol(\"features\")\n    \n    val output \u003d assembler.transform(df)\n    println(\"Assembled columns ShipFrom, ShipTo, SourceInventory, DestinationInventory, Supplier, TransportMode, Carrier, FromWeather, ToWeather to vector column \u0027features\u0027\")\n    output.select(\"features\", \"label\").show(true)\n    \n    // Set parameters for the algorithm.\n    // Here, we limit the number of iterations to 10.\n    val lr \u003d new LogisticRegression()\n        .setMaxIter(10)\n\n        \n    \n    // Fit the model to the data.\n    val model \u003d lr.fit(output)\n    \n   //Get the number of classes in Label\n     val numClasses \u003d model.numClasses\n    // Given a dataset, predict each point\u0027s label, and show the results.\n    val newdf \u003d model.transform(output)\n    \n    // Print the coefficients and intercept for multinomial logistic regression\n    println(s\"Coefficients: \\n${model.coefficientMatrix}\")\n    println(s\"Intercepts: ${model.interceptVector}\")\n    \n    ",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:10:58.207",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_-1971148676",
      "id": "20170621-164423_1216161315",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Deploy Model to Prediction Table",
      "text": "%spark\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.sql.types.{StructType,StructField,DoubleType, LongType}\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.catalyst.encoders.RowEncoder\n\nval predictionTable \u003d \"timeline.predictions\"\n\nvar labelCnt \u003d numClasses\n//Only allow max of 10 lables\nif(labelCnt \u003e 10)\n    labelCnt \u003d10\n\n    \n newdf.printSchema()\n \n    \n    var schema \u003d StructType(\n    StructField(\"TO_ID\", LongType, false) :: Nil)\n   \n    \n    var i\u003d0;\n    for (i \u003c- 1 to labelCnt) {\n        schema \u003d schema.add( StructField(\"LATENESSBIN\"+i, DoubleType, false) )\n    }\n           \n    \nval encoder \u003d RowEncoder(schema)\n \n val pred \u003d newdf\n  .select( \"features\", \"label\", \"probability\", \"prediction\", \"to_id\")\n  .map { case Row( features: Vector, label: Integer, prob: Vector, prediction: Double, idd:Long) \u003d\u003e \n  \n    var seq1 : Seq[Any] \u003d Seq(idd.asInstanceOf[Number].longValue())\n    var j\u003d0;\n    for (j \u003c- 1 to labelCnt) {\n        seq1 \u003d seq1:+ ( prob(j-1).asInstanceOf[Number].doubleValue())\n    }\n    println(seq1)\n     Row.fromSeq(seq1)   \n    }(encoder)\n    \n    \n  splicemachineContext.update(pred, predictionTable) \n  pred.show()\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 11:55:39.000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398139937_467778342",
      "id": "20170626-132011_1256759754",
      "dateCreated": "2018-11-16 11:55:39.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\nWe\u0027ll now continue our exploration of Machine Learning with Splice Machine by implementing a [*KMeans clustering algorithm*](/#/notebook/2DX6TGACY) in a Splice Machine Zeppelin notebook.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:11:16.344",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eWhere to Go Next\u003c/h2\u003e\n\u003cp\u003eWe\u0026rsquo;ll now continue our exploration of Machine Learning with Splice Machine by implementing a \u003ca href\u003d\"/#/notebook/2DX6TGACY\"\u003e\u003cem\u003eKMeans clustering algorithm\u003c/em\u003e\u003c/a\u003e in a Splice Machine Zeppelin notebook.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398139938_-585719086",
      "id": "20170714-192918_375392082",
      "dateCreated": "2018-11-16 11:55:39.000",
      "dateStarted": "2018-11-20 10:52:00.343",
      "dateFinished": "2018-11-20 10:52:00.347",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training/For Data Scientists/i. Predicting Supply Chain Shortages",
  "id": "2DY411M2A",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "splicemachine:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}