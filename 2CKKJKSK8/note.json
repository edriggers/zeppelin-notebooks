{
  "paragraphs": [
    {
      "text": "%md\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles.css\" />\n\n# Crystal Ball\nThe Crystal Ball application is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. With the crystall ball you can:\n\n1. Perform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments\n2. Learn when shipments are likely to be late\n3. Anticipate stock outs due to predicted late orders\n4. Determine what customers or downstream orders are affected by anticipated stockouts.\n\nWhen supply chain managers have the crystal ball, they can:\n-- plan around stock outs\n-- warn down stream consumers so they can re-plan.\n\n",
      "user": "splice",
      "dateUpdated": "2018-08-02T14:47:55+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles.css\" />\n<h1>Crystal Ball</h1>\n<p>The Crystal Ball application is a supply chain reference application relevant to manufacturers, distributors, retailers, and e-commerce companies. With the crystall ball you can:</p>\n<ol>\n  <li>Perform Available-to-Promise (ATP) inquiries in seconds on real-time inventory changes due to purchases, manufacturing, sales, and shipments</li>\n  <li>Learn when shipments are likely to be late</li>\n  <li>Anticipate stock outs due to predicted late orders</li>\n  <li>Determine what customers or downstream orders are affected by anticipated stockouts.</li>\n</ol>\n<p>When supply chain managers have the crystal ball, they can:<br/>&ndash; plan around stock outs<br/>&ndash; warn down stream consumers so they can re-plan.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708936_46133131",
      "id": "20170621-041621_785608971",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "dateStarted": "2018-08-02T14:47:55+0000",
      "dateFinished": "2018-08-02T14:47:57+0000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500,
      "focus": true,
      "$$hashKey": "object:58884"
    },
    {
      "text": "%spark\n  println(\"Please copy and paste your JDBC URL. You can find it at the bottom right of your cluster dashboard\")\n  val defaultJDBCURL = z.input(\"JDBCurl\",\"\"\"jdbc:splice://{FRAMEWORKNAME}-proxy.marathon.mesos:1527/splicedb;user=splice;password=admin;useSpark=true\"\"\").toString\n  val localJDBCURL = \"\"\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin\"\"\"\n",
      "user": "splice",
      "dateUpdated": "2018-08-02T14:48:17+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "JDBCurl": "jdbc:splice://localhost:1527/splicedb;user=splice;password=admin"
        },
        "forms": {
          "JDBCurl": {
            "name": "JDBCurl",
            "displayName": "JDBCurl",
            "type": "input",
            "defaultValue": "jdbc:splice://{FRAMEWORKNAME}-proxy.marathon.mesos:1527/splicedb;user=splice;password=admin;useSpark=true",
            "hidden": false,
            "$$hashKey": "object:59998"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708947_55751854",
      "id": "20170622-063514_1166002275",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58885"
    },
    {
      "title": "Timeline  Code",
      "text": "%spark\nimport java.sql.{Connection,Timestamp}\nimport java.util.Date\nimport com.splicemachine.si.api.txn.WriteConflict\nimport org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\nimport com.splicemachine.spark.splicemachine._\n    \n  val table = \"TimeLine_Int\"\n  val schema = \"TimeLine\"\n  val internalTN = schema + \".\" + table\n  val startOfTimeStr = \"1678-01-01 00:00:00\"\n  val endOfTimeStr = \"2261-12-31 00:00:00\"\n  val startOfTime = java.sql.Timestamp.valueOf(startOfTimeStr)\n  val endOfTime = java.sql.Timestamp.valueOf(endOfTimeStr)\n  val MAX_RETRIES: Integer = 2\n\n  val SQL_ID = 1\n  val SQL_ST = 2\n  val SQL_ET = 3\n  val SQL_VAL = 4\n  val DF_ID = 0\n  val DF_ST = 1\n  val DF_ET = 2\n  val DF_VAL = 3\n  \n  val columnsWithPrimaryKey: String  = \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n  val columnsWithoutPrimaryKey = \"(\" + \"Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint \" + \")\"\n  val primaryKeys = Seq(\"Timeline_ID, ST\")\n  val columnsInsertString = \"(\" + \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Val\" + \") \"\n  val columnsSelectString = \"Timeline_Id, \" + \"ST, \" + \"ET, \" + \"Value\"\n  val columnsInsertStringValues = \"values (?,?,?,?)\"\n\n\n  /* (t1<=ST and t2>ST) or (t1>ST and t1<ET)  (t1 t2 t1 t1 )*/\n  val overlapCondition = \"where Timeline_Id = ? and ((ST >=? and ST <?) or ((ST < ?) and (ET > >?)))\"\n\n\n  val internalOptions = Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> internalTN,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n  )\n\n  val internalJDBCOptions = new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(internalOptions)\n  val splicemachineContext =  new com.splicemachine.spark.splicemachine.SplicemachineContext(defaultJDBCURL)\n\n\n\n  /**\n    *\n    * createTimeline (table)\n    *\n    * @param table table name of timeline\n    * @return\n    */\n  def createTimeline(table: String, columnsWithPrimaryKey: String , internalJDBCOptions: JDBCOptions = internalJDBCOptions ): Unit = {\n    val conn = JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    if (splicemachineContext.tableExists(table)){\n      conn.createStatement().execute(\"drop table \" + table)\n    }\n    conn.createStatement().execute(\"create table \" + table + columnsWithPrimaryKey)\n  }\n  \n  \n  \n  /**\n    *\n    * initialize (id startOfTime endOfTime value)\n    *\n    * @param table table name of timeline\n    * @param id id of timeline\n    * @param value initial value of timeline\n    * @return\n    */\n def initialize(table: String, id: Integer, value: Integer, columnsInsertString : String = columnsInsertString ,columnsInsertStringValues :String = columnsInsertStringValues  , internalJDBCOptions :JDBCOptions = internalJDBCOptions ): Unit = {\n    val conn = JdbcUtils.createConnectionFactory(internalJDBCOptions)()\n    val start: Timestamp = startOfTime\n    val end: Timestamp = endOfTime\n    try {\n      var ps = conn.prepareStatement(\"delete from \" + table + \" where timeline_id = \" + id)\n      ps.execute()\n      ps = conn.prepareStatement(\"insert into \" + table + columnsInsertString + columnsInsertStringValues)\n      ps.setInt(SQL_ID, id)\n      ps.setTimestamp(SQL_ST, start)\n      ps.setTimestamp(SQL_ET, end)\n      ps.setInt(SQL_VAL, value)\n      ps.execute()\n    } finally {\n      conn.close()\n    }\n  }\n\n  val CHANGE_AT_ST = 0\n  val CHANGE_AT_ET = 1\n  val CHANGE_BETWEEN_ST_ET =2\n  \n\n  /**\n    * splitMiddle - The new delta interval is subsumed by one interval.\n    *\n    *  ST------------ET\n    *      t1---t2         ==>   ST---t1 t1----t2 t2----ET\n    *\n    * Change the original interval to end at the start of the new delta interval\n    * Create a new record for the delta and apply the delta value\n    * Create a new record for the interval from the delta to the end of the original interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    *\n    */\n    \n                \n  def splitMiddle(id: Integer,\n                  t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                  delta: Long,\n                  persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT')\")\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldET = df.first().getTimestamp(DF_ET)\n\n      /* Update containing interval to be the begin split */\n      val updatedDF = df\n        .filter(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* calculate persistence */\n      val firstValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal + delta\n        case _                     => 0\n      }\n\n      /* Insert the two new splits */\n      /* Note - the second new split will have delta added\n\t\tin the persistAfter method\n       */\n      val newDF = sqlContext.createDataFrame(Seq(\n        (id, t1, t2, firstValue),\n        (id, t2, oldET, oldVal)))\n        .toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n\n  /***\n    * \tsplitAtEnd - Delta overlaps beginning of interval.\n    *\n    *         ST------ET\n    *      t1---t2         ==>  ST---t2 t2----ET\n    *\n    * Change the interval to end at the end of the delta then add a split from end of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n    \n     \n  def splitAtEnd(id: Integer,\n                 t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                 delta: Long,\n                 persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"\"\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT') AND ST < to_utc_timestamp('$t2','GMT')\"\"\")\n\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldST = df.first().getTimestamp(DF_ST)\n      var oldET = df.first().getTimestamp(DF_ET)\n      /* Update overlapping interval to be the begin split */\n\n      /* calculate persistence */\n      /* Note - the second new split will have delta added\n          in the persistAfter method if required\n */\n      val firstValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal + delta\n        case _                     => 0\n      }\n\n      val updatedDF = df\n\t    .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET > to_utc_timestamp('$t2','GMT') AND ST < to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t2))\n      .withColumn(\"VAL\", lit(firstValue))\n      splicemachineContext.update(updatedDF, internalTN)\n\n      /* Insert a new split after the delta */\n      val newDF = sqlContext.createDataFrame(Seq((id, t2, oldET, oldVal))).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n  }\n\n  /**\n    * \tsplitAtStart - Delta overlaps end of interval.\n    *\n    *         ST-----ET\n    *            t1------t2         ==>    ST---t1 t1---ET\n    *\n    * Change the interval to end at the start of the delta then add a split from beginning of delta to the end of interval\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n   \n  def splitAtStart(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long, persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n    val df = sqlContext.read.options(internalOptions).splicemachine.where(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND \" +\n                s\"ET < to_utc_timestamp('$t2','GMT') AND ET > to_utc_timestamp('$t1','GMT')\")\n    if (df.count() > 0) {\n\n      /* Save old values */\n      var oldVal = df.first().getLong(DF_VAL)\n      var oldST = df.first().getTimestamp(DF_ST)\n      var oldET = df.first().getTimestamp(DF_ET)\n\n      /* calculate persistence */\n      val newValue: Long = persistence match {\n        case CHANGE_AT_ST          => oldVal + delta\n        case CHANGE_AT_ET          => oldVal\n        case CHANGE_BETWEEN_ST_ET  => oldVal\n        case _                     => 0\n      }\n      /* Update overlapping interval to be the begin split */\n      val updatedDF = df\n        .filter(s\"TIMELINE_ID = $id AND ST < to_utc_timestamp('$t1','GMT') AND ET < to_utc_timestamp('$t2','GMT') AND ET > to_utc_timestamp('$t1','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"ET\", lit(t1))\n      .withColumn(\"VAL\", lit(newValue))\n      splicemachineContext.update(updatedDF, internalTN)\n      \n      /* Insert a new split */\n      val newDF = sqlContext.createDataFrame(Seq(\n        (id, t1, oldET, oldVal)\n      )).toDF(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      splicemachineContext.insert(newDF, internalTN)\n    }\n }\n                   \n    \n  /***\n    *   changeNoSplit - Handles all intervals contained by delta\n    *\n    *           ST-----ET\n    *     t1---------------t2\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def changeNoSplit(id: Integer,\n                    t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                    delta: Long,\n                    persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n           \n    val df = sqlContext.read.options(internalOptions).splicemachine\n      .where(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET <= to_utc_timestamp('$t2','GMT')\")\n\n    /* Calculate persistence */\n    val increment: Long = persistence match {\n      case CHANGE_AT_ST          => delta\n      case CHANGE_AT_ET          => 0\n      case CHANGE_BETWEEN_ST_ET  => delta\n      case _                     => 0\n    }\n    val updatedDF = df\n      .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t1','GMT') AND ET <= to_utc_timestamp('$t2','GMT')\")\n      .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + increment)\n\n    splicemachineContext.update(updatedDF, internalTN)\n  }\n\n  /***\n    *   persistAfter - changes the values for all intervals after delta\n    *\n    *     t1---------------t2  ST-----ET\n    *\n    *  No splits required since always initialized with infinite time, just need values changed\n    *\n    * @param id - the id of the timeline to update\n    * @param t1 - the start of new delta\n    * @param t2 - the end of the new delta\n    * @param delta - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                      CHANGE_AT_ET persists delta from t2 onwards\n    *                      CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n  def persistAfter(id: Integer,\n                   t1: java.sql.Timestamp, t2: java.sql.Timestamp,\n                   delta: Long,\n                   persistence: Int,\n                  internalTN : String =internalTN ,\n                  internalOptions : Map[String,String] = internalOptions): Unit = {\n\n    /* Persist delta after new splits if necesary */\n    if (persistence != CHANGE_BETWEEN_ST_ET) {\n      val persistDF = sqlContext.read.options(internalOptions).splicemachine\n        .filter(s\"TIMELINE_ID = $id AND ST >= to_utc_timestamp('$t2','GMT')\")\n        .select(\"TIMELINE_ID\", \"ST\", \"ET\", \"VAL\")\n      .withColumn(\"VAL\", col(\"VAL\") + delta)\n      splicemachineContext.update(persistDF, internalTN)\n    }\n  }\n\n  /** *\n    * update - increases/decreases the value for the interval\n    * from the start, end or during the interval\n    *\n    * @param table       - the name of the timeline table\n    * @param id          - the id of the timeline to update\n    * @param t1          - the start of new delta\n    * @param t2          - the end of the new delta\n    * @param delta       - an integer increment to the timeline\n    * @param persistence - CHANGE_AT_ST persists delta from t1 onwards\n    *                    CHANGE_AT_ET persists delta from t2 onwards\n    *                    CHANGE_BETWEEN_ST_ET persists delta during [t1 t2]\n    */\n\n  def update(table: String,\n             id: Integer,\n             t1: Timestamp, t2: Timestamp,\n             delta: Long,\n             persistence: Int): Unit = {\n                \n\n   val intOptions = Map(\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> table,\n    org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n  )\n    changeNoSplit(id, t1, t2, delta, persistence, table,intOptions )\n    splitAtStart(id, t1, t2, delta, persistence, table,intOptions)\n    splitMiddle(id, t1, t2, delta, persistence, table,intOptions)\n    splitAtEnd(id, t1, t2, delta, persistence, table,intOptions)\n    persistAfter(id, t1, t2, delta, persistence, table,intOptions)\n  }\n\n\n\n\n\n\n",
      "user": "splice",
      "dateUpdated": "2018-08-02T14:48:56+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708948_53828109",
      "id": "20170622-231413_1135446195",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58886"
    },
    {
      "text": "%md\n### Application Requirements\n\n* Streaming inventory movements - ASN - EDI856\n* Streaming ancilary data like real-time weather\n* Needle-in-Haystack OLTP queries and range scans for ATP\n* ACID Transactions for concurrent inventory changes\n* OLAP for analysis and feature engineering\n* OLAP for inventory projections\n* Machine Learning\n* UI for Collaboration\n\nSplice Machine has all these components pre-integrated and optimized",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Application Requirements</h3>\n<ul>\n  <li>Streaming inventory movements - ASN - EDI856</li>\n  <li>Streaming ancilary data like real-time weather</li>\n  <li>Needle-in-Haystack OLTP queries and range scans for ATP</li>\n  <li>ACID Transactions for concurrent inventory changes</li>\n  <li>OLAP for analysis and feature engineering</li>\n  <li>OLAP for inventory projections</li>\n  <li>Machine Learning</li>\n  <li>UI for Collaboration</li>\n</ul>\n<p>Splice Machine has all these components pre-integrated and optimized</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708949_53443360",
      "id": "20170621-041831_354747046",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58887"
    },
    {
      "text": "%md\n### Ingest Advanced Shipping Notices - Transfer Orders\n\nHere you can copy and paste these data ingestion calls.\n\nThe data was generated by a supply-chain simulator http://localhost:8080/#/notebook/2CKG62TQU.\n\nThe simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates. \n\nThe generator randomly selects features for the transfer orders. \n\nThe files below reflect the state of the database after the simulation runs.\n\nThe orders and change orders are independent files that can be loaded separately.\n\nThe simulation runs are cumulative meaning demo has the inventory timelines for the test data and the train data. \n\nSo to use the demo data. Load train and test for orders and change orders and the load the demo inventory timeline file.\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Ingest Advanced Shipping Notices - Transfer Orders</h3>\n<p>Here you can copy and paste these data ingestion calls.</p>\n<p>The data was generated by a supply-chain simulator <a href=\"http://localhost:8080/#/notebook/2CKG62TQU\">http://localhost:8080/#/notebook/2CKG62TQU</a>.</p>\n<p>The simulator ticks through time randomly inserting Transfer Orders and also randomly inserts changes to Transfer Orders delivery dates. </p>\n<p>The generator randomly selects features for the transfer orders. </p>\n<p>The files below reflect the state of the database after the simulation runs.</p>\n<p>The orders and change orders are independent files that can be loaded separately.</p>\n<p>The simulation runs are cumulative meaning demo has the inventory timelines for the test data and the train data. </p>\n<p>So to use the demo data. Load train and test for orders and change orders and the load the demo inventory timeline file.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708950_54597607",
      "id": "20170621-044326_1460127976",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58888"
    },
    {
      "title": "Initialize",
      "text": "%spark\n\nz.run(\"20170622-063514_1166002275\"); // JDBC URL\nz.run(\"20170622-231413_1135446195\"); // Timeline Code\nz.run(\"20170622-222153_977899468\"); // DDL\nz.run(\"20170623-174025_718327456\"); // Load Data\n\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708951_54212858",
      "id": "20170628-085245_2111524765",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58889"
    },
    {
      "text": "%splicemachine\ncreate schema TIMELINE;\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-03T21:11:37+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708952_52289114",
      "id": "20170703-142111_1098530498",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58890"
    },
    {
      "title": "Create Schema",
      "text": "%splicemachine\n\ndrop table IF EXISTS  TIMELINE.TRANSFERORDERS;\ndrop table IF EXISTS  TIMELINE.TO_DELIVERY_CHG_EVENT;\ndrop table IF EXISTS  TIMELINE.TIMELINE_INT;\ndrop table IF EXISTS TIMELINE.STOCKOUTS;\n\n\n\ncreate table TIMELINE.TRANSFERORDERS(\n    TO_ID   BIGINT,\n    PO_ID   BIGINT,\n    SHIPFROM BIGINT,\n    SHIPTO  BIGINT,\n    SHIPDATE TIMESTAMP,\n    DELIVERYDATE TIMESTAMP,\n    MODDELIVERYDATE TIMESTAMP,\n    SOURCEINVENTORY BIGINT,\n    DESTINATIONINVENTORY BIGINT,\n    QTY BIGINT,\n    SUPPLIER BIGINT,\n    ASN VARCHAR(100),\n    CONTAINER VARCHAR(100),\n    TRANSPORTMODE SMALLINT,\n    CARRIER BIGINT,\n    FROMWEATHER SMALLINT,\n    TOWEATHER SMALLINT,\n    LATITUDE  DOUBLE,\n    LONGITUDE DOUBLE,\n    primary key (TO_ID)\n    );\n\ncreate index TIMELINE.TOSTIDX on TRANSFERORDERS (\n    ShipDate,\n    TO_Id\n );\n \n create index TIMELINE.TOETIDX on TRANSFERORDERS (\n    Deliverydate,\n    TO_Id\n );\n\ncreate table TIMELINE.TO_DELIVERY_CHG_EVENT(\n    TO_event_Id bigint,\n    TO_Id bigint ,\n    ShipFrom bigint,\n    ShipTo bigint,\n    OrgDeliveryDate timestamp,\n    newDeliveryDate timestamp,\n    Supplier varchar(100) ,\n    TransportMode smallint ,\n    Carrier bigint ,\n    Fromweather smallint,\n    ToWeather smallint,\n    primary key (TO_event_Id)\n    );\n    \ncreate table TIMELINE.TIMELINE_INT(\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    ET          TIMESTAMP,\n    VAL         BIGINT,\n    primary key (Timeline_Id, ST)\n    );\n    \ncreate table TIMELINE.STOCKOUTS(\n    TO_ID   BIGINT,\n    Timeline_Id BIGINT,\n    ST          TIMESTAMP,\n    primary key (TO_ID,ST)\n    );\n    \n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:16:32+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708953_51904365",
      "id": "20170622-222153_977899468",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58891"
    },
    {
      "title": "Load Train Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/train_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/data_0623/train_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/train_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:18:18+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708954_53058611",
      "id": "20170623-174025_718327456",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58892"
    },
    {
      "title": "Load Test Data",
      "text": "%splicemachine\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/test_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/data_0623/test_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/test_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1501790708955_52673862",
      "id": "20170628-222352_2120811555",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58893"
    },
    {
      "title": "Load Demo Data",
      "text": "%splicemachine\n\n\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TRANSFERORDERS',null, 's3a://splice-demo/supplychain/data_0623/demo_orders.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TO_DELIVERY_CHG_EVENT', null, 's3a://splice-demo/supplychain/demo_0623/demo_events.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\ncall SYSCS_UTIL.IMPORT_DATA('TIMELINE','TIMELINE_INT', null, 's3a://splice-demo/supplychain/data_0623/demo_inv.csv', null, null, 'yyyy-MM-dd HH:mm:ss.S', null, null, -1, '/tmp', true, null);\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1501790708956_50750118",
      "id": "20170628-222451_440347172",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58894"
    },
    {
      "title": "Transfer Orders",
      "text": "%splicemachine\nselect * from timeline.transferorders\n\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:18:51+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "304"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708957_50365369",
      "id": "20170623-175231_773807313",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58895"
    },
    {
      "text": "%md\n### Timelines\n\nTimelines are a relational representation of temporal data for AI applications \n\nTimelines record historical, present and future values.\n\nA timeline table contains a collection of timelines, each with a unique id.\nEvery row represents: `TIMELINE_ID = VAL @ [ST ET]` meaning the variable denoted by the id has the value over that time interval\n\nTimelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.\n\nTimelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.\n\nFor example, you have to make sure that when you move an order that the decrement to the source inventory changes atomically with the change to the destination inventory.",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Timelines</h3>\n<p>Timelines are a relational representation of temporal data for AI applications </p>\n<p>Timelines record historical, present and future values.</p>\n<p>A timeline table contains a collection of timelines, each with a unique id.<br/>Every row represents: <code>TIMELINE_ID = VAL @ [ST ET]</code> meaning the variable denoted by the id has the value over that time interval</p>\n<p>Timelines require indexed row-based storage and an OLTP compute engine to quickly look up values associated at times.</p>\n<p>Timelines require ACID properties because they serve concurrent users changing timelines plus all the timeline updates require atomic changes to timelines.</p>\n<p>For example, you have to make sure that when you move an order that the decrement to the source inventory changes atomically with the change to the destination inventory.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708961_36514409",
      "id": "20170621-050328_679054277",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58896"
    },
    {
      "title": "Tracking Inventory As Timelines",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere TIMELINE_ID = ${inv=200}\norder by TIMELINE.TIMELINE_INT.ST;",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:14:35+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "ST",
                  "index": 1,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 3,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200"
        },
        "forms": {
          "inv": {
            "name": "inv",
            "defaultValue": "200",
            "hidden": false,
            "$$hashKey": "object:60748"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708962_37668655",
      "id": "20170621-052218_96471785",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58897"
    },
    {
      "title": "Stock Outs",
      "text": "%splicemachine\nselect * from timeline.timeline_int\nwhere timeline_id = ${inv= 100} AND val < 0 \norder by timeline.timeline_int.st;",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T01:15:45+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 132,
              "optionOpen": false
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "500"
        },
        "forms": {
          "inv": {
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false,
            "$$hashKey": "object:60831"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708964_35360162",
      "id": "20170621-052618_1306506874",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58898"
    },
    {
      "title": "ATP",
      "text": "%splicemachine\nselect VAL AS Available from timeline.timeline_int\nwhere timeline_id = ${inv= 100} \nAND ST <= TIMESTAMP('${Time=2017-05-05 00:00:00.0}')  \nAND ET > TIMESTAMP('${Time=2017-05-05 00:00:00.0}')",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T01:15:48+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 90,
              "optionOpen": false
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "100",
          "Time": "2016-05-10 00:00:00.0"
        },
        "forms": {
          "inv": {
            "name": "inv",
            "defaultValue": " 100",
            "hidden": false,
            "$$hashKey": "object:60914"
          },
          "Time": {
            "name": "Time",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false,
            "$$hashKey": "object:60915"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708966_36129660",
      "id": "20170621-053013_888862556",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58899"
    },
    {
      "text": "%splicemachine\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1501790708966_36129660",
      "id": "20170628-145111_1644223982",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58900"
    },
    {
      "text": "%md\n### Apply the Crystal Ball\n#### Perform a What-If on any predicted late shipment\n\nBy moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.\n\nBelow we create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only. \n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Apply the Crystal Ball</h3>\n<h4>Perform a What-If on any predicted late shipment</h4>\n<p>By moving the shipment to the predicted new delivery date, you can see the new inventory levels and plan around stockouts.</p>\n<p>Below we create a prediction table that materializes predictions on some set of orders as to whether they are late. Then we initialize the table randomly for demostration purposes only.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708967_35744911",
      "id": "20170621-054855_1620710812",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58901"
    },
    {
      "title": "Prediction Table",
      "text": "%splicemachine\nDrop table IF EXISTS TIMELINE.PREDICTIONS;\ncreate table TIMELINE.PREDICTIONS(\n    TO_ID   BIGINT,\n    LatenessBin1 DOUBLE,\n    LatenessBin2 DOUBLE,\n    LatenessBin3 DOUBLE,\n    LatenessBin4 DOUBLE,\n    LatenessBin5 DOUBLE,\n    LatenessBin6 DOUBLE,\n    LatenessBin7 DOUBLE,\n    LatenessBin8 DOUBLE,\n    LatenessBin9 DOUBLE,\n    LatenessBin10 DOUBLE,\n    primary key (TO_ID)\n    );\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:18:59+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708968_33821166",
      "id": "20170623-181559_517039267",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58902"
    },
    {
      "title": "Initializing Predictions Randomly",
      "text": "%splicemachine\ninsert into TIMELINE.PREDICTIONS (\n    TO_ID, \n    LatenessBin1,\n    LatenessBin2,\n    LatenessBin3,\n    LatenessBin4\n    )\n    SELECT TO_ID, RANDOM(), RANDOM(), RANDOM(), RANDOM() \n    From TIMELINE.TRANSFERORDERS\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:19:02+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 6,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708969_33436417",
      "id": "20170623-182513_1199711298",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58903"
    },
    {
      "title": "Predictions",
      "text": "%splicemachine\nSELECT TP.TO_ID, TP.LatenessBin1 as ZERO_DAYLATE, TP.LatenessBin2 as ONE_DAYLATE, TP.LatenessBin3 as FIVE_DAYLATE,  TP.LatenessBin4 as TEN_DAYLATE, timeline.transferorders.*    FROM timeline.predictions TP  LEFT OUTER JOIN timeline.transferorders  ON TP.to_id = timeline.transferorders.to_id\nwhere TIMESTAMP('${begin =2017-05-05 00:00:00.0}') >= timeline.transferorders.deliverydate \nAND TIMESTAMP('${end =2017-05-05 00:00:00.0}') >timeline.transferorders.deliverydate \nAND TP.LatenessBin3 >= ${threshold = .75}",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:15:16+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "end": "2017-05-05 00:00:00.0",
          "threshold": ".5",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false,
            "$$hashKey": "object:61167"
          },
          "threshold": {
            "name": "threshold",
            "defaultValue": " .75",
            "hidden": false,
            "$$hashKey": "object:61168"
          },
          "begin": {
            "name": "begin",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false,
            "$$hashKey": "object:61169"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708970_34590664",
      "id": "20170714-183906_14590483",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58904"
    },
    {
      "text": "%md\n### What-If Simulation \n#### Perform a What-If for the specified Order with specified delay in shipment\n\nPick an order that may be delayed by number of days to see what orders may result in stock out situation because of the delay.\n\nFirst all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.\nNext the delay is simulated, and inventory calculations  are made and the Orders that are sourced from the Destination, are again checked for stockout situation.\n\nSince the what-if calculations are done on temporary table and does not impact the actual data.\n\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>What-If Simulation</h3>\n<h4>Perform a What-If for the specified Order with specified delay in shipment</h4>\n<p>Pick an order that may be delayed by number of days to see what orders may result in stock out situation because of the delay.</p>\n<p>First all the orders that are sourced from the Destination of the Order in consideration, the ones that have stockout are listed, before the delay in delivery date for comparison.<br/>Next the delay is simulated, and inventory calculations are made and the Orders that are sourced from the Destination, are again checked for stockout situation.</p>\n<p>Since the what-if calculations are done on temporary table and does not impact the actual data.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708972_32282171",
      "id": "20170716-211650_1813160194",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58905"
    },
    {
      "text": "%angular\n\n<form class=\"form-inline\">\n  <div class=\"form-group\">\n   <h5>Simulate Late Order </h5>\n    <label for=\"orderFieldId\"> Order ID : </label>\n    <input type=\"text\" class=\"form-control\" id=\"orderFieldId\" placeholder= Order id ...\" ng-model=\"orderId\"></input>\n    <label for=\"delayFieldId\">Delay in Days: </label>\n    <input type=\"text\" class=\"form-control\" id=\"delayFieldId\" placeholder= Delay Days ...\" ng-model=\"delayDays\"></input>\n      <button type=\"submit\" class=\"btn btn-primary\" ng-click=\"z.angularBind('orderId',orderId,'20170625-202310_651912174');z.angularBind('delayDays',delayDays,'20170625-202310_651912174'); z.runParagraph('20170625-202310_651912174')\"> Run What-If</button>\n  </div>\n\n</form>\n",
      "dateUpdated": "2017-08-04T05:19:18+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/undefined",
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708973_31897422",
      "id": "20170627-003424_154469379",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58906"
    },
    {
      "title": "What-If Simulation Code",
      "text": "%spark\n\nval splicemachineContext = new SplicemachineContext(defaultJDBCURL)\nval InventoryTable = \"timeline.timeline_int\"\nval TOTable = \"timeline.transferorders\"\nval stockoutTable = \"timeline.STOCKOUTS\"\nval CHANGE_AT_ST = 0\nval CHANGE_AT_ET = 1\nval tempTableColsWithPKey : String  = \"(Timeline_Id bigint, \" + \"ST timestamp, \" + \"ET timestamp, \" + \"Val bigint, \" + \"primary key (Timeline_ID, ST)\" +\")\"\n\ndef createTempInvTable (smContext :SplicemachineContext, source : Long, dest : Long): String = {\n    \n    var tempTable =\"Timeline.\"+  \"TEMP_INV_\" + org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n            while(smContext.tableExists( tempTable))\n                tempTable =\"Timeline.\"+  \"TEMP_INV_\" +org.apache.commons.lang3.RandomStringUtils.randomAlphabetic(6).toUpperCase();\n    \n    \n    \n    val tempOptions = Map(\n         org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_TABLE_NAME -> tempTable,\n        org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.JDBC_URL -> defaultJDBCURL\n    )\n\n    val tempJDBCOptions = new org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions(tempOptions)\n\n    \n    val conn = JdbcUtils.createConnectionFactory(tempJDBCOptions)()\n    try {\n    conn.createStatement().execute(\"create table \" + tempTable + tempTableColsWithPKey)\n    } finally {\n      conn.close()\n    }\n    \n    //insert \n    val stmt = \"select *  FROM timeline.timeline_int  WHERE Timeline_Id  in ( \" + source + \", \"+ dest +\")\"\n    val timesDf = splicemachineContext.df(stmt)\n    smContext.insert(timesDf,tempTable )\n   tempTable\n \n    \n}\n\ndef whatif(smContext :SplicemachineContext,\n            tempInvTable: String,\n           source: Integer,\n           destination: Integer,\n           shippingDate: Timestamp,\n           deliveryDate: Timestamp,\n           newDeliveryDate : Timestamp,\n           qty: Long,\n           retryCount: Integer = 0,\n           revertFlag: Boolean): Unit = {\n\n        val conn: Connection = smContext.getConnection()\n         try {\n          conn.setAutoCommit(false) //TBD - Need to set to false when DBAAS-570 is resolved\n          update(tempInvTable, source, shippingDate, deliveryDate,  qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, deliveryDate,  -qty, CHANGE_AT_ET)\n          update(tempInvTable, source, shippingDate, newDeliveryDate,  -qty, CHANGE_AT_ST)\n          update(tempInvTable, destination, shippingDate, newDeliveryDate,  qty, CHANGE_AT_ET)\n          conn.commit()\n          \n        }\n        catch {\n          case exp: WriteConflict => {\n            conn.rollback()\n            conn.setAutoCommit(true)\n            if (retryCount < MAX_RETRIES) {\n              println(\"Retrying create TO\" + source + \" \" + destination + \" \" + shippingDate + \" \" + deliveryDate + \" \" + qty + \" \" + retryCount + 1)\n              whatif(smContext, tempInvTable,source, destination, shippingDate, deliveryDate, newDeliveryDate, qty, retryCount + 1, revertFlag)\n            }\n            else {\n              // put code here to handle too many retries\n            }\n          }\n          case e: Throwable => println(s\"Got some other kind of exception: $e\")\n        }\n        finally {\n          conn.setAutoCommit(true)\n        }\n      }\n      \n      \n  // Will need to copy the inventory table so that what-if is not visible to others\n\n  val transferOrdersTable = Map(\n    JDBCOptions.JDBC_TABLE_NAME -> \"Timeline.TransferOrders\",\n    JDBCOptions.JDBC_URL -> defaultJDBCURL\n    ) \n  val orderid = z.angular(\"orderId\").toString.toLong\n  val q = s\"select *  FROM timeline.transferorders WHERE to_id = $orderid\"\n  val order = splicemachineContext.df(q)\n  \n   val days = z.angular(\"delayDays\").toString.toInt\n \n  if(order.count > 0 && days > 0) {\n    //  val days: Int = 5\n      val source = order.first().getAs(\"SOURCEINVENTORY\").asInstanceOf[Long]\n      val dest = order.first().getAs(\"DESTINATIONINVENTORY\").asInstanceOf[Long]\n      val ship = order.first().getAs(\"SHIPDATE\").asInstanceOf[Timestamp]\n      val delivery = order.first().getAs(\"DELIVERYDATE\").asInstanceOf[Timestamp]\n      val qty = order.first().getAs(\"QTY\").asInstanceOf[Long]\n      val newDelivery =new Timestamp( new org.joda.time.DateTime (delivery).plusDays(days).getMillis())\n      \n      //Populate stockouts before What If\n      \n     val queryBefore = s\"\"\"SELECT t.to_id, i.ST, i.timeline_id FROM $InventoryTable i  , $TOTable t\n        WHERE i.timeline_id = $dest\n        AND t.sourceinventory = i.timeline_id\n        AND val < 0\n        AND i.ST <=  t.shipdate\n        AND  t.shipdate < i.ET\n        ORDER BY i.ST\"\"\"\n    \n       println(s\"q=$queryBefore\")\n      val stockOutsBefore = splicemachineContext.df(queryBefore)\n  \n      splicemachineContext.insert(stockOutsBefore, stockoutTable)\n      z.run(\"20170621-055239_1661420434\")\n      z.run(\"20170628-152508_1831563439\")\n      \n      val tempInventoryTable = createTempInvTable(splicemachineContext,source,dest)\n      \n      whatif(splicemachineContext,tempInventoryTable,source.toInt, dest.toInt, ship, delivery, newDelivery, qty, days, false)\n      \n      val destInvCol = TOTable + \".destinationinventory \"\n      val timelineIdCol = tempInventoryTable + \".timeline_id \"\n      val toIdCol = TOTable + \".to_id \"\n      val stCol = tempInventoryTable + \".ST \"\n      val etCol = tempInventoryTable + \".ET \"\n      val delDateCol = TOTable + \".deliverydate \"\n      val shipDateCol =  TOTable + \".shipdate \"\n      val sourceInvCol = TOTable + \".sourceinventory \"\n      val latCol = TOTable + \".latitude \"\n      val longCol = TOTable + \".longitude \"\n      val srcWeatherCol = TOTable + \".fromweather \"\n      val destWeatherCol = TOTable + \".toweather \"\n      /*\n      val query = s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n                        WHERE $timelineIdCol = $dest\n                        AND $destInvCol = $timelineIdCol\n                        AND val < 0\n                        AND $stCol >= $delDateCol\n                        ORDER BY $stCol\"\"\"\n                        println(s\"q=$query\")\n                        */\n   \n     val query = s\"\"\"SELECT $toIdCol, $stCol, $timelineIdCol FROM $tempInventoryTable , $TOTable\n        WHERE $timelineIdCol = $dest\n        AND $sourceInvCol = $timelineIdCol\n        AND val < 0\n        AND $stCol <=  $shipDateCol\n        AND  $shipDateCol < $etCol\n        ORDER BY $stCol\"\"\"\n    \n    println(s\"q=$query\")\n      val stockOuts = splicemachineContext.df(query)\n  \n     // whatif(source.toInt, dest.toInt, ship, delivery, newDelivery, qty, 5, true) // undo what-if \n      splicemachineContext.insert(stockOuts, stockoutTable)\n      z.run(\"20170716-165322_7991113\")\n      z.run(\"20170628-152508_1831563439\")\n     // splicemachineContext.dropTable(tempInventoryTable)\n   } else {\n    println(\" NO ORDERS FOUND FOR ORDER ID \" + orderid)\n   }\n  \n",
      "user": "anonymous",
      "dateUpdated": "2017-09-19T00:27:44+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "orderid": "19"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708974_33051669",
      "id": "20170625-202310_651912174",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58907"
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs? - Before",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id = Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id =  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id =  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST =  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708976_43055140",
      "id": "20170621-055239_1661420434",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58908"
    },
    {
      "title": "What-If This Order Were Late - Stock-Outs?  - After",
      "text": "%splicemachine\nselect \n    timeline.stockouts.st,\n    timeline.timeline_int.et,\n    val,\n    timeline.stockouts.to_id,\n    shipfrom,\n    shipto,\n    qty,\n    DESTINATIONINVENTORY,\n    SOURCEINVENTORY,\n    LATITUDE,\n    LONGITUDE,\n    FROMWEATHER,\n    TOWEATHER,     \n    SUPPLIER,\n    CARRIER,\n    TRANSPORTMODE\n    from Timeline.Stockouts, Timeline.TransferOrders, timeline.Timeline_int \n    Where Timeline.Stockouts.to_id = Timeline.TransferOrders.to_id \n    AND Timeline.Stockouts.timeline_id =  timeline.Timeline_int.timeline_id\n    AND timeline.Timeline_int.timeline_id =  Timeline.TransferOrders.sourceinventory\n    AND  Timeline.Stockouts.ST =  timeline.Timeline_int.ST\norder by ST;\n\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": true,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "ST",
                    "index": 0,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 11,
                    "aggr": "sum"
                  },
                  "size": {
                    "name": "VAL",
                    "index": 1,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {
                  "stacked": true
                }
              },
              "keys": [
                {
                  "name": "ST",
                  "index": 0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "VAL",
                  "index": 2,
                  "aggr": "sum"
                }
              ],
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "200",
          "Order": " 27",
          "end": "2017-05-05 00:00:00.0",
          "in v": " 100",
          "threshold": " .75",
          "to": "27",
          "begin": "2017-05-05 00:00:00.0",
          "Inventory": "100"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708977_42670391",
      "id": "20170716-165322_7991113",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58909"
    },
    {
      "text": "%splicemachine\ndelete from timeline.stockouts where to_id >0;",
      "user": "anonymous",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708978_43824638",
      "id": "20170628-152508_1831563439",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58910"
    },
    {
      "title": "Num of Late Orders By Weather",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "yAxis": {
                    "name": "TOWEATHER",
                    "index": 10,
                    "aggr": "sum"
                  },
                  "xAxis": {
                    "name": "FROMWEATHER",
                    "index": 9,
                    "aggr": "sum"
                  },
                  "group": {
                    "name": "CARRIER",
                    "index": 8,
                    "aggr": "sum"
                  }
                },
                "pieChart": {},
                "multiBarChart": {}
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "FROMWEATHER",
                  "index": 9,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "TOWEATHER",
                  "index": 10,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "NEWDELIVERYDATE",
                  "index": 5,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {
          "inv": "98426393"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708979_43439889",
      "id": "20170623-175239_660149064",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58911"
    },
    {
      "title": "Num of Late Orders By Route",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "SHIPFROM",
                    "index": 2,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "SHIPTO",
                    "index": 3,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708982_42285642",
      "id": "20170628-143430_93328688",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58912"
    },
    {
      "title": "Num of Late Orders By Lat/Long",
      "text": "%splicemachine\nselect * from timeline.TO_DELIVERY_CHG_EVENT, timeline.transferorders \nwhere timeline.transferorders.to_id = timeline.TO_DELIVERY_CHG_EVENT.to_id",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 4,
        "editorMode": "ace/mode/sql",
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "scatterChart",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "scatterChart": {
                  "xAxis": {
                    "name": "LATITUDE",
                    "index": 28,
                    "aggr": "sum"
                  },
                  "yAxis": {
                    "name": "LONGITUDE",
                    "index": 29,
                    "aggr": "sum"
                  }
                }
              }
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708985_39592400",
      "id": "20170628-144341_2096133153",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58913"
    },
    {
      "text": "%md\n## Machine Learning \n### Learning to Predict Late Shipments\n\nHere we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.\n\nThe model considers attributes of the orders such as:\n- Mode of Transport\n- Carrier\n- Latitude \n- Longitude\n- Source City\n- Destination City\n- Part.\n\nThe model also considers exogenous data to enrich the inventory data such as weather:\n- weather at source\n- weather at destination.\n\nThe machine learning algorithm outputs a model that can predict whether a shipment is late. \n\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": false,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Machine Learning</h2>\n<h3>Learning to Predict Late Shipments</h3>\n<p>Here we use a logistic regression ML model to classify late orders. Our inventory system tracks events such as the delivery date on an order changing or the qty delivered being different than expected.</p>\n<p>The model considers attributes of the orders such as:<br/>- Mode of Transport<br/>- Carrier<br/>- Latitude<br/>- Longitude<br/>- Source City<br/>- Destination City<br/>- Part.</p>\n<p>The model also considers exogenous data to enrich the inventory data such as weather:<br/>- weather at source<br/>- weather at destination.</p>\n<p>The machine learning algorithm outputs a model that can predict whether a shipment is late.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708992_123082911",
      "id": "20170621-053550_1927397352",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58914"
    },
    {
      "text": "%md\n### Ease of ML - NO ETL \n#### Just Transformations\n\nSplice Machine is HTAP so you can perform both transactional and analytical queries.\n\nTherefore we do not need to extract and load data - we only transform it.\n\nBelow we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.\n\nThe first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.\n\n\n",
      "dateUpdated": "2017-08-03T20:05:08+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Ease of ML - NO ETL</h3>\n<h4>Just Transformations</h4>\n<p>Splice Machine is HTAP so you can perform both transactional and analytical queries.</p>\n<p>Therefore we do not need to extract and load data - we only transform it.</p>\n<p>Below we transform the transfer orders and the changes to transfer orders into a view, computing how late the order is and binning the lateness into 0,1,5,and 10 day late bins.</p>\n<p>The first step is a classic transformation step of merging a master table of data with a table of changes and labeling the rows with classes and enriching it with outside data like weather in this case.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790708993_122698162",
      "id": "20170621-070538_308959124",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58915"
    },
    {
      "title": "Bin Order Lateness and Label Orders",
      "text": "%splicemachine\n\ndrop table IF EXISTS TIMELINE.FEATURES;\n\nCREATE table TIMELINE.FEATURES AS\nSELECT \n    TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate,  \n    TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN TimeLine.TransferOrders.fromweather \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.fromweather end as currentweather,\n    TimeLine.TransferOrders.*, \n    CASE WHEN TimeLine.TO_DELIVERY_CHG_EVENT.TO_EVENT_ID is Null \n        THEN 0 \n        ELSE TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate end as Lateness,\n    CASE\n    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 0 \n    THEN\n        CASE\n            WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 5 \n            THEN\n                CASE \n                    WHEN  TimeLine.TO_DELIVERY_CHG_EVENT.newdeliverydate - TimeLine.TO_DELIVERY_CHG_EVENT.orgdeliverydate > 10\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n\n        END\n    ELSE 0\n    END AS Label\n from TimeLine.TransferOrders Left Outer Join TimeLine.TO_DELIVERY_CHG_EVENT\n on TimeLine.TransferOrders.TO_ID = TimeLine.TO_DELIVERY_CHG_EVENT.TO_ID\n WHERE  TIMESTAMP('${begin = 2017-05-05 00:00:00.0}') >= timeline.transferorders.deliverydate \nAND TIMESTAMP('${end =2017-05-05 00:00:00.0}') > timeline.transferorders.deliverydate; \n select * from timeline.features\n WHERE TIMESTAMP('${begin = 2017-05-05 00:00:00.0}') >= timeline.features.orgdeliverydate \n    AND TIMESTAMP('${end =2017-05-05 00:00:00.0}') > timeline.features.orgdeliverydate ;\n \n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:20:10+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "high": "Timestamp('2014-05-01')",
          "Start": "",
          "low": "Timestamp('2018-08-01')",
          "End": "",
          "end": "2017-05-15 00:00:00.0",
          "begin": "2017-05-05 00:00:00.0"
        },
        "forms": {
          "end": {
            "name": "end",
            "defaultValue": "2017-05-05 00:00:00.0",
            "hidden": false,
            "$$hashKey": "object:61893"
          },
          "begin": {
            "name": "begin",
            "defaultValue": " 2017-05-05 00:00:00.0",
            "hidden": false,
            "$$hashKey": "object:61894"
          }
        }
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790708995_123467660",
      "id": "20170621-115351_1800134706",
      "dateCreated": "2017-08-03T20:05:08+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58916"
    },
    {
      "text": "%md\n#### MLlib\n\nMLlib is a rich repository of Transformers and Models. \n\nhttps://spark.apache.org/docs/latest/ml-guide.html\n\nIn this use case we will use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and  10 or over days late.\n\nThe Logistic Regression Model expects a dataframe with two elements: feature Vector and label.\n\nTherefore we have to extract the columns from the above table into this form.\n\nLuckily MLlib has such a transformer called a Vector Assembler.\n\nBelow we create a Vector Assembler, extract some columns from or feature table and then feed this to the model.\n\nThen we can deploy the model to create the prediction table we used above.\n",
      "dateUpdated": "2017-08-03T20:05:09+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>MLlib</h4>\n<p>MLlib is a rich repository of Transformers and Models. </p>\n<p><a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">https://spark.apache.org/docs/latest/ml-guide.html</a></p>\n<p>In this use case we will use Logistic Regression to classify late orders into four classes: 0 days late, 1-5 days late, 5-10 days late and 10 or over days late.</p>\n<p>The Logistic Regression Model expects a dataframe with two elements: feature Vector and label.</p>\n<p>Therefore we have to extract the columns from the above table into this form.</p>\n<p>Luckily MLlib has such a transformer called a Vector Assembler.</p>\n<p>Below we create a Vector Assembler, extract some columns from or feature table and then feed this to the model.</p>\n<p>Then we can deploy the model to create the prediction table we used above.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501790709001_119620171",
      "id": "20170621-164244_783302183",
      "dateCreated": "2017-08-03T20:05:09+0000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58917"
    },
    {
      "title": "Assemble Feature Vector and Train Model",
      "text": "%spark\n    \n    import org.apache.spark.ml.feature.VectorAssembler\n    import java.sql.{Connection,Timestamp}\n    import com.splicemachine.spark.splicemachine._\n    import org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\n    import org.apache.spark.ml.classification.LogisticRegression\n    import spark.implicits._\n\n    \n    val optionMap = Map(\n      JDBCOptions.JDBC_TABLE_NAME -> \"Timeline.Features\",\n      JDBCOptions.JDBC_URL -> defaultJDBCURL\n    )\n    val dfUpper = sqlContext.read.options(optionMap).splicemachine\n    val newNames = Seq(\"orgdeliverydate\",\"newdeliverydate\",\"currentweather\",\"to_id\",\n      \"po_id\",\"shipfrom\",\"shipto\",\"shipdate\",\"deliverydate\",\"moddeliverydate\",\"sourceinventory\",\n      \"destinationinventory\",\"qty\",\"supplier\",\"asn\",\"container\",\"transportmode\",\"carrier\",\n      \"fromweather\",\"toweather\",\"latitude\",\"longitude\",\"lateness\",\"label\")\n    val df = dfUpper.toDF(newNames: _*)\n    \n    \n    //assemble feature vector from dataframe\n    val assembler = new VectorAssembler()\n      .setInputCols(Array(\"shipfrom\", \"shipto\", \"sourceinventory\", \"destinationinventory\", \"supplier\", \"transportmode\", \"carrier\", \"fromweather\", \"toweather\"))\n      .setOutputCol(\"features\")\n    \n    val output = assembler.transform(df)\n    println(\"Assembled columns ShipFrom, ShipTo, SourceInventory, DestinationInventory, Supplier, TransportMode, Carrier, FromWeather, ToWeather to vector column 'features'\")\n    output.select(\"features\", \"label\").show(true)\n    \n    // Set parameters for the algorithm.\n    // Here, we limit the number of iterations to 10.\n    val lr = new LogisticRegression()\n        .setMaxIter(10)\n\n        \n    \n    // Fit the model to the data.\n    val model = lr.fit(output)\n    \n   //Get the number of classes in Label\n     val numClasses = model.numClasses\n    // Given a dataset, predict each point's label, and show the results.\n    val newdf = model.transform(output)\n    \n    // Print the coefficients and intercept for multinomial logistic regression\n    println(s\"Coefficients: \\n${model.coefficientMatrix}\")\n    println(s\"Intercepts: ${model.interceptVector}\")\n    \n    ",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:20:20+0000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790709002_120774418",
      "id": "20170621-164423_1216161315",
      "dateCreated": "2017-08-03T20:05:09+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58918"
    },
    {
      "title": "Deploy Model to Prediction Table",
      "text": "%spark\nimport org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.sql.types.{StructType,StructField,DoubleType, LongType}\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.catalyst.encoders.RowEncoder\n\nval predictionTable = \"timeline.predictions\"\n\nvar labelCnt = numClasses\n//Only allow max of 10 lables\nif(labelCnt > 10)\n    labelCnt =10\n\n    \n newdf.printSchema()\n \n    \n    var schema = StructType(\n    StructField(\"TO_ID\", LongType, false) :: Nil)\n   \n    \n    var i=0;\n    for (i <- 1 to labelCnt) {\n        schema = schema.add( StructField(\"LATENESSBIN\"+i, DoubleType, false) )\n    }\n           \n    \nval encoder = RowEncoder(schema)\n \n val pred = newdf\n  .select( \"features\", \"label\", \"probability\", \"prediction\", \"to_id\")\n  .map { case Row( features: Vector, label: Integer, prob: Vector, prediction: Double, idd:Long) => \n  \n    var seq1 : Seq[Any] = Seq(idd.asInstanceOf[Number].longValue())\n    var j=0;\n    for (j <- 1 to labelCnt) {\n        seq1 = seq1:+ ( prob(j-1).asInstanceOf[Number].doubleValue())\n    }\n    println(seq1)\n     Row.fromSeq(seq1)   \n    }(encoder)\n    \n    \n  splicemachineContext.update(pred, predictionTable) \n  pred.show()\n",
      "user": "anonymous",
      "dateUpdated": "2017-08-04T05:20:26+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS"
      },
      "apps": [],
      "jobName": "paragraph_1501790709003_120389669",
      "id": "20170626-132011_1256759754",
      "dateCreated": "2017-08-03T20:05:09+0000",
      "status": "READY",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58919"
    },
    {
      "text": "%spark\n",
      "dateUpdated": "2017-08-03T20:05:09+0000",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1501790709005_118081175",
      "id": "20170714-192918_375392082",
      "dateCreated": "2017-08-03T20:05:09+0000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500,
      "$$hashKey": "object:58920"
    }
  ],
  "name": "4. Reference Applications / 1. Supply Chain - Predicting Shortages",
  "id": "2CKKJKSK8",
  "angularObjects": {
    "2DNHZSRUQ:shared_process": [],
    "2DP6VF566:shared_process": [],
    "2DM92W265:shared_process": [],
    "2DPD6828Z:shared_process": [],
    "2DPSBXP2Z:shared_process": [],
    "2DNP2K3KJ:shared_process": []
  },
  "config": {
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}