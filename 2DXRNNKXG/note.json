{
  "paragraphs": [
    {
      "text": "%md\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\n# Introduction to Developer Training, Part II\nThis curriculum is recommended for query writers, ETL processors, and developers who have completed Part 1 of our Developer training and want to proceed on to more advanced topics. To understand the topics in this section, you need to have experience with SQL, and some programming experience with Python or Scala. You can expect to spend 2-3 hours completing this curriculum.\n\nNote that each notebook contains a link to the next notebook in the sequence, and most notebooks also contain links to related pages in our Splice Machine Documentation web.\n\nThis is our recommended learning sequence of notebooks for a deeper dive into Splice Machine development:\n\n\n\n\u003ctable class\u003d\"splicezepOddEven\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;1.\u003c/td\u003e\n            \u003ctd\u003eIf you\u0027ve not already done so, please complete our \u003ca href\u003d\"/#/notebook/2DYAK9C9S\"\u003e\u003cem\u003eDeveloper\u0027s Guide - Part 1\u003c/em\u003e\u003c/a\u003e curriculum.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;2.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DW2MCTTP\"\u003e\u003cem\u003eRunning the TPCH-1 Benchmark Queries\u003c/em\u003e\u003c/a\u003e notebook introduces you to importing TPCH-1 benchmark data into your database and then creating indexes, compacting your database, collecting statistics, and running the TPCH-1 queries.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;3.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DUK929SD\"\u003e\u003cem\u003eCommon Utilities\u003c/em\u003e\u003c/a\u003e notebook describes a number of utilities that you may find useful when working with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;4.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWS5FM39\"\u003e\u003cem\u003eThe Life of a Query\u003c/em\u003e\u003c/a\u003e notebook is a more in-depth walk-through of creating, populating, and querying TPCH benchmark data in Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;5.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DY6YKEVA\"\u003e\u003cem\u003eVisualizing Results with Zeppelin\u003c/em\u003e\u003c/a\u003e notebook shows you how to use Zeppelin for filtering and graphing query results.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;6.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DUKWWK84\"\u003e\u003cem\u003eTransactions with Spark and JDBC\u003c/em\u003e\u003c/a\u003e notebook provides a glimpse into the transactional nature of Splice Machine and introduces use of the \u003ccode\u003e%spark\u003c/code\u003e interpreter with a JDBC connection.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;7.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DVU2ESP3\"\u003e\u003cem\u003eCreating Applications with Splice Machine\u003c/em\u003e\u003c/a\u003e notebook shows you how to run a \u003cem\u003eSpring\u003c/em\u003e application (the \u003cem\u003ePetclinic\u003c/em\u003e web app) with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;8.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DW6E5Z1X\"\u003e\u003cem\u003eUsing the Splice Machine Native Spark DataSource\u003c/em\u003e\u003c/a\u003e notebook demonstrates how our Native Spark DataSource allows you to adopt the full power of Spark and manipulate dataframes while also having the power of full ANSI, ACID-compliant SQL.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;9.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWTYCFTY\"\u003e\u003cem\u003eMachine Learning with Spark MLib using Python\u003c/em\u003e\u003c/a\u003e notebook contains Python code that uses the Machine Learning Library embedded in Spark, \u003cem\u003eMLlib\u003c/em\u003e, with the Splice Machine Spark Adapter to realize in-process machine learning.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e10.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DX1UV9MX\"\u003e\u003cem\u003eMachine Learning with Spark MLib using Scala\u003c/em\u003e\u003c/a\u003e notebook contains Scala code that uses the Machine Learning Library embedded in Spark, \u003cem\u003eMLlib\u003c/em\u003e, with the Splice Machine Spark Adapter to realize in-process machine learning.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e11.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWAGKSPM\"\u003e\u003cem\u003eCreating Custom Stored Procedures\u003c/em\u003e\u003c/a\u003e notebook show you how to create and deploy custom, stored functions and procedures that you can call from your SQL queries in Splice Machine .\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e12.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DXK4FQKX\"\u003e\u003cem\u003eETL Pipeline\u003c/em\u003e\u003c/a\u003e notebook presents a simple example of constructing an ETL pipeline with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n   \u003c/tbody\u003e\n\u003c/table\u003e\n\n\n        ",
      "user": "anonymous",
      "dateUpdated": "2018-11-19 15:49:35.918",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003ch1\u003eIntroduction to Developer Training, Part II\u003c/h1\u003e\n\u003cp\u003eThis curriculum is recommended for query writers, ETL processors, and developers who have completed Part 1 of our Developer training and want to proceed on to more advanced topics. To understand the topics in this section, you need to have experience with SQL, and some programming experience with Python or Scala. You can expect to spend 2-3 hours completing this curriculum.\u003c/p\u003e\n\u003cp\u003eNote that each notebook contains a link to the next notebook in the sequence, and most notebooks also contain links to related pages in our Splice Machine Documentation web.\u003c/p\u003e\n\u003cp\u003eThis is our recommended learning sequence of notebooks for a deeper dive into Splice Machine development:\u003c/p\u003e\n\u003ctable class\u003d\"splicezepOddEven\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;1.\u003c/td\u003e\n            \u003ctd\u003eIf you\u0027ve not already done so, please complete our \u003ca href\u003d\"/#/notebook/2DYAK9C9S\"\u003e\u003cem\u003eDeveloper\u0027s Guide - Part 1\u003c/em\u003e\u003c/a\u003e curriculum.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;2.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DW2MCTTP\"\u003e\u003cem\u003eRunning the TPCH-1 Benchmark Queries\u003c/em\u003e\u003c/a\u003e notebook introduces you to importing TPCH-1 benchmark data into your database and then creating indexes, compacting your database, collecting statistics, and running the TPCH-1 queries.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;3.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DUK929SD\"\u003e\u003cem\u003eCommon Utilities\u003c/em\u003e\u003c/a\u003e notebook describes a number of utilities that you may find useful when working with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;4.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWS5FM39\"\u003e\u003cem\u003eThe Life of a Query\u003c/em\u003e\u003c/a\u003e notebook is a more in-depth walk-through of creating, populating, and querying TPCH benchmark data in Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;5.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DY6YKEVA\"\u003e\u003cem\u003eVisualizing Results with Zeppelin\u003c/em\u003e\u003c/a\u003e notebook shows you how to use Zeppelin for filtering and graphing query results.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;6.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DUKWWK84\"\u003e\u003cem\u003eTransactions with Spark and JDBC\u003c/em\u003e\u003c/a\u003e notebook provides a glimpse into the transactional nature of Splice Machine and introduces use of the \u003ccode\u003e%spark\u003c/code\u003e interpreter with a JDBC connection.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;7.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DVU2ESP3\"\u003e\u003cem\u003eCreating Applications with Splice Machine\u003c/em\u003e\u003c/a\u003e notebook shows you how to run a \u003cem\u003eSpring\u003c/em\u003e application (the \u003cem\u003ePetclinic\u003c/em\u003e web app) with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;8.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DW6E5Z1X\"\u003e\u003cem\u003eUsing the Splice Machine Native Spark DataSource\u003c/em\u003e\u003c/a\u003e notebook demonstrates how our Native Spark DataSource allows you to adopt the full power of Spark and manipulate dataframes while also having the power of full ANSI, ACID-compliant SQL.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u0026nbsp;9.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWTYCFTY\"\u003e\u003cem\u003eMachine Learning with Spark MLib using Python\u003c/em\u003e\u003c/a\u003e notebook contains Python code that uses the Machine Learning Library embedded in Spark, \u003cem\u003eMLlib\u003c/em\u003e, with the Splice Machine Spark Adapter to realize in-process machine learning.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e10.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DX1UV9MX\"\u003e\u003cem\u003eMachine Learning with Spark MLib using Scala\u003c/em\u003e\u003c/a\u003e notebook contains Scala code that uses the Machine Learning Library embedded in Spark, \u003cem\u003eMLlib\u003c/em\u003e, with the Splice Machine Spark Adapter to realize in-process machine learning.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e11.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DWAGKSPM\"\u003e\u003cem\u003eCreating Custom Stored Procedures\u003c/em\u003e\u003c/a\u003e notebook show you how to create and deploy custom, stored functions and procedures that you can call from your SQL queries in Splice Machine .\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e12.\u003c/td\u003e\n            \u003ctd\u003eThe \u003ca href\u003d\"/#/notebook/2DXK4FQKX\"\u003e\u003cem\u003eETL Pipeline\u003c/em\u003e\u003c/a\u003e notebook presents a simple example of constructing an ETL pipeline with Splice Machine.\u003c/td\u003e\n        \u003c/tr\u003e\n   \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542394386424_-2104749238",
      "id": "20181115-180806_798211942",
      "dateCreated": "2018-11-16 10:53:06.000",
      "dateStarted": "2018-11-19 15:49:35.919",
      "dateFinished": "2018-11-19 15:49:35.930",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 10:53:06.000",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542394386424_-1260678790",
      "id": "20181115-200551_832129466",
      "dateCreated": "2018-11-16 10:53:06.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Training/Developers - Part II/a. Introduction",
  "id": "2DXRNNKXG",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}