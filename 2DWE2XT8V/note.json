{
  "paragraphs": [
    {
      "text": "%md\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\n# Using Spark in a Zeppelin Notebook\nThis notebook demonstrates how to use Spark in a Zeppelin notebook, in the following sections:\n\n* *Loading Data Into A Table Using Spark*\n* *Using Spark SQL to Query the Loaded Data*\n\n\u003cdiv class\u003d\"notePlain\" style\u003d\"font-size:12px\"\u003e\nThe data we use in this notebook is public data; here is access information for it:\n\u003cp style\u003d\"margin-left:60px;\"\u003e[Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. \u003cem\u003eUsing Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology.\u003c/em\u003e In P. Novais et al. (Eds.), \u003cem\u003eProceedings of the European Simulation and Modelling Conference - ESM\u00272011\u003c/em\u003e, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\u003c/p\u003e\n\n\u003cp style\u003d\"margin-left:60px;\"\u003eAvailable at: \u003ca href\u003d\"http://hdl.handle.net/1822/14838\"\u003ehttp://hdl.handle.net/1822/14838\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 06:00:26.157",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003ch1\u003eUsing Spark in a Zeppelin Notebook\u003c/h1\u003e\n\u003cp\u003eThis notebook demonstrates how to use Spark in a Zeppelin notebook, in the following sections:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eLoading Data Into A Table Using Spark\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eUsing Spark SQL to Query the Loaded Data\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class\u003d\"notePlain\" style\u003d\"font-size:12px\"\u003e\nThe data we use in this notebook is public data; here is access information for it:\n\u003cp style\u003d\"margin-left:60px;\"\u003e[Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. \u003cem\u003eUsing Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology.\u003c/em\u003e In P. Novais et al. (Eds.), \u003cem\u003eProceedings of the European Simulation and Modelling Conference - ESM\u00272011\u003c/em\u003e, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\u003c/p\u003e\n\n\u003cp style\u003d\"margin-left:60px;\"\u003eAvailable at: \u003ca href\u003d\"http://hdl.handle.net/1822/14838\"\u003ehttp://hdl.handle.net/1822/14838\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542397883898_-912211351",
      "id": "20150213-231621_168813393",
      "dateCreated": "2018-11-16 11:51:23.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Loading Data Into a Table Using Spark\n\nThe following paragraph uses the `%spark` interpreter to load public bank data into a table. Note that Zeppelin creates and injects the SparkContext (`sc`) and sqlContext (`HiveContext` or `SqlContext`) for you, so you don\u0027t need to create them manually.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 06:00:57.796",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eLoading Data Into a Table Using Spark\u003c/h2\u003e\n\u003cp\u003eThe following paragraph uses the \u003ccode\u003e%spark\u003c/code\u003e interpreter to load public bank data into a table. Note that Zeppelin creates and injects the SparkContext (\u003ccode\u003esc\u003c/code\u003e) and sqlContext (\u003ccode\u003eHiveContext\u003c/code\u003e or \u003ccode\u003eSqlContext\u003c/code\u003e) for you, so you don\u0026rsquo;t need to create them manually.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1543604712907_1062286965",
      "id": "20181130-190512_465791935",
      "dateCreated": "2018-11-30 19:05:12.907",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load data into table",
      "text": "%spark\nimport org.apache.commons.io.IOUtils\nimport java.net.URL\nimport java.nio.charset.Charset\n\n// Zeppelin creates and injects sc (SparkContext) and sqlContext (HiveContext or SqlContext)\n// So you don\u0027t need create them manually\n\n// load bank data\nval bankText \u003d sc.parallelize(\n    IOUtils.toString(\n        new URL(\"https://s3.amazonaws.com/apache-zeppelin/tutorial/bank/bank.csv\"),\n        Charset.forName(\"utf8\")).split(\"\\n\"))\n\ncase class Bank(age: Integer, job: String, marital: String, education: String, balance: Integer)\n\nval bank \u003d bankText.map(s \u003d\u003e s.split(\";\")).filter(s \u003d\u003e s(0) !\u003d \"\\\"age\\\"\").map(\n    s \u003d\u003e Bank(s(0).toInt, \n            s(1).replaceAll(\"\\\"\", \"\"),\n            s(2).replaceAll(\"\\\"\", \"\"),\n            s(3).replaceAll(\"\\\"\", \"\"),\n            s(5).replaceAll(\"\\\"\", \"\").toInt\n        )\n).toDF()\nbank.registerTempTable(\"bank\")",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 02:28:53.702",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false
            }
          }
        ],
        "enabled": true,
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542397883898_336019294",
      "id": "20150210-015259_1403135953",
      "dateCreated": "2018-11-16 11:51:23.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Using Spark SQL to Query the Loaded Data\n\nThe three paragraphs below use the `%spark.sql` interpreter to query the loaded data; each displays the query results using one of the available Zeppelin data visualizations.  \n\nWe also demonstrate how you can substitute variables into your queries that can be populated in a textbox.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 02:30:37.358",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eUsing Spark SQL to Query the Loaded Data\u003c/h2\u003e\n\u003cp\u003eThe three paragraphs below use the \u003ccode\u003e%spark.sql\u003c/code\u003e interpreter to query the loaded data; each displays the query results using one of the available Zeppelin data visualizations. \u003c/p\u003e\n\u003cp\u003eWe also demonstrate how you can substitute variables into your queries that can be populated in a textbox.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1543605021486_1684401472",
      "id": "20181130-191021_2034021855",
      "dateCreated": "2018-11-30 19:10:21.486",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.sql \nselect age, count(1) value\nfrom bank \nwhere age \u003c 30 \ngroup by age \norder by age",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 02:29:01.278",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "multiBarChart",
              "height": 366.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "age",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "value",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        ],
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542397883899_311454002",
      "id": "20150210-015302_1492795503",
      "dateCreated": "2018-11-16 11:51:23.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.sql \nselect age, count(1) value \nfrom bank \nwhere age \u003c ${maxAge\u003d30} \ngroup by age \norder by age",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 02:29:07.463",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": [
          {
            "graph": {
              "mode": "multiBarChart",
              "height": 294.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "age",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "value",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        ],
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {
          "maxAge": "35"
        },
        "forms": {
          "maxAge": {
            "type": "TextBox",
            "name": "maxAge",
            "defaultValue": "30",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542397883899_-2020806566",
      "id": "20150212-145404_867439529",
      "dateCreated": "2018-11-16 11:51:23.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.sql \nselect age, count(1) value \nfrom bank \nwhere marital\u003d\"${marital\u003dsingle,single|divorced|married}\" \ngroup by age \norder by age",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 02:29:13.756",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "runOnSelectionChange": true,
        "results": [
          {
            "graph": {
              "mode": "stackedAreaChart",
              "height": 280.0,
              "optionOpen": false,
              "setting": {
                "stackedAreaChart": {
                  "rotate": {
                    "degree": "-45"
                  },
                  "xLabelStatus": "default"
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "age",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "value",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        ],
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {
          "marital": "single"
        },
        "forms": {
          "marital": {
            "type": "Select",
            "options": [
              {
                "value": "single"
              },
              {
                "value": "divorced"
              },
              {
                "value": "married"
              }
            ],
            "name": "marital",
            "defaultValue": "single",
            "hidden": false
          }
        }
      },
      "apps": [],
      "jobName": "paragraph_1542397883900_2032268547",
      "id": "20150213-230422_1600658137",
      "dateCreated": "2018-11-16 11:51:23.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\nYou\u0027ve learned a bit about using Spark in Zeppelin notebooks; the next notebook in this class, [*Machine Learning with Spark MLlib Using Python*](/#/notebook/2DYC2S8DY), shows you how to use R to program with Spark in a Zeppelin Notebook.",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 07:31:49.310",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eWhere to Go Next\u003c/h2\u003e\n\u003cp\u003eYou\u0026rsquo;ve learned a bit about using Spark in Zeppelin notebooks; the next notebook in this class, \u003ca href\u003d\"/#/notebook/2DYC2S8DY\"\u003e\u003cem\u003eMachine Learning with Spark MLlib Using Python\u003c/em\u003e\u003c/a\u003e, shows you how to use R to program with Spark in a Zeppelin Notebook.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542397883901_1883049237",
      "id": "20150703-133047_853701097",
      "dateCreated": "2018-11-16 11:51:23.000",
      "dateStarted": "2018-12-03 07:28:42.967",
      "dateFinished": "2018-12-03 07:28:43.046",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training/For Data Scientists/d. Basics of Using Spark in Zeppelin",
  "id": "2DWE2XT8V",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "splicemachine:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}