{
  "paragraphs": [
    {
      "text": "%md\n# Decision Trees\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\nThe [Decision Tree](https://spark.apache.org/docs/latest/mllib-decision-tree.html) is a greedy algorithm that performs a recursive binary partitioning of the feature space for predictive modeling. \n\n* Locally optimal decisions are made at each node in hopes of a globally optimal decision\n* Because of it\u0027s greedy nature, it cannot guarantee the globally optimal tree\n\nAt its core (and most simplified), decision trees are simply a system of if-else statements, always taking the most optimal answer, resulting in (hopefully) the most optimal decision, as shown in this diagram:\n\n\u003cimg class\u003d\"splice\" src\u003d\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/image/decisionTree/classification.jpg\"\u003e",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 18:37:41.724",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eDecision Trees\u003c/h1\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003cp\u003eThe \u003ca href\u003d\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\"\u003eDecision Tree\u003c/a\u003e is a greedy algorithm that performs a recursive binary partitioning of the feature space for predictive modeling. \u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eLocally optimal decisions are made at each node in hopes of a globally optimal decision\u003c/li\u003e\n  \u003cli\u003eBecause of it\u0026rsquo;s greedy nature, it cannot guarantee the globally optimal tree\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAt its core (and most simplified), decision trees are simply a system of if-else statements, always taking the most optimal answer, resulting in (hopefully) the most optimal decision, as shown in this diagram:\u003c/p\u003e\n\u003cimg class\u003d\"splice\" src\u003d\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/image/decisionTree/classification.jpg\"\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398443304_1947682620",
      "id": "20170620-141909_771490751",
      "dateCreated": "2018-11-16 12:00:43.000",
      "dateStarted": "2018-11-20 18:37:41.724",
      "dateFinished": "2018-11-20 18:37:41.730",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Decision Tree Example\n\nThe remainder of this notebook demonstrates how to:\n\n* Load a  [LIBSVM](https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt) data file\n* Parse it as an RDD of LabeledPoint\n* Perform classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5.\n\nThe test error is calculated to measure the algorithm accuracy. \n\nFor more information, check out \u003ca href\u003d\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target\u003d\"_blank\"\u003eSpark\u0027s Decision Tree page\u003c/a\u003e.\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 18:40:17.840",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eDecision Tree Example\u003c/h2\u003e\n\u003cp\u003eThe remainder of this notebook demonstrates how to:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eLoad a \u003ca href\u003d\"https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt\"\u003eLIBSVM\u003c/a\u003e data file\u003c/li\u003e\n  \u003cli\u003eParse it as an RDD of LabeledPoint\u003c/li\u003e\n  \u003cli\u003ePerform classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe test error is calculated to measure the algorithm accuracy. \u003c/p\u003e\n\u003cp\u003eFor more information, check out \u003ca href\u003d\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target\u003d\"_blank\"\u003eSpark\u0026rsquo;s Decision Tree page\u003c/a\u003e.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542767864123_962201816",
      "id": "20181120-183744_1917061299",
      "dateCreated": "2018-11-20 18:37:44.123",
      "dateStarted": "2018-11-20 18:40:17.840",
      "dateFinished": "2018-11-20 18:40:17.845",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nimport org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.model.DecisionTreeModel\nimport org.apache.spark.mllib.util.MLUtils\n\n// Load and parse the data file.\nval data \u003d MLUtils.loadLibSVMFile(sc, \"/Users/benepstein/Desktop/sample_libsvm_data.txt\")\n// Split the data into training and test sets (30% held out for testing)\nval splits \u003d data.randomSplit(Array(0.7, 0.3))\nval (trainingData, testData) \u003d (splits(0), splits(1))\n\n// Train a DecisionTree model.\n//  Empty categoricalFeaturesInfo indicates all features are continuous.\nval numClasses \u003d 2\nval categoricalFeaturesInfo \u003d Map[Int, Int]()\nval impurity \u003d \"gini\"\nval maxDepth \u003d 5\nval maxBins \u003d 32\n\nval model \u003d DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n  impurity, maxDepth, maxBins)\n\n// Evaluate model on test instances and compute test error\nval labelAndPreds \u003d testData.map { point \u003d\u003e\n  val prediction \u003d model.predict(point.features)\n  (point.label, prediction)\n}\nval testErr \u003d labelAndPreds.filter(r \u003d\u003e r._1 !\u003d r._2).count().toDouble / testData.count()\nprintln(\"Test Error \u003d \" + testErr)\nprintln(\"Learned classification tree model:\\n\" + model.toDebugString)\n\n// Save and load model\n// model.save(sc, \"target/tmp/myDecisionTreeClassificationModel\")\n// val sameModel \u003d DecisionTreeModel.load(sc, \"target/tmp/myDecisionTreeClassificationModel\")",
      "user": "anonymous",
      "dateUpdated": "2018-11-16 12:00:43.000",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398443305_2007728913",
      "id": "20170620-153325_126659046",
      "dateCreated": "2018-11-16 12:00:43.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\u003cbr /\u003e\nThe final notebook in this class shows you an example of implementing a simple [*ETL Pipeline*](/#/notebook/2DWVX87QY) in a Splice Machine Zeppelin notebook.\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 18:40:39.373",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cbr /\u003e\n\u003cp\u003eThe final notebook in this class shows you an example of implementing a simple \u003ca href\u003d\"/#/notebook/2DWVX87QY\"\u003e\u003cem\u003eETL Pipeline\u003c/em\u003e\u003c/a\u003e in a Splice Machine Zeppelin notebook.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398443306_-1240311123",
      "id": "20170620-153620_626385294",
      "dateCreated": "2018-11-16 12:00:43.000",
      "dateStarted": "2018-11-20 18:40:39.374",
      "dateFinished": "2018-11-20 18:40:39.378",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n",
      "user": "anonymous",
      "dateUpdated": "2018-11-20 10:17:40.729",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542737860728_1243453423",
      "id": "20181120-101740_2054891679",
      "dateCreated": "2018-11-20 10:17:40.728",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training/For Data Scientists/k. Decision Trees",
  "id": "2DUQ8F96K",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "angular:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}