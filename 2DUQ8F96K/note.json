{
  "paragraphs": [
    {
      "text": "%md\n# Decision Trees Example\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" />\n\nThis notebook provides an example of implementing a *Decision Tree* algorithm that:\n\n* Loads a data file\n* Parses the data as an RDD of LabeledPoint\n* Performs classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5.\n\nThe <a href=\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target=\"_blank\">Decision Tree Algorithm</a> is a greedy algorithm that performs a recursive binary partitioning of the feature space for predictive modeling. Here are some interesting points about this algorithm: \n\n* Locally optimal decisions are made at each node in hopes of a globally optimal decision\n* Because of it's greedy nature, it cannot guarantee the globally optimal tree\n\nAt its core (and most simplified), decision trees are simply a system of if-else statements, always taking the most optimal answer, resulting in (hopefully) the most optimal decision, as shown in this diagram:\n\n<img class=\"splice\" src=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/image/decisionTree/classification.jpg\">",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:13:03.558",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "fontSize": 9.0,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Decision Trees</h1>\n<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" />\n<p>This notebook provides an example of implementing a <em>Decision Trees Example</em> algorithm that:</p>\n<ul>\n  <li>Loads a data file</li>\n  <li>Parses the data as an RDD of LabeledPoint</li>\n  <li>Performs classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5.</li>\n</ul>\n<p>The <a href=\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target=\"_blank\">Decision Tree Algorithm</a> is a greedy algorithm that performs a recursive binary partitioning of the feature space for predictive modeling. Here are some interesting points about this algorithm: </p>\n<ul>\n  <li>Locally optimal decisions are made at each node in hopes of a globally optimal decision</li>\n  <li>Because of it&rsquo;s greedy nature, it cannot guarantee the globally optimal tree</li>\n</ul>\n<p>At its core (and most simplified), decision trees are simply a system of if-else statements, always taking the most optimal answer, resulting in (hopefully) the most optimal decision, as shown in this diagram:</p>\n<img class=\"splice\" src=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/lguo/image/decisionTree/classification.jpg\">\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398443304_1947682620",
      "id": "20170620-141909_771490751",
      "dateCreated": "2018-11-16 12:00:43.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Decision Tree Example\n\nThe example in the next paragraph loads a LIBSVM data file, available from <a href=\"https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt\" target=\"_blank\">https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt</a>.\n\nIt then parses that data as an RDD of labeled points, and performs classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5. The test error is calculated, to measure the accuracy of the algorithm.\n\nYou can learn more about decision trees with MLlib on <a href=\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target=\"_blank\">Spark's Decision Tree page</a>.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:13:09.994",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Decision Tree Example</h2>\n<p>The example in the next paragraph loads a LIBSVM data file, available from <a href=\"https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt\" target=\"_blank\"><a href=\"https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt\">https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt</a></a>.</p>\n<p>It then parses that data as an RDD of labeled points, and performs classification using a decision tree with Gini impurity as an impurity measure and a maximum tree depth of 5. The test error is calculated, to measure the accuracy of the algorithm.</p>\n<p>You can learn more about decision trees with MLlib on <a href=\"https://spark.apache.org/docs/latest/mllib-decision-tree.html\" target=\"_blank\">Spark&rsquo;s Decision Tree page</a>.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542767864123_962201816",
      "id": "20181120-183744_1917061299",
      "dateCreated": "2018-11-20 18:37:44.123",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nimport org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.model.DecisionTreeModel\nimport org.apache.spark.mllib.util.MLUtils\n\n// Load and parse the data file.\nval data = MLUtils.loadLibSVMFile(sc, \"/opt/data/sample_libsvm_data.txt\")\n// Split the data into training and test sets (30% held out for testing)\nval splits = data.randomSplit(Array(0.7, 0.3))\nval (trainingData, testData) = (splits(0), splits(1))\n\n// Train a DecisionTree model.\n//  Empty categoricalFeaturesInfo indicates all features are continuous.\nval numClasses = 2\nval categoricalFeaturesInfo = Map[Int, Int]()\nval impurity = \"gini\"\nval maxDepth = 5\nval maxBins = 32\n\nval model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n  impurity, maxDepth, maxBins)\n\n// Evaluate model on test instances and compute test error\nval labelAndPreds = testData.map { point =>\n  val prediction = model.predict(point.features)\n  (point.label, prediction)\n}\nval testErr = labelAndPreds.filter(r => r._1 != r._2).count().toDouble / testData.count()\nprintln(\"Test Error = \" + testErr)\nprintln(\"Learned classification tree model:\\n\" + model.toDebugString)\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-03 04:32:10.161",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542398443305_2007728913",
      "id": "20170620-153325_126659046",
      "dateCreated": "2018-11-16 12:00:43.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\n\nThe final notebook in this class shows you an example of implementing a simple [*ETL Pipeline Example*](/#/notebook/2DWVX87QY) in a Splice Machine Zeppelin notebook.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 07:14:04.975",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Where to Go Next</h2>\n<p>The final notebook in this class shows you an example of implementing a simple <a href=\"/#/notebook/2DWVX87QY\"><em>ETL Pipeline Example</em></a> in a Splice Machine Zeppelin notebook.</p>\n</div>"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542398443306_-1240311123",
      "id": "20170620-153620_626385294",
      "dateCreated": "2018-11-16 12:00:43.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training/For Data Scientists/g. Decision Trees Example",
  "id": "2DUQ8F96K",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}