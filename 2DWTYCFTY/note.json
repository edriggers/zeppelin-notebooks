{
  "paragraphs": [
    {
      "text": "%md\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\n# Machine Learning with Spark MLlib\n\nThis notebook contains code that uses the Machine Learning (\u003cem\u003eML\u003c/em\u003e) Library embedded in Spark, *MLlib*, with the Splice Machine Spark Adapter to realize in-process machine learning. Specifically, the example in this notebook uses data that tracks international shipments to learn, and then predicts how late a shipment will be, based on various factors.\n\nIf you\u0027re not familiar with Machine Learning with Spark MLlib, you can learn more about this library here: \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003ehttps://spark.apache.org/docs/latest/ml-guide.html\u003c/a\u003e.\n\nThe code in this project was written in the Scala programming language as well as the Python programming language.\n\nThe remainder of this notebook contains these sections:\n\n* \u003cem\u003eBasic Terminology\u003c/em\u003e defines a few major ML terms used in this notebook.\n* \u003cem\u003eAbout Our Sample Data\u003c/em\u003e introduces the shipping data that we use. \n* \u003cem\u003eAbout our Learning Model\u003c/em\u003e describes the learning model method we\u0027re using.\n* \u003cem\u003eCreating our Splice Machine Database\u003c/em\u003e walks you through setting up our database with our sample data.\n* \u003cem\u003eCreating, Training, and Deploying our Learning Model\u003c/em\u003e walks you through our Machine Learning sample code.\n* \u003cem\u003eProgram Listing\u003c/em\u003e contains a listing of all of the code used in this notebook.\n\n## Basic Terminology\n\nHere\u0027s some basic terminology you need to be familiar with to understand the code in this notebook. These descriptions are paraphrased from the \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003eabove-mentioned Spark MLlib guide.\u003c/a\u003e\n\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eTerm\u003c/th\u003e\n            \u003cth\u003eDescription\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eDataFrame\u003c/td\u003e\n            \u003ctd\u003eA DataFrame is a basic Spark SQL concept. A DataFrame is similar to a table in a database: it contains rows of data with columns of varying types. The MLlib operates on datasets that are organized in DataFrames. \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003ePipeline\u003c/td\u003e\n            \u003ctd\u003eIn MLlib, you chain together a sequence of algorithms, or \u003cem\u003estages\u003c/em\u003e that operate on your DataFrame into a \u003cem\u003epipeline\u003c/em\u003e that learns.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eTransformer\u003c/td\u003e\n            \u003ctd\u003eAn algorithm that transforms a DataFrame into another DataFrame. Each transformer implements a method named \u003ccode\u003etransform\u003c/code\u003e that converts the DataFrame, typically by appending additional columns to it. A \u003cem\u003emodel\u003c/em\u003e is a kind of transformer.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eEstimator\u003c/td\u003e\n            \u003ctd\u003eA learning algorithm that trains or \u003cem\u003efits\u003c/em\u003e on a DataFrame and produces a \u003ccode\u003emodel\u003c/code\u003e. Each estimator implements a method named \u003ccode\u003efit\u003c/code\u003e that produces a model.\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n    \n\n## About our Sample Data\n\nWe\u0027ve obtained some actual shipping data that tracks international shipments between ports, and have imported that data into a Splice Machine database that we\u0027ve named `ASN.` The tables of interest are named `SHIPMENT_IN_TRANSIT` and `SHIPMENT_HISTORY;` you\u0027ll see these table used in the sample code below. We also create a database table named `Features` that forms the basis of the DataFrame we use for our learning model; this is the table you\u0027ll see featured in this notebook\u0027s code. The idea of this model is to predict, in real-time, how late a specific shipment will be, based on past data and other factors. Over time, as more data is processed by the model, the predictions become more accurate. \n\n## About our Learning Model\n\nWe use a Logistic Regression *estimator* as the final stage in our pipeline to produce a Logistic Regression Model of lateness from our data, and then deploy that model on a dataset to predict lateness.\n\nThe estimator operates on data that is formatted into vectors of integers. Since most of the fields in  our input dataset contain string values, we need to convert any data that will be used by the estimator into this format, as you\u0027ll see below. ",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:18:56.308",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003clink rel\u003d\"stylesheet\" href\u003d\"https://doc.splicemachine.com/zeppelin/css/zepstyles2.css\" /\u003e\n\u003ch1\u003eMachine Learning with Spark MLlib\u003c/h1\u003e\n\u003cp\u003eThis notebook contains code that uses the Machine Learning (\u003cem\u003eML\u003c/em\u003e) Library embedded in Spark, \u003cem\u003eMLlib\u003c/em\u003e, with the Splice Machine Spark Adapter to realize in-process machine learning. Specifically, the example in this notebook uses data that tracks international shipments to learn, and then predicts how late a shipment will be, based on various factors.\u003c/p\u003e\n\u003cp\u003eIf you\u0026rsquo;re not familiar with Machine Learning with Spark MLlib, you can learn more about this library here: \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003e\u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\"\u003ehttps://spark.apache.org/docs/latest/ml-guide.html\u003c/a\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe code in this project was written in the Scala programming language as well as the Python programming language.\u003c/p\u003e\n\u003cp\u003eThe remainder of this notebook contains these sections:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eBasic Terminology\u003c/em\u003e defines a few major ML terms used in this notebook.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eAbout Our Sample Data\u003c/em\u003e introduces the shipping data that we use.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eAbout our Learning Model\u003c/em\u003e describes the learning model method we\u0026rsquo;re using.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eCreating our Splice Machine Database\u003c/em\u003e walks you through setting up our database with our sample data.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eCreating, Training, and Deploying our Learning Model\u003c/em\u003e walks you through our Machine Learning sample code.\u003c/li\u003e\n  \u003cli\u003e\u003cem\u003eProgram Listing\u003c/em\u003e contains a listing of all of the code used in this notebook.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eBasic Terminology\u003c/h2\u003e\n\u003cp\u003eHere\u0026rsquo;s some basic terminology you need to be familiar with to understand the code in this notebook. These descriptions are paraphrased from the \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003eabove-mentioned Spark MLlib guide.\u003c/a\u003e\u003c/p\u003e\n\u003ctable class\u003d\"splicezep\"\u003e\n    \u003ccol /\u003e\n    \u003ccol /\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eTerm\u003c/th\u003e\n            \u003cth\u003eDescription\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eDataFrame\u003c/td\u003e\n            \u003ctd\u003eA DataFrame is a basic Spark SQL concept. A DataFrame is similar to a table in a database: it contains rows of data with columns of varying types. The MLlib operates on datasets that are organized in DataFrames. \u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003ePipeline\u003c/td\u003e\n            \u003ctd\u003eIn MLlib, you chain together a sequence of algorithms, or \u003cem\u003estages\u003c/em\u003e that operate on your DataFrame into a \u003cem\u003epipeline\u003c/em\u003e that learns.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eTransformer\u003c/td\u003e\n            \u003ctd\u003eAn algorithm that transforms a DataFrame into another DataFrame. Each transformer implements a method named \u003ccode\u003etransform\u003c/code\u003e that converts the DataFrame, typically by appending additional columns to it. A \u003cem\u003emodel\u003c/em\u003e is a kind of transformer.\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd class\u003d\"ItalicFont\"\u003eEstimator\u003c/td\u003e\n            \u003ctd\u003eA learning algorithm that trains or \u003cem\u003efits\u003c/em\u003e on a DataFrame and produces a \u003ccode\u003emodel\u003c/code\u003e. Each estimator implements a method named \u003ccode\u003efit\u003c/code\u003e that produces a model.\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003eAbout our Sample Data\u003c/h2\u003e\n\u003cp\u003eWe\u0026rsquo;ve obtained some actual shipping data that tracks international shipments between ports, and have imported that data into a Splice Machine database that we\u0026rsquo;ve named \u003ccode\u003eASN.\u003c/code\u003e The tables of interest are named \u003ccode\u003eSHIPMENT_IN_TRANSIT\u003c/code\u003e and \u003ccode\u003eSHIPMENT_HISTORY;\u003c/code\u003e you\u0026rsquo;ll see these table used in the sample code below. We also create a database table named \u003ccode\u003eFeatures\u003c/code\u003e that forms the basis of the DataFrame we use for our learning model; this is the table you\u0026rsquo;ll see featured in this notebook\u0026rsquo;s code. The idea of this model is to predict, in real-time, how late a specific shipment will be, based on past data and other factors. Over time, as more data is processed by the model, the predictions become more accurate. \u003c/p\u003e\n\u003ch2\u003eAbout our Learning Model\u003c/h2\u003e\n\u003cp\u003eWe use a Logistic Regression \u003cem\u003eestimator\u003c/em\u003e as the final stage in our pipeline to produce a Logistic Regression Model of lateness from our data, and then deploy that model on a dataset to predict lateness.\u003c/p\u003e\n\u003cp\u003eThe estimator operates on data that is formatted into vectors of integers. Since most of the fields in our input dataset contain string values, we need to convert any data that will be used by the estimator into this format, as you\u0026rsquo;ll see below.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787807_-1859852963",
      "id": "20180129-160012_924943773",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Create our Splice Machine Database\n\nBefore working with the MLlib, we need to create a Splice Machine database that contains the shipping data we\u0027re using. We:\n\n1. Connect to your database via JDBC\n2. Create the schema and tables\n3. Import the data\n4. Create our features table\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:19:01.848",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eCreate our Splice Machine Database\u003c/h2\u003e\n\u003cp\u003eBefore working with the MLlib, we need to create a Splice Machine database that contains the shipping data we\u0026rsquo;re using. We:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eConnect to your database via JDBC\u003c/li\u003e\n  \u003cli\u003eCreate the schema and tables\u003c/li\u003e\n  \u003cli\u003eImport the data\u003c/li\u003e\n  \u003cli\u003eCreate our features table\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787808_1407293526",
      "id": "20180202-100849_1233744001",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. Connect to Your Database via JDBC\n\nFirst we\u0027ll configure the URL we\u0027ll use in our JDBC connection to Splice Machine. For this class, you can simply use the `defaultJDBCURL` assignment in the next paragraph. ",
      "user": "anonymous",
      "dateUpdated": "2018-12-07 01:11:02.636",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. Connect to Your Database via JDBC\u003c/h3\u003e\n\u003cp\u003eFirst we\u0026rsquo;ll configure the URL we\u0026rsquo;ll use in our JDBC connection to Splice Machine. For this class, you can simply use the \u003ccode\u003edefaultJDBCURL\u003c/code\u003e assignment in the next paragraph.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787809_1910261322",
      "id": "20180613-033509_2022872512",
      "dateCreated": "2018-11-16 11:16:27.000",
      "dateStarted": "2018-12-07 01:10:57.393",
      "dateFinished": "2018-12-07 01:10:57.417",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\ndefaultJDBCURL \u003d \"\"\"jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin\"\"\"\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 17:55:57.891",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {
          "JDBCurl": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin",
          "JDBCurl Scala": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin;useSpark\u003dtrue",
          "JDBCxurl": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin;useSpark\u003dtrue",
          "JDBCURL Scala": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin",
          "Scala JDBCurl": "jdbc:splice://localhost:1527/splicedb;user\u003dsplice;password\u003dadmin"
        },
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1542395787809_-1189057698",
      "id": "20180215-062654_2077965041",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n### 2. Create the Schema and Tables\n\nWe\u0027ll now create our new schema, make it our default schema, and then create the tables for the `shipment_in_transit` and `shipment_history` data that we will import.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:19:32.476",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. Create the Schema and Tables\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll now create our new schema, make it our default schema, and then create the tables for the \u003ccode\u003eshipment_in_transit\u003c/code\u003e and \u003ccode\u003eshipment_history\u003c/code\u003e data that we will import.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542759443596_-1054064431",
      "id": "20181120-161723_2024551045",
      "dateCreated": "2018-11-20 16:17:23.596",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nCREATE SCHEMA DEV2_ASN;\nSET SCHEMA DEV2_ASN;\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:08:21.516",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787809_90897399",
      "id": "20180202-101539_620068341",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\n\nDROP TABLE IF EXISTS SHIPMENT_IN_TRANSIT;\nCREATE TABLE SHIPMENT_IN_TRANSIT(\n    SHIPMENTID VARCHAR(11) NOT NULL PRIMARY KEY,\n    STATUS VARCHAR(50),\n    SHIPMODE VARCHAR(30),\n    PRODUCT_DESCRIPTION VARCHAR(500),\n    CONSIGNEE VARCHAR(200),\n    SHIPPER VARCHAR(100),\n    ARRIVAL_DATE TIMESTAMP,\n    GROSS_WEIGHT_LB INTEGER,\n    GROSS_WEIGHT_KG INTEGER,\n    FOREIGN_PORT VARCHAR(50),\n    US_PORT VARCHAR(50),\n    VESSEL_NAME VARCHAR(40),\n    COUNTRY_OF_ORIGIN VARCHAR(40),\n    CONSIGNEE_ADDRESS VARCHAR(150),\n    SHIPPER_ADDRESS VARCHAR(150),\n    ZIPCODE VARCHAR(20),\n    NO_OF_CONTAINERS INTEGER,\n    CONTAINER_NUMBER VARCHAR(200),\n    CONTAINER_TYPE VARCHAR(80),\n    QUANTITY INTEGER,\n    QUANTITY_UNIT VARCHAR(10),\n    MEASUREMENT INTEGER,\n    MEASUREMENT_UNIT VARCHAR(5),\n    BILL_OF_LADING VARCHAR(20),\n    HOUSE_VS_MASTER CHAR(1),\n    DISTRIBUTION_PORT VARCHAR(40),\n    MASTER_BL VARCHAR(20),\n    VOYAGE_NUMBER VARCHAR(10),\n    SEAL VARCHAR(300),\n    SHIP_REGISTERED_IN VARCHAR(40),\n    INBOND_ENTRY_TYPE VARCHAR(30),\n    CARRIER_CODE VARCHAR(10),\n    CARRIER_NAME VARCHAR(40),\n    CARRIER_CITY VARCHAR(40),\n    CARRIER_STATE VARCHAR(10),\n    CARRIER_ZIP VARCHAR(10),\n    CARRIER_ADDRESS VARCHAR(200),\n    NOTIFY_PARTY VARCHAR(50),\n    NOTIFY_ADDRESS VARCHAR(200),\n    PLACE_OF_RECEIPT VARCHAR(50),\n    DATE_OF_RECEIPT TIMESTAMP\n    );\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:08:24.342",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787810_-28707119",
      "id": "20180202-102107_567153190",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\nDROP TABLE IF EXISTS SHIPMENT_HISTORY;\nCREATE TABLE SHIPMENT_HISTORY(\n    SHIPMENTID VARCHAR(11) NOT NULL PRIMARY KEY,\n    STATUS VARCHAR(50),\n    SHIPMODE VARCHAR(30),\n    PRODUCT_DESCRIPTION VARCHAR(500),\n    CONSIGNEE VARCHAR(200),\n    SHIPPER VARCHAR(100),\n    ARRIVAL_DATE TIMESTAMP,\n    GROSS_WEIGHT_LB INTEGER,\n    GROSS_WEIGHT_KG INTEGER,\n    FOREIGN_PORT VARCHAR(50),\n    US_PORT VARCHAR(50),\n    VESSEL_NAME VARCHAR(40),\n    COUNTRY_OF_ORIGIN VARCHAR(40),\n    CONSIGNEE_ADDRESS VARCHAR(150),\n    SHIPPER_ADDRESS VARCHAR(150),\n    ZIPCODE VARCHAR(20),\n    NO_OF_CONTAINERS INTEGER,\n    CONTAINER_NUMBER VARCHAR(200),\n    CONTAINER_TYPE VARCHAR(80),\n    QUANTITY INTEGER,\n    QUANTITY_UNIT VARCHAR(10),\n    MEASUREMENT INTEGER,\n    MEASUREMENT_UNIT VARCHAR(5),\n    BILL_OF_LADING VARCHAR(20),\n    HOUSE_VS_MASTER CHAR(1),\n    DISTRIBUTION_PORT VARCHAR(40),\n    MASTER_BL VARCHAR(20),\n    VOYAGE_NUMBER VARCHAR(10),\n    SEAL VARCHAR(300),\n    SHIP_REGISTERED_IN VARCHAR(40),\n    INBOND_ENTRY_TYPE VARCHAR(30),\n    CARRIER_CODE VARCHAR(10),\n    CARRIER_NAME VARCHAR(40),\n    CARRIER_CITY VARCHAR(40),\n    CARRIER_STATE VARCHAR(10),\n    CARRIER_ZIP VARCHAR(10),\n    CARRIER_ADDRESS VARCHAR(200),\n    NOTIFY_PARTY VARCHAR(50),\n    NOTIFY_ADDRESS VARCHAR(200),\n    PLACE_OF_RECEIPT VARCHAR(50),\n    DATE_OF_RECEIPT TIMESTAMP\n);\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:08:33.181",
      "config": {
        "colWidth": 4.0,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787810_2044720705",
      "id": "20180202-102130_85303245",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 3. Import the Data\n\nNext we import the shipping data, which is in csv format, into our Splice Machine database.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:20:12.931",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e3. Import the Data\u003c/h3\u003e\n\u003cp\u003eNext we import the shipping data, which is in csv format, into our Splice Machine database.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787810_156567497",
      "id": "20180202-104354_1962297047",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ncall SYSCS_UTIL.IMPORT_DATA (\n     \u0027DEV2_ASN\u0027,\n     \u0027SHIPMENT_IN_TRANSIT\u0027,\n     null,\n     \u0027s3a://splice-demo/shipment/shipment_in_transit.csv\u0027,\n     \u0027|\u0027,\n     null,\n     \u0027yyyy-MM-dd HH:mm:ss.SSSSSS\u0027,\n     \u0027yyyy-MM-dd\u0027,\n     null,\n     -1,\n     \u0027/tmp\u0027,\n     true, null);",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:09:23.971",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787811_1399795537",
      "id": "20180202-104501_1686524282",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ncall SYSCS_UTIL.IMPORT_DATA (\n     \u0027DEV2_ASN\u0027,\n     \u0027SHIPMENT_HISTORY\u0027,\n     null,\n     \u0027s3a://splice-demo/shipment/shipment_history.csv\u0027,\n     \u0027|\u0027,\n     null,\n     \u0027yyyy-MM-dd HH:mm:ss.SSSSSS\u0027,\n     \u0027yyyy-MM-dd\u0027,\n     null,\n     -1,\n     \u0027/tmp\u0027,\n     true, null);",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:09:21.359",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/sql",
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "rowsImported": "string",
                      "failedRows": "string",
                      "files": "string",
                      "dataSize": "string",
                      "failedLog": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787811_1348543062",
      "id": "20180202-104531_242494964",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 4. Create our Features Table\n\nWe create a features table in our database that we use with our learning model. We add three computed fields in the `features` table that are important to our model:\n\n* `quantity_bin` categorizes shipping quantities into bins, to improve learning accuracy \n* `lateness` computes how many days late a shipment was\n* `label` categorizes lateness into one of four values:\n\n\u003ctable class\u003d\"spliceZepNoBorder\" style\u003d\"margin: 0 0 100px 50px;\"\u003e\n    \u003ctbody\u003e\n            \u003ctr\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e1-5 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e5-10 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e3\u003c/td\u003e\u003ctd\u003e10 days or more late\u003c/td\u003e\u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:20:34.367",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e4. Create our Features Table\u003c/h3\u003e\n\u003cp\u003eWe create a features table in our database that we use with our learning model. We add three computed fields in the \u003ccode\u003efeatures\u003c/code\u003e table that are important to our model:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ccode\u003equantity_bin\u003c/code\u003e categorizes shipping quantities into bins, to improve learning accuracy\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003elateness\u003c/code\u003e computes how many days late a shipment was\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003elabel\u003c/code\u003e categorizes lateness into one of four values:\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable class\u003d\"spliceZepNoBorder\" style\u003d\"margin: 0 0 100px 50px;\"\u003e\n    \u003ctbody\u003e\n            \u003ctr\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e1-5 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e5-10 days late\u003c/td\u003e\u003c/tr\u003e\n            \u003ctr\u003e\u003ctd\u003e3\u003c/td\u003e\u003ctd\u003e10 days or more late\u003c/td\u003e\u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787811_-342254676",
      "id": "20180202-104618_659628734",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ndrop table IF EXISTS DEV2_ASN.FEATURES;\nCREATE table DEV2_ASN.FEATURES AS\n    SELECT \n    SHIPMENTID,\n    STATUS,\n    SHIPMODE,\n    PRODUCT_DESCRIPTION,\n    CONSIGNEE,\n    SHIPPER,\n    ARRIVAL_DATE,\n    GROSS_WEIGHT_LB,\n    GROSS_WEIGHT_KG,\n    FOREIGN_PORT,\n    US_PORT,\n    VESSEL_NAME,\n    COUNTRY_OF_ORIGIN,\n    CONSIGNEE_ADDRESS,\n    SHIPPER_ADDRESS,\n    ZIPCODE,\n    NO_OF_CONTAINERS,\n    CONTAINER_NUMBER,\n    CONTAINER_TYPE,\n    QUANTITY,\n    QUANTITY_UNIT,\n    MEASUREMENT,\n    MEASUREMENT_UNIT,\n    BILL_OF_LADING,\n    HOUSE_VS_MASTER,\n    DISTRIBUTION_PORT,\n    MASTER_BL,\n    VOYAGE_NUMBER,\n    SEAL,\n    SHIP_REGISTERED_IN,\n    INBOND_ENTRY_TYPE,\n    CARRIER_CODE,\n    CARRIER_NAME,\n    CARRIER_CITY,\n    CARRIER_STATE,\n    CARRIER_ZIP,\n    CARRIER_ADDRESS,\n    NOTIFY_PARTY,\n    NOTIFY_ADDRESS,\n    PLACE_OF_RECEIPT,\n    DATE_OF_RECEIPT,\n    CASE\n    WHEN DEV2_ASN.SHIPMENT_HISTORY.QUANTITY \u003e 10\n    THEN\n        CASE\n            WHEN DEV2_ASN.SHIPMENT_HISTORY.QUANTITY \u003e 100\n            THEN\n                CASE\n                    WHEN DEV2_ASN.SHIPMENT_HISTORY.QUANTITY \u003e 1000\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n    END\n    ELSE 0\n    END AS QUANTITY_BIN,\n    DEV2_ASN.SHIPMENT_HISTORY.DATE_OF_RECEIPT - DEV2_ASN.SHIPMENT_HISTORY.ARRIVAL_DATE as LATENESS,\n    CASE\n    WHEN  DEV2_ASN.SHIPMENT_HISTORY.DATE_OF_RECEIPT - DEV2_ASN.SHIPMENT_HISTORY.ARRIVAL_DATE \u003e 0\n    THEN\n        CASE\n            WHEN  DEV2_ASN.SHIPMENT_HISTORY.DATE_OF_RECEIPT - DEV2_ASN.SHIPMENT_HISTORY.ARRIVAL_DATE \u003e 5\n            THEN\n                CASE\n                    WHEN  DEV2_ASN.SHIPMENT_HISTORY.DATE_OF_RECEIPT - DEV2_ASN.SHIPMENT_HISTORY.ARRIVAL_DATE \u003e 10\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n    END\n    ELSE 0\n    END AS LABEL\nFROM DEV2_ASN.SHIPMENT_HISTORY ",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:09:48.001",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787812_-713520919",
      "id": "20180205-022847_1435938411",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Create, Train, and Deploy our Learning Model\n\nThe remainder of this notebook walks you through the code we use to create, train, and deploy our learning model, in these steps:\n\n1. Perform Spark+MLlib Setup Tasks\n2. Create our DataFrame\n3. Create Pipeline Stages\n4. Assemble the Pipeline\u003eTrain our Model\n5. Deploy our Model\n\nWe include the entire program at the end of this notebook.",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:21:37.537",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eCreate, Train, and Deploy our Learning Model\u003c/h2\u003e\n\u003cp\u003eThe remainder of this notebook walks you through the code we use to create, train, and deploy our learning model, in these steps:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003ePerform Spark+MLlib Setup Tasks\u003c/li\u003e\n  \u003cli\u003eCreate our DataFrame\u003c/li\u003e\n  \u003cli\u003eCreate Pipeline Stages\u003c/li\u003e\n  \u003cli\u003eAssemble the Pipeline\u0026gt;Train our Model\u003c/li\u003e\n  \u003cli\u003eDeploy our Model\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWe include the entire program at the end of this notebook.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787812_-451255579",
      "id": "20180131-172852_644197695",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 1. Perform Spark + MLlib Setup Tasks\n\nThe Python Splice Machine API communicates with your database through the `PySparkContext` class, which we created in the previous Notebook.\n\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:07:34.907",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e1. Perform Spark + MLlib Setup Tasks\u003c/h3\u003e\n\u003cp\u003eThe Python Splice Machine API communicates with your database through the \u003ccode\u003ePySparkContext\u003c/code\u003e class, which we created in the previous Notebook.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542759213126_684562962",
      "id": "20181120-161333_1536591529",
      "dateCreated": "2018-11-20 16:13:33.127",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \nWe use the following code to instantiate `PySpliceContext` and import our modules:\n\n```\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\n\nsplice \u003d PySpliceContext(defaultJDBCURL, sqlContext)\n```",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:22:19.245",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eWe use the following code to instantiate \u003ccode\u003ePySpliceContext\u003c/code\u003e and import our modules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\n\nsplice \u003d PySpliceContext(defaultJDBCURL, sqlContext)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787814_1617706465",
      "id": "20180611-203526_1071983380",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 2. Create our DataFrame\n\nNext we create a Python DataFrame from the results of a SQL `SELECT` query from the database. This allows us to manipulate our Splice Machine data as a Spark DataFrame\n\n```\ndf_with_uppercase_schema \u003d PySpliceContext.df(\"select * from DEV2_ASN.Features\")\nnewNames \u003d [\n    \"consignee\",\n    \"shipper\",\n    \"shipmode\",\n    \"gross_weight_lb\",\n    \"foreign_port\",\n    \"us_port\",\n    \"vessel_name\",\n    \"country_of_origin\",\n    \"container_number\",\n    \"container_type\",\n    \"quantity\",\n    \"ship_registered_in\",\n    \"carrier_code\",\n    \"carrier_city\",\n    \"notify_party\",\n    \"place_of_receipt\",\n    \"zipcode\",\n    \"quantity_bin\"\n    ]\ndf \u003d df_with_uppercase_schema.toDF(newNames)\n```",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:23:24.910",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e2. Create our DataFrame\u003c/h3\u003e\n\u003cp\u003eNext we create a Python DataFrame from the results of a SQL \u003ccode\u003eSELECT\u003c/code\u003e query from the database. This allows us to manipulate our Splice Machine data as a Spark DataFrame\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edf_with_uppercase_schema \u003d PySpliceContext.df(\u0026quot;select * from DEV2_ASN.Features\u0026quot;)\nnewNames \u003d [\n    \u0026quot;consignee\u0026quot;,\n    \u0026quot;shipper\u0026quot;,\n    \u0026quot;shipmode\u0026quot;,\n    \u0026quot;gross_weight_lb\u0026quot;,\n    \u0026quot;foreign_port\u0026quot;,\n    \u0026quot;us_port\u0026quot;,\n    \u0026quot;vessel_name\u0026quot;,\n    \u0026quot;country_of_origin\u0026quot;,\n    \u0026quot;container_number\u0026quot;,\n    \u0026quot;container_type\u0026quot;,\n    \u0026quot;quantity\u0026quot;,\n    \u0026quot;ship_registered_in\u0026quot;,\n    \u0026quot;carrier_code\u0026quot;,\n    \u0026quot;carrier_city\u0026quot;,\n    \u0026quot;notify_party\u0026quot;,\n    \u0026quot;place_of_receipt\u0026quot;,\n    \u0026quot;zipcode\u0026quot;,\n    \u0026quot;quantity_bin\u0026quot;\n    ]\ndf \u003d df_with_uppercase_schema.toDF(newNames)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787814_-782902311",
      "id": "20180611-211856_605292217",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 3. Create Pipeline Stages\n\nOur pipeline stages are fairly simple:\n\n* Transform each row of data in the input dataset into an integer vector.\n* Assemble the vectors into a DataFrame\n* Use a Logistic Regression Estimator to create our model\n\n#### Transform each row of data into an integer vector\n\nThe Logistic Regression estimator operates on integer vectors, so we need to convert each row in our input dataframe into an integer vector. Remember that each row contains only the fields from our database that are of interest to our model: the fields that previously included in our sequence and concatenated onto our DataFrame.\n\nSpark includes a `StringIndexer` function that does exactly that, so we create a `StringIndexer` for each field, and we\u0027ll later use each of these as a stage in our learning pipeline. The `StringIndexer` transforms the data from a specified input column in our DataFrame and stores the output in a specified and new output column. By convention, we name each string indexer with the name of the field+`Indexer,` and name the output column the name of the field+`Index,` e.g. we create a transformer named `consigneeIndexer` to transform the input column `consignee` into the new output column `consigneeIndex.`\n\n```\n// Transform strings into numbers\nconsigneeIndexer \u003d  StringIndexer(inputCol\u003d\"consignee\", outputCol\u003d\"consigneeIndex\", handleInvalid\u003d\"skip\")\nshipperIndexer \u003d StringIndexer(inputCol\u003d\"shipper\", outputCol\u003d\"shipperIndex\", handleInvalid\u003d\"skip\")\nshipmodeIndexer \u003d StringIndexer(inputCol\u003d\"shipmode\", outputCol\u003d\"shipmodeIndex\", handleInvalid\u003d\"skip\")\ngross_weight_lbIndexer \u003d StringIndexer(inputCol\u003d\"gross_weight_lb\", outputCol\u003d\"gross_weight_lbIndex\", handleInvalid\u003d\"skip\")\nforeign_portIndexer \u003d  StringIndexer(inputCol\u003d\"foreign_port\", outputCol\u003d\"foreign_portIndex\", handleInvalid\u003d\"skip\")\nus_portIndexer \u003d StringIndexer(inputCol\u003d\"us_port\", outputCol\u003d\"us_portIndex\", handleInvalid\u003d\"skip\")\nvessel_nameIndexer \u003d StringIndexer(inputCol\u003d\"vessel_name\", outputCol\u003d\"vessel_nameIndex\",  handleInvalid\u003d\"skip\")\ncountry_of_originIndexer \u003d StringIndexer(inputCol\u003d\"country_of_origin\", outputCol\u003d\"country_of_originIndex\",  handleInvalid\u003d\"skip\")\ncontainer_numberIndexer \u003d StringIndexer(inputCol\u003d\"container_number\", outputCol\u003d\"container_numberIndex\", handleInvalid\u003d\"skip\")\ncontainer_typeIndexer \u003d StringIndexer(inputCol\u003d\"container_type\", outputCol\u003d\"container_typeIndex\", handleInvalid\u003d\"skip\")\nship_registered_inIndexer \u003d StringIndexer(inputCol\u003d\"ship_registered_in\", outputCol\u003d\"ship_registered_inIndex\", handleInvalid\u003d\"skip\")\ncarrier_codeIndexer \u003d StringIndexer(inputCol\u003d\"carrier_code\", outputCol\u003d\"carrier_codeIndex\", handleInvalid\u003d\"skip\")\ncarrier_cityIndexer \u003d StringIndexer(inputCol\u003d\"carrier_city\", outputCol\u003d\"carrier_cityIndex\", handleInvalid\u003d\"skip\")\nnotify_partyIndexer \u003d StringIndexer(inputCol\u003d\"notify_party\", outputCol\u003d\"notify_partyIndex\", handleInvalid\u003d\"skip\")\nplace_of_receiptIndexer \u003d StringIndexer(inputCol\u003d\"place_of_receipt\", outputCol\u003d\"place_of_receiptIndex\", handleInvalid\u003d\"skip\")\nzipcodeIndexer \u003d StringIndexer(inputCol\u003d\"zipcode\", outputCol\u003d\"zipcodeIndex\", handleInvalid\u003d\"skip\")\n```\n#### Assemble the Vectors\n\nAfter our pipeline has transformed data into numbers, we need to assemble those into vectors. Spark includes a `VectorAssembler` object that does just that, transforming a set of input columns into a vector that is stored in the `features` column in the DataFrame:\n\n```\n//assemble raw features\nassembler \u003d VectorAssembler(inputCols\u003d[\n                    \"shipmodeIndex\",\n                    \"consigneeIndex\",\n                    \"shipperIndex\",\n                    \"gross_weight_lbIndex\",\n                    \"foreign_portIndex\",\n                    \"us_portIndex\",\n                    \"vessel_nameIndex\",\n                    \"country_of_originIndex\",\n                    \"container_numberIndex\",\n                    \"container_typeIndex\",\n                    \"quantity_bin\",\n                    \"ship_registered_inIndex\",\n                    \"carrier_codeIndex\",\n                    \"carrier_cityIndex\",\n                    \"notify_partyIndex\",\n                    \"place_of_receiptIndex\",\n                    \"zipcodeIndex\",\n                    \"quantity_bin\"\n                    ], outputCol\u003d\u0027features\u0027)\n```\n\n#### Create the Estimator\n\nCreating the estimator is a simple matter of specifying a few parameters, including which column in the DataFrame is the label, and which column contains the feature set:\n\n```\n//Create ML analytic\nlr \u003d LogisticRegression(maxIter\u003d30, labelCol\u003d\"label\", featuresCol\u003d\"features\", regParam\u003d0.3)\n\n```\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:23:31.149",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e3. Create Pipeline Stages\u003c/h3\u003e\n\u003cp\u003eOur pipeline stages are fairly simple:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eTransform each row of data in the input dataset into an integer vector.\u003c/li\u003e\n  \u003cli\u003eAssemble the vectors into a DataFrame\u003c/li\u003e\n  \u003cli\u003eUse a Logistic Regression Estimator to create our model\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eTransform each row of data into an integer vector\u003c/h4\u003e\n\u003cp\u003eThe Logistic Regression estimator operates on integer vectors, so we need to convert each row in our input dataframe into an integer vector. Remember that each row contains only the fields from our database that are of interest to our model: the fields that previously included in our sequence and concatenated onto our DataFrame.\u003c/p\u003e\n\u003cp\u003eSpark includes a \u003ccode\u003eStringIndexer\u003c/code\u003e function that does exactly that, so we create a \u003ccode\u003eStringIndexer\u003c/code\u003e for each field, and we\u0026rsquo;ll later use each of these as a stage in our learning pipeline. The \u003ccode\u003eStringIndexer\u003c/code\u003e transforms the data from a specified input column in our DataFrame and stores the output in a specified and new output column. By convention, we name each string indexer with the name of the field+\u003ccode\u003eIndexer,\u003c/code\u003e and name the output column the name of the field+\u003ccode\u003eIndex,\u003c/code\u003e e.g. we create a transformer named \u003ccode\u003econsigneeIndexer\u003c/code\u003e to transform the input column \u003ccode\u003econsignee\u003c/code\u003e into the new output column \u003ccode\u003econsigneeIndex.\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Transform strings into numbers\nconsigneeIndexer \u003d  StringIndexer(inputCol\u003d\u0026quot;consignee\u0026quot;, outputCol\u003d\u0026quot;consigneeIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nshipperIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;shipper\u0026quot;, outputCol\u003d\u0026quot;shipperIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nshipmodeIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;shipmode\u0026quot;, outputCol\u003d\u0026quot;shipmodeIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\ngross_weight_lbIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;gross_weight_lb\u0026quot;, outputCol\u003d\u0026quot;gross_weight_lbIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nforeign_portIndexer \u003d  StringIndexer(inputCol\u003d\u0026quot;foreign_port\u0026quot;, outputCol\u003d\u0026quot;foreign_portIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nus_portIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;us_port\u0026quot;, outputCol\u003d\u0026quot;us_portIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nvessel_nameIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;vessel_name\u0026quot;, outputCol\u003d\u0026quot;vessel_nameIndex\u0026quot;,  handleInvalid\u003d\u0026quot;skip\u0026quot;)\ncountry_of_originIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;country_of_origin\u0026quot;, outputCol\u003d\u0026quot;country_of_originIndex\u0026quot;,  handleInvalid\u003d\u0026quot;skip\u0026quot;)\ncontainer_numberIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;container_number\u0026quot;, outputCol\u003d\u0026quot;container_numberIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\ncontainer_typeIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;container_type\u0026quot;, outputCol\u003d\u0026quot;container_typeIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nship_registered_inIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;ship_registered_in\u0026quot;, outputCol\u003d\u0026quot;ship_registered_inIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\ncarrier_codeIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;carrier_code\u0026quot;, outputCol\u003d\u0026quot;carrier_codeIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\ncarrier_cityIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;carrier_city\u0026quot;, outputCol\u003d\u0026quot;carrier_cityIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nnotify_partyIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;notify_party\u0026quot;, outputCol\u003d\u0026quot;notify_partyIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nplace_of_receiptIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;place_of_receipt\u0026quot;, outputCol\u003d\u0026quot;place_of_receiptIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\nzipcodeIndexer \u003d StringIndexer(inputCol\u003d\u0026quot;zipcode\u0026quot;, outputCol\u003d\u0026quot;zipcodeIndex\u0026quot;, handleInvalid\u003d\u0026quot;skip\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eAssemble the Vectors\u003c/h4\u003e\n\u003cp\u003eAfter our pipeline has transformed data into numbers, we need to assemble those into vectors. Spark includes a \u003ccode\u003eVectorAssembler\u003c/code\u003e object that does just that, transforming a set of input columns into a vector that is stored in the \u003ccode\u003efeatures\u003c/code\u003e column in the DataFrame:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e//assemble raw features\nassembler \u003d VectorAssembler(inputCols\u003d[\n                    \u0026quot;shipmodeIndex\u0026quot;,\n                    \u0026quot;consigneeIndex\u0026quot;,\n                    \u0026quot;shipperIndex\u0026quot;,\n                    \u0026quot;gross_weight_lbIndex\u0026quot;,\n                    \u0026quot;foreign_portIndex\u0026quot;,\n                    \u0026quot;us_portIndex\u0026quot;,\n                    \u0026quot;vessel_nameIndex\u0026quot;,\n                    \u0026quot;country_of_originIndex\u0026quot;,\n                    \u0026quot;container_numberIndex\u0026quot;,\n                    \u0026quot;container_typeIndex\u0026quot;,\n                    \u0026quot;quantity_bin\u0026quot;,\n                    \u0026quot;ship_registered_inIndex\u0026quot;,\n                    \u0026quot;carrier_codeIndex\u0026quot;,\n                    \u0026quot;carrier_cityIndex\u0026quot;,\n                    \u0026quot;notify_partyIndex\u0026quot;,\n                    \u0026quot;place_of_receiptIndex\u0026quot;,\n                    \u0026quot;zipcodeIndex\u0026quot;,\n                    \u0026quot;quantity_bin\u0026quot;\n                    ], outputCol\u003d\u0026#39;features\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eCreate the Estimator\u003c/h4\u003e\n\u003cp\u003eCreating the estimator is a simple matter of specifying a few parameters, including which column in the DataFrame is the label, and which column contains the feature set:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e//Create ML analytic\nlr \u003d LogisticRegression(maxIter\u003d30, labelCol\u003d\u0026quot;label\u0026quot;, featuresCol\u003d\u0026quot;features\u0026quot;, regParam\u003d0.3)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787814_-937797929",
      "id": "20180611-212921_295690204",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 4. Assemble our Pipeline\n\nNow we\u0027re ready to assemble our pipeline:\n\n```\n// Chain indexers and tree in a Pipeline\nlrPipeline \u003d Pipeline(stages\u003d\n        [consigneeIndexer,\n        shipperIndexer,\n        shipmodeIndexer,\n        gross_weight_lbIndexer,\n        foreign_portIndexer,\n        us_portIndexer,\n        vessel_nameIndexer,\n        country_of_originIndexer,\n        container_numberIndexer,\n        container_typeIndexer,\n        ship_registered_inIndexer,\n        carrier_codeIndexer,\n        carrier_cityIndexer,\n        notify_partyIndexer,\n        place_of_receiptIndexer,\n        zipcodeIndexer,\n        assembler,\n        lr]\n        )\n```",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:23:55.260",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e4. Assemble our Pipeline\u003c/h3\u003e\n\u003cp\u003eNow we\u0026rsquo;re ready to assemble our pipeline:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Chain indexers and tree in a Pipeline\nlrPipeline \u003d Pipeline(stages\u003d\n        [consigneeIndexer,\n        shipperIndexer,\n        shipmodeIndexer,\n        gross_weight_lbIndexer,\n        foreign_portIndexer,\n        us_portIndexer,\n        vessel_nameIndexer,\n        country_of_originIndexer,\n        container_numberIndexer,\n        container_typeIndexer,\n        ship_registered_inIndexer,\n        carrier_codeIndexer,\n        carrier_cityIndexer,\n        notify_partyIndexer,\n        place_of_receiptIndexer,\n        zipcodeIndexer,\n        assembler,\n        lr]\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787815_-1002231981",
      "id": "20180611-215932_1084664308",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### 5. Train our Model\nNow that our pipeline is set up, all we need to do to train our model by feeding our dataframe into the pipeline\u0027s `fit` method, which learns from the data. \n```\n// Train model. \nlrModel \u003d lrPipeline.fit(df)\n```\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:24:00.998",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e5. Train our Model\u003c/h3\u003e\n\u003cp\u003eNow that our pipeline is set up, all we need to do to train our model by feeding our dataframe into the pipeline\u0026rsquo;s \u003ccode\u003efit\u003c/code\u003e method, which learns from the data. \u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// Train model. \nlrModel \u003d lrPipeline.fit(df)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787815_1282966933",
      "id": "20180611-220247_1750575070",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Using Spark MLlib",
      "text": "%md\n### 6. Materialize the Model\n\nAfter training our model, we can apply it to real data and display the results. For simplicity sake, in this example, we\u0027ll apply the model to our feature table itself.\n\n```\nlrModel.transform(df).select(\"prediction\", \"probability\", \"features\").show(100)\n```",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:24:06.119",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": false,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003e6. Materialize the Model\u003c/h3\u003e\n\u003cp\u003eAfter training our model, we can apply it to real data and display the results. For simplicity sake, in this example, we\u0026rsquo;ll apply the model to our feature table itself.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003elrModel.transform(df).select(\u0026quot;prediction\u0026quot;, \u0026quot;probability\u0026quot;, \u0026quot;features\u0026quot;).show(100)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787815_-1172896776",
      "id": "20180118-020316_1913850778",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\nselect *  from DEV2_ASN.features { limit 100 }\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:10:19.203",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "SHIPMENTID": "string",
                      "STATUS": "string",
                      "SHIPMODE": "string",
                      "PRODUCT_DESCRIPTION": "string",
                      "CONSIGNEE": "string",
                      "SHIPPER": "string",
                      "ARRIVAL_DATE": "string",
                      "GROSS_WEIGHT_LB": "string",
                      "GROSS_WEIGHT_KG": "string",
                      "FOREIGN_PORT": "string",
                      "US_PORT": "string",
                      "VESSEL_NAME": "string",
                      "COUNTRY_OF_ORIGIN": "string",
                      "CONSIGNEE_ADDRESS": "string",
                      "SHIPPER_ADDRESS": "string",
                      "ZIPCODE": "string",
                      "NO_OF_CONTAINERS": "string",
                      "CONTAINER_NUMBER": "string",
                      "CONTAINER_TYPE": "string",
                      "QUANTITY": "string",
                      "QUANTITY_UNIT": "string",
                      "MEASUREMENT": "string",
                      "MEASUREMENT_UNIT": "string",
                      "BILL_OF_LADING": "string",
                      "HOUSE_VS_MASTER": "string",
                      "DISTRIBUTION_PORT": "string",
                      "MASTER_BL": "string",
                      "VOYAGE_NUMBER": "string",
                      "SEAL": "string",
                      "SHIP_REGISTERED_IN": "string",
                      "INBOND_ENTRY_TYPE": "string",
                      "CARRIER_CODE": "string",
                      "CARRIER_NAME": "string",
                      "CARRIER_CITY": "string",
                      "CARRIER_STATE": "string",
                      "CARRIER_ZIP": "string",
                      "CARRIER_ADDRESS": "string",
                      "NOTIFY_PARTY": "string",
                      "NOTIFY_ADDRESS": "string",
                      "PLACE_OF_RECEIPT": "string",
                      "DATE_OF_RECEIPT": "string",
                      "QUANTITY_BIN": "string",
                      "LATENESS": "string",
                      "LABEL": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787816_-999139773",
      "id": "20180205-024307_1130627818",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## The Python Code\n\nOur Python code is listed in the next paragraph.\n\n\u003cp class\u003d\"noteNote\"\u003eYou can ignore the \u003ccode\u003eRuntimeWarning:\u003c/code\u003e warning messages that may display when you run the code in the next paragraph.\u003c/p\u003e\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-07 00:24:26.489",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eThe Python Code\u003c/h2\u003e\n\u003cp\u003eOur Python code is listed in the next paragraph.\u003c/p\u003e\n\u003cp class\u003d\"noteNote\"\u003eYou can ignore the \u003ccode\u003eRuntimeWarning:\u003c/code\u003e warning messages that may display when you run the code in the next paragraph.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787817_317619724",
      "id": "20180611-220822_612758436",
      "dateCreated": "2018-11-16 11:16:27.000",
      "dateStarted": "2018-12-07 00:24:26.491",
      "dateFinished": "2018-12-07 00:24:26.574",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nfrom __future__ import print_function\nimport string\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nfrom pyspark.sql import DataFrame\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nfrom __future__ import print_function\n\nfrom pyspark.sql import DataFrame\n\n# Setup our SpliceContext\nsplice \u003d PySpliceContext(defaultJDBCURL, sqlContext)\n \n# Query Features\nquery_results \u003d splice.df(\"select * from DEV2_ASN.Features\")\nnewNames \u003d [\"shipmentid\",\n            \"status\",\n            \"shipmode\",\n            \"product_description\",\n            \"consignee\",\n            \"shipper\",\n            \"arrival_date\",\n            \"gross_weight_lb\",\n            \"gross_weight_kg\",\n            \"foreign_port\",\n            \"us_port\",\n            \"vessel_name\",\n            \"country_of_origin\",\n            \"consignee_address\",\n            \"shipper_address\",\n            \"zipcode\",\n            \"no_of_containers\",\n            \"container_number\",\n            \"container_type\",\n            \"quantity\",\n            \"quantity_unit\",\n            \"measurement\",\n            \"measurement_unit\",\n            \"bill_of_lading\",\n            \"house_vs_master\",\n            \"distribution_port\",\n            \"master_bl\",\n            \"voyage_number\",\n            \"seal\",\n            \"ship_registered_in\",\n            \"inbond_entry_type\",\n            \"carrier_code\",\n            \"carrier_name\",\n            \"carrier_city\",\n            \"carrier_state\",\n            \"carrier_zip\",\n            \"carrier_address\",\n            \"notify_party\",\n            \"notify_address\",\n            \"place_of_receipt\",\n            \"date_of_receipt\",\n            \"quantity_bin\",\n            \"lateness\",\n            \"label\"]\n\ndf \u003d query_results.toDF(*newNames)\n\n# Assemble Vectors\nassembler \u003d VectorAssembler(inputCols\u003d[\n    \"shipmodeIndex\",\n    \"consigneeIndex\",\n    \"shipperIndex\",\n    \"gross_weight_lbIndex\",\n    \"foreign_portIndex\",\n    \"us_portIndex\",\n    \"vessel_nameIndex\",\n    \"country_of_originIndex\",\n    \"container_numberIndex\",\n    \"container_typeIndex\",\n    \"ship_registered_inIndex\",\n    \"carrier_codeIndex\",\n    \"carrier_cityIndex\",\n    \"notify_partyIndex\",\n    \"place_of_receiptIndex\",\n    \"zipcodeIndex\",\n    \"quantity_bin\"\n], outputCol\u003d\u0027features\u0027)\n\n# Transform strings into numbers\nzipcodeIndexer \u003d StringIndexer(inputCol\u003d\"zipcode\", outputCol\u003d\"zipcodeIndex\", handleInvalid\u003d\"skip\")\nconsigneeIndexer \u003d StringIndexer(inputCol\u003d\"consignee\", outputCol\u003d\"consigneeIndex\", handleInvalid\u003d\"skip\")\nshipperIndexer \u003d StringIndexer(inputCol\u003d\"shipper\", outputCol\u003d\"shipperIndex\", handleInvalid\u003d\"skip\")\nstatusIndexer \u003d StringIndexer(inputCol\u003d\"status\", outputCol\u003d\"statusIndex\", handleInvalid\u003d\"skip\")\nshipmodeIndexer \u003d StringIndexer(inputCol\u003d\"shipmode\", outputCol\u003d\"shipmodeIndex\", handleInvalid\u003d\"skip\")\ngross_weight_lbIndexer \u003d StringIndexer(inputCol\u003d\"gross_weight_lb\", outputCol\u003d\"gross_weight_lbIndex\",\n                                       handleInvalid\u003d\"skip\")\nforeign_portIndexer \u003d StringIndexer(inputCol\u003d\"foreign_port\", outputCol\u003d\"foreign_portIndex\", handleInvalid\u003d\"skip\")\nus_portIndexer \u003d StringIndexer(inputCol\u003d\"us_port\", outputCol\u003d\"us_portIndex\", handleInvalid\u003d\"skip\")\nvessel_nameIndexer \u003d StringIndexer(inputCol\u003d\"vessel_name\", outputCol\u003d\"vessel_nameIndex\", handleInvalid\u003d\"skip\")\ncountry_of_originIndexer \u003d StringIndexer(inputCol\u003d\"country_of_origin\", outputCol\u003d\"country_of_originIndex\",\n                                         handleInvalid\u003d\"skip\")\ncontainer_numberIndexer \u003d StringIndexer(inputCol\u003d\"container_number\", outputCol\u003d\"container_numberIndex\",\n                                        handleInvalid\u003d\"skip\")\ncontainer_typeIndexer \u003d StringIndexer(inputCol\u003d\"container_type\", outputCol\u003d\"container_typeIndex\",\n                                      handleInvalid\u003d\"skip\")\ndistribution_portIndexer \u003d StringIndexer(inputCol\u003d\"distribution_port\", outputCol\u003d\"distribution_portIndex\",\n                                         handleInvalid\u003d\"skip\")\nship_registered_inIndexer \u003d StringIndexer(inputCol\u003d\"ship_registered_in\", outputCol\u003d\"ship_registered_inIndex\",\n                                          handleInvalid\u003d\"skip\")\ninbond_entry_typeIndexer \u003d StringIndexer(inputCol\u003d\"inbond_entry_type\", outputCol\u003d\"inbond_entry_typeIndex\",\n                                         handleInvalid\u003d\"skip\")\ncarrier_codeIndexer \u003d StringIndexer(inputCol\u003d\"carrier_code\", outputCol\u003d\"carrier_codeIndex\", handleInvalid\u003d\"skip\")\ncarrier_cityIndexer \u003d StringIndexer(inputCol\u003d\"carrier_city\", outputCol\u003d\"carrier_cityIndex\", handleInvalid\u003d\"skip\")\ncarrier_stateIndexer \u003d StringIndexer(inputCol\u003d\"carrier_state\", outputCol\u003d\"carrier_stateIndex\", handleInvalid\u003d\"skip\")\ncarrier_zipIndexer \u003d StringIndexer(inputCol\u003d\"carrier_zip\", outputCol\u003d\"carrier_zipIndex\", handleInvalid\u003d\"skip\")\nnotify_partyIndexer \u003d StringIndexer(inputCol\u003d\"notify_party\", outputCol\u003d\"notify_partyIndex\", handleInvalid\u003d\"skip\")\nplace_of_receiptIndexer \u003d StringIndexer(inputCol\u003d\"place_of_receipt\", outputCol\u003d\"place_of_receiptIndex\",\n                                        handleInvalid\u003d\"skip\")\n\nlr \u003d LogisticRegression(maxIter\u003d30, labelCol\u003d\"label\", featuresCol\u003d\"features\", regParam\u003d0.3)\n\nlrPipeline \u003d Pipeline(stages\u003d\n                      [consigneeIndexer,\n                       shipperIndexer,\n                       shipmodeIndexer,\n                       gross_weight_lbIndexer,\n                       foreign_portIndexer,\n                       us_portIndexer,\n                       vessel_nameIndexer,\n                       country_of_originIndexer,\n                       container_numberIndexer,\n                       container_typeIndexer,\n                       ship_registered_inIndexer,\n                       carrier_codeIndexer,\n                       carrier_cityIndexer,\n                       notify_partyIndexer,\n                       place_of_receiptIndexer,\n                       zipcodeIndexer,\n                       assembler,\n                       lr]\n                      )\nparamGrid \u003d ParamGridBuilder() \\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .build()\n\ncrossval \u003d CrossValidator(estimator\u003dlrPipeline,\n                          estimatorParamMaps\u003dparamGrid,\n                          evaluator\u003dBinaryClassificationEvaluator(),\n                          numFolds\u003d2)  # use 3+ folds in practice\n\n# Run cross-validation, and choose the best parameters to demonstate GridSearch in Spark MLlib\nlrModel \u003d crossval.fit(df)\n\ntransformed_df \u003d lrModel.transform(df)\ntransformed_df.createOrReplaceTempView(\"res_view\")\nresults \u003d sqlContext.sql(\u0027SELECT prediction, probability, features from res_view\u0027)\nresults.show(20)\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-07 21:57:19.115",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787817_1342897950",
      "id": "20180611-220729_615649684",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\ndrop table IF EXISTS DEV2_ASN.TEST_FEATURES;\nCREATE table DEV2_ASN.TEST_FEATURES AS\n    SELECT \n    SHIPMENTID,\n    STATUS,\n    SHIPMODE,\n    PRODUCT_DESCRIPTION,\n    CONSIGNEE,\n    SHIPPER,\n    ARRIVAL_DATE,\n    GROSS_WEIGHT_LB,\n    GROSS_WEIGHT_KG,\n    FOREIGN_PORT,\n    US_PORT,\n    VESSEL_NAME,\n    COUNTRY_OF_ORIGIN,\n    CONSIGNEE_ADDRESS,\n    SHIPPER_ADDRESS,\n    ZIPCODE,\n    NO_OF_CONTAINERS,\n    CONTAINER_NUMBER,\n    CONTAINER_TYPE,\n    QUANTITY,\n    QUANTITY_UNIT,\n    MEASUREMENT,\n    MEASUREMENT_UNIT,\n    BILL_OF_LADING,\n    HOUSE_VS_MASTER,\n    DISTRIBUTION_PORT,\n    MASTER_BL,\n    VOYAGE_NUMBER,\n    SEAL,\n    SHIP_REGISTERED_IN,\n    INBOND_ENTRY_TYPE,\n    CARRIER_CODE,\n    CARRIER_NAME,\n    CARRIER_CITY,\n    CARRIER_STATE,\n    CARRIER_ZIP,\n    CARRIER_ADDRESS,\n    NOTIFY_PARTY,\n    NOTIFY_ADDRESS,\n    PLACE_OF_RECEIPT,\n    DATE_OF_RECEIPT,\n    CASE\n    WHEN DEV2_ASN.SHIPMENT_IN_TRANSIT.QUANTITY \u003e 10\n    THEN\n        CASE\n            WHEN DEV2_ASN.SHIPMENT_IN_TRANSIT.QUANTITY \u003e 100\n            THEN\n                CASE\n                    WHEN DEV2_ASN.SHIPMENT_IN_TRANSIT.QUANTITY \u003e 1000\n                    THEN 3\n                    ELSE 2\n                END\n            ELSE 1\n\tEND\n    ELSE 0\n    END AS QUANTITY_BIN\n    FROM DEV2_ASN.SHIPMENT_IN_TRANSIT;\n    \n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:10:45.146",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787818_-279223434",
      "id": "20180304-185514_1167859763",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n## Testing the Code\n\nNow we\u0027ll test our code on the `testing` features table:",
      "user": "anonymous",
      "dateUpdated": "2018-12-01 05:27:08.901",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTesting the Code\u003c/h2\u003e\n\u003cp\u003eNow we\u0026rsquo;ll test our code on the \u003ccode\u003etesting\u003c/code\u003e features table:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787818_781413201",
      "id": "20180612-031608_1101973053",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nsplice \u003d PySpliceContext(defaultJDBCURL, sqlContext)\ntest_data_with_uppercase_schema \u003d splice.df(\u0027SELECT * FROM DEV2_ASN.TEST_FEATURES\u0027)\n\nnewNames \u003d [\"shipmentid\",\n            \"status\",\n            \"shipmode\",\n            \"product_description\",\n            \"consignee\",\n            \"shipper\",\n            \"arrival_date\",\n            \"gross_weight_lb\",\n            \"gross_weight_kg\",\n            \"foreign_port\",\n            \"us_port\",\n            \"vessel_name\",\n            \"country_of_origin\",\n            \"consignee_address\",\n            \"shipper_address\",\n            \"zipcode\",\n            \"no_of_containers\",\n            \"container_number\",\n            \"container_type\",\n            \"quantity\",\n            \"quantity_unit\",\n            \"measurement\",\n            \"measurement_unit\",\n            \"bill_of_lading\",\n            \"house_vs_master\",\n            \"distribution_port\",\n            \"master_bl\",\n            \"voyage_number\",\n            \"seal\",\n            \"ship_registered_in\",\n            \"inbond_entry_type\",\n            \"carrier_code\",\n            \"carrier_name\",\n            \"carrier_city\",\n            \"carrier_state\",\n            \"carrier_zip\",\n            \"carrier_address\",\n            \"notify_party\",\n            \"notify_address\",\n            \"place_of_receipt\",\n            \"date_of_receipt\",\n            \"quantity_bin\"]\n\ndf\u003d test_data_with_uppercase_schema.toDF(*newNames)\nlrPredictions \u003d lrModel.transform(df)\nlrPredictions.createOrReplaceTempView(\"pred_view\")\nresults \u003d sqlContext.sql(\u0027SELECT prediction, probability, features FROM pred_view ORDER BY features\u0027)\nresults.show(20)",
      "user": "anonymous",
      "dateUpdated": "2018-12-07 22:11:54.483",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787818_-162438799",
      "id": "20180612-031749_1939890694",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\nDROP TABLE IF EXISTS DEV2_ASN.PREDICTIONS;\nCREATE TABLE DEV2_ASN.PREDICTIONS (\n    SHIPMENTID VARCHAR(11) NOT NULL PRIMARY KEY,\n    PREDICTION DOUBLE\n    );",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:11:03.812",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787819_8682636",
      "id": "20180205-024429_478433529",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\npredictions \u003d lrPredictions.select(\"SHIPMENTID\", \"PREDICTION\")\npredictions.printSchema()\nsplice.insert(predictions, \u0027DEV2_ASN.predictions\u0027)",
      "user": "anonymous",
      "dateUpdated": "2018-12-07 22:38:10.625",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787819_-1654523393",
      "id": "20180612-161439_366937269",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%splicemachine\nselect * from DEV2_ASN.predictions;",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 18:11:20.636",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 318.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "SHIPMENTID": "string",
                      "PREDICTION": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": true
        },
        "fontSize": 9.0,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542395787820_-1276369870",
      "id": "20180304-190035_379792791",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Where to Go Next\nThe next notebook in this class, [*Creating Custom Stored Procedures*](/#/notebook/2DWAGKSPM), shows you how to create and use custom stored procedures with Splice Machine.\n",
      "user": "anonymous",
      "dateUpdated": "2018-12-02 20:10:51.105",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "results": {},
        "enabled": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": true,
          "completionSupport": false
        },
        "fontSize": 9.0,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eWhere to Go Next\u003c/h2\u003e\n\u003cp\u003eThe next notebook in this class, \u003ca href\u003d\"/#/notebook/2DWAGKSPM\"\u003e\u003cem\u003eCreating Custom Stored Procedures\u003c/em\u003e\u003c/a\u003e, shows you how to create and use custom stored procedures with Splice Machine.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1542395787820_-1701111727",
      "id": "20180726-013341_1392399267",
      "dateCreated": "2018-11-16 11:16:27.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Splice Machine Training / For Developers, Part II - Intermediate / h. Machine Learning with Spark MLlib",
  "id": "2DWTYCFTY",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "splicemachine:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {}
}